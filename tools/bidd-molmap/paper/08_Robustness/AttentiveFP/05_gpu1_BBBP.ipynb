{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sxh/Research/AttentiveFP/code',)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "        \n",
    "    preds = []\n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        probs = F.softmax(mol_prediction,dim=-1).data.cpu().numpy()[:,1]\n",
    "        preds.append(probs)\n",
    "    return np.concatenate(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  2050\n",
      "not successfully processed smiles:  O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n",
      "not successfully processed smiles:  c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
      "not successfully processed smiles:  Cc1nc(sc1)\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [08:35:29] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [08:35:29] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:29] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 12 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [08:35:30] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n",
      "not successfully processed smiles:  c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n",
      "not successfully processed smiles:  s1cc(nc1\\[NH]=C(\\N)N)C\n",
      "not successfully processed smiles:  c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [08:35:30] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successfully processed smiles:  2039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = ['BBBP']\n",
    "raw_filename = \"/home/sxh/Research/AttentiveFP/data/BBBP.csv\"\n",
    "\n",
    "\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 88\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBBP</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>CN[C@H](CC(C)C)C(=O)NC1[C@H](O)c2ccc(Oc3cc4cc(...</td>\n",
       "      <td>CN[C@H](CC(C)C)C(=O)NC1C(=O)N[C@@H](CC(N)=O)C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0</td>\n",
       "      <td>CCC(C)[C@H]1O[C@]2(CC[C@@H]1C)CC3C[C@@H](C\\C=C...</td>\n",
       "      <td>CCC(C)[C@H]1O[C@]2(CC[C@@H]1C)CC1C[C@@H](C/C=C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>CCCCCCCCCC(=O)N[C@@H]1[C@@H](O)[C@H](O)[C@@H](...</td>\n",
       "      <td>CCCCCCCCCC(=O)N[C@H]1[C@H](Oc2c3cc4cc2Oc2ccc(c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BBBP                                             smiles  \\\n",
       "372     0  CN[C@H](CC(C)C)C(=O)NC1[C@H](O)c2ccc(Oc3cc4cc(...   \n",
       "826     0  CCC(C)[C@H]1O[C@]2(CC[C@@H]1C)CC3C[C@@H](C\\C=C...   \n",
       "932     0  CCCCCCCCCC(=O)N[C@@H]1[C@@H](O)[C@H](O)[C@@H](...   \n",
       "\n",
       "                                           cano_smiles  \n",
       "372  CN[C@H](CC(C)C)C(=O)NC1C(=O)N[C@@H](CC(N)=O)C(...  \n",
       "826  CCC(C)[C@H]1O[C@]2(CC[C@@H]1C)CC1C[C@@H](C/C=C...  \n",
       "932  CCCCCCCCCC(=O)N[C@H]1[C@H](Oc2c3cc4cc2Oc2ccc(c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 BBBP\n",
      "16 BBBP\n",
      "32 BBBP\n",
      "64 BBBP\n",
      "128 BBBP\n",
      "256 BBBP\n",
      "512 BBBP\n",
      "1024 BBBP\n",
      "2048 BBBP\n",
      "4096 BBBP\n"
     ]
    }
   ],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "\n",
    "file_path = \"/raid/shenwanxiang/08_Robustness/dataset_induces/split\"\n",
    "random_seeds = [2, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
    "\n",
    "\n",
    "task_name = 'BBBP'\n",
    "\n",
    "\n",
    "for seed in random_seeds:\n",
    "    \n",
    "    train_path = os.path.join(file_path, task_name,\"%s\" % seed, \"train.csv\")\n",
    "    valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"val.csv\")\n",
    "    test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"test.csv\")\n",
    "\n",
    "    pred_valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_pred_val.csv\")\n",
    "    pred_test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_pred_test.csv\")\n",
    "    \n",
    "    saved_valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_saved_val.csv\")\n",
    "    saved_test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_saved_test.csv\")\n",
    "    \n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_valid = pd.read_csv(valid_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    print(seed, task_name)\n",
    "    if (os.path.exists(pred_test_path)) & (os.path.exists(pred_valid_path)):\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    test_df = remained_df[remained_df.smiles.isin(df_test.smiles)].reset_index(drop=True)\n",
    "    valid_df = remained_df[remained_df.smiles.isin(df_valid.smiles)].reset_index(drop=True)\n",
    "    train_df = remained_df[remained_df.smiles.isin(df_train.smiles)].reset_index(drop=True)\n",
    "\n",
    "    weights = []\n",
    "    for i,task in enumerate(tasks):    \n",
    "        negative_df = train_df[train_df[task] == 0][[\"smiles\",task]]\n",
    "        positive_df = train_df[train_df[task] == 1][[\"smiles\",task]]\n",
    "        weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                        (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "\n",
    "    print(len(train_df),len(valid_df),len(test_df),)\n",
    "\n",
    "    x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "    num_atom_features = x_atom.shape[-1]\n",
    "    num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "    loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight)) for weight in weights]\n",
    "    model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "                fingerprint_dim, output_units_num, p_dropout)\n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "    best_param ={}\n",
    "    best_param[\"roc_epoch\"] = 0\n",
    "    best_param[\"loss_epoch\"] = 0\n",
    "    best_param[\"valid_roc\"] = 0\n",
    "    best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "    for epoch in range(epochs):    \n",
    "        train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "        valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "        train_roc_mean = np.array(train_roc).mean()\n",
    "        valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "        if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "            best_param[\"roc_epoch\"] = epoch\n",
    "            best_param[\"valid_roc\"] = valid_roc_mean\n",
    "            if valid_roc_mean > 0.78:\n",
    "                 torch.save(model, '/raid/shenwanxiang/08_Robustness/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "\n",
    "        if valid_loss < best_param[\"valid_loss\"]:\n",
    "            best_param[\"loss_epoch\"] = epoch\n",
    "            best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "        print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "            +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "            +\"valid_roc\"+\":\"+str(valid_roc)+'\\n')\n",
    "        if epoch - best_param[\"roc_epoch\"] > 10:        \n",
    "            break\n",
    "\n",
    "        train(model, train_df, optimizer, loss_function)\n",
    "\n",
    "    # evaluate model\n",
    "    best_model = torch.load('/raid/shenwanxiang/08_Robustness/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "    test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "    print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "          +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "          +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "         )\n",
    "\n",
    "\n",
    "    pred_test = predict(best_model, test_df)\n",
    "    pd.DataFrame(pred_test, index = test_df['smiles'],\n",
    "                 columns = [tasks]).to_csv(pred_test_path)\n",
    "\n",
    "    pd.DataFrame(test_df[tasks].values, index = test_df['smiles'],\n",
    "                 columns = [tasks]).to_csv(saved_test_path)\n",
    "\n",
    "    pred_valid = predict(best_model, valid_df)\n",
    "    pd.DataFrame(pred_valid, index = valid_df['smiles'], \n",
    "                 columns = [tasks]).to_csv(pred_valid_path)\n",
    "\n",
    "    pd.DataFrame(valid_df[tasks].values, index = valid_df['smiles'],\n",
    "                 columns = [tasks]).to_csv(saved_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
