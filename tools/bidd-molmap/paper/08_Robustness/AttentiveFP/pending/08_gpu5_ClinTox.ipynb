{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sxh/Research/AttentiveFP/code',)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(y_pred_list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1484\n",
      "not successfully processed smiles:  [NH4][Pt]([NH4])(Cl)Cl\n",
      "not successfully processed smiles:  c1ccc(cc1)n2c(=O)c(c(=O)n2c3ccccc3)CCS(=O)c4ccccc4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [23:56:53] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "RDKit ERROR: [23:56:53] Can't kekulize mol.  Unkekulized atoms: 9\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [23:56:53] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "RDKit ERROR: [23:56:53] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "RDKit ERROR: [23:56:53] Can't kekulize mol.  Unkekulized atoms: 4\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [23:56:53] Can't kekulize mol.  Unkekulized atoms: 4\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  Cc1cc2c(cc1C)N3C=N2[Co+]456(N7=C8[C@H](C(C7=CC9=N4C(=C(C1=N5[C@@]([C@@H]2N6C(=C8C)[C@@]([C@H]2CC(=O)N)(CCC(=O)NC[C@H](OP(=O)(O[C@@H]2[C@H](O[C@H]3[C@@H]2O)CO)[O-])C)C)([C@@]([C@@H]1CCC(=O)N)(C)CC(=O)N)C)C)[C@@]([C@@H]9CCC(=O)N)(C)CC(=O)N)(C)C)CCC(=O)N)O\n",
      "not successfully processed smiles:  Cc1cc2c(cc1C)N3C=N2[Co]456(N7=C8[C@H](C(C7=CC9=N4C(=C(C1=N5[C@@]([C@@H]2N6C(=C8C)[C@@]([C@H]2CC(=O)N)(CCC(=O)NC[C@H](OP(=O)(O[C@@H]2[C@H](O[C@H]3[C@@H]2O)CO)O)C)C)([C@@]([C@@H]1CCC(=O)N)(C)CC(=O)N)C)C)[C@@]([C@@H]9CCC(=O)N)(C)CC(=O)N)(C)C)CCC(=O)N)C#N\n",
      "not successfully processed smiles:  CCCCc1c(=O)n(n(c1=O)c2ccc(cc2)O)c3ccccc3\n",
      "not successfully processed smiles:  CCCCc1c(=O)n(n(c1=O)c2ccccc2)c3ccccc3\n",
      "number of successfully processed smiles:  1478\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAC/CAYAAAB+KF5fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXgUlEQVR4nO3df1CT9x0H8DdICA1QB17Azh5WbxIY8kPcOlHW08HVyJziKaCeWE5nV8v1Vryzh7Pc7Yc9Os2c7tBbdR1zHuOYHV7mPFGhXv+YPzZ/MjWFwljtzgKpdECAPEnIsz84nhITk/AQSIjv15135ft88vh9vilvn+/zPPkmRBRFEURENC6h/u4AEdF0xPAkIpKB4UlEJAPDk4hIBoYnEZEMDE8iIhkYnkREMoT5uwO+8OWXA7DbPT+uOmtWFB49Mk1Bj2gsjrv/cOzlCw0NQUxM5BO3B0V42u2iV+E5WktTj+PuPxz7ycFpOxGRDAxPIiIZGJ5ERDIwPImIZAiKG0bTnc0OCFab2xqlIgxh/KeOKGAwPAOAYLXhn4YutzXfTo5HmJJvF1Gg4LkMEZEMDE8iIhkYnkREMjA8iYhk8Bie//rXv1BaWooVK1YgLS0Ny5Ytw/bt23Hz5k2n2ps3b2LTpk1IT0/HsmXLsG/fPgwNDTnVWSwWHDhwANnZ2UhLS0NhYSGuXLnimyMiIpoCHsPzs88+w/DwMAoKClBRUYHt27ejp6cHW7Zswd///nepzmAwoKSkBIIgoLy8HBs2bEBdXR3Kysqc9lleXo4TJ05gzZo12Lt3L0JDQ7Fjxw7cunXLt0dHRDRJQuR8e+bQ0BByc3OxcOFCvPfeewCAHTt2oKWlBefOnUNk5MhKJKdOncLbb7+NP/zhD8jKygIANDc3o6CgAHv27EFJSQkAQBAErF69GnFxcaipqRn3QTx6ZPJq8QO1OhpGY/+49z/ZBgTvHlWKnKaPKgXquD8NOPbyhYaGYNasqCdvl7PTZ555BrGxsejr6wMAmEwmXL58Gfn5+VJwAsDatWuhUqlw7tw5qa2hoQEKhQIFBQVSm1KpxIYNG3Djxg10d3fL6RIR0ZTyOjxNJhN6enrw73//GwcPHkRra6t0NtnS0gKbzYaFCxc6vCY8PBzJyckwGAxSm8FgwLx58xxCFgDS0tIgiqJDLRFRoPJ6HviTn/wE58+fBwAoFAps3LgRr732GgDAaDQCANRqtdPr1Go1bt++Lf1sNBoRHx/vsg4AzzyJaFrwOjxLS0tRVFSEzs5O6PV6WCwWWK1WhIeHw2w2Axg503ycUqmUtgOA2WyGQqFwWQeMXP8cL3fXJR6nVkePe/+TTewZRHRUhNsalUoJdaxqinrke4E47k8Ljv3k8Do8NRoNNBoNAGDNmjVYv3499uzZg9/85jeIiBj5xbdYLE6vEwRB2g4AERERsFqtLuuAr0J0PKb7DaNBwYZ+k9l9zaAA4/DwFPXItwJ13J8GHHv5JuWGkUKhQE5ODi5cuACz2SxNuUen72MZjUbExcVJP6vVapdT89HXjq0lIgpUsj9hZDabIYoiBgYGkJiYiLCwMNy9e9ehxmKxwGAwIDk5WWpLSkpCR0cHBgYGHGrv3LkjbSciCnQew7Onp8epzWQy4fz583juuecwa9YsREdHIysrC3q93iEU9Xo9BgcHodVqpTatVgur1YpTp05JbRaLBfX19cjMzHR5M4mIKNB4vOb55ptvQqlUYtGiRVCr1fj8889RX1+Pzs5OHDx4UKorKyvDxo0bUVxcjIKCAnR2dqK6uhovvfQSli5dKtWlp6dDq9VCp9PBaDQiISEBp0+fxsOHD1FZWTk5R0lE5GMeP2H0wQcfQK/Xo62tDX19fYiOjkZGRga2bduGF1980aH2+vXr0Ol0uH//PqKiopCXl4ddu3ZBpXK8SywIAg4dOoQzZ86gt7cXGo0Gu3btcgjZ8ZjuN4z4CSOaLBx7+TzdMJL18cxAw/AMbIE67k8Djr18k3K3nYjoacfwJCKSgeFJRCQDw5OISAaGJxGRDNPz9u00YrOPfC+7O148KEBEAYbhOckEq+fHkNITnZfyI6LAxmk7EZEMDE8iIhkYnkREMjA8iYhkYHgSEcnA8CQikoHhSUQkA8OTiEgGhicRkQwMTyIiGRieREQyMDyJiGRgeBIRycDwJCKSgeFJRCQDw5OISAaGJxGRDAxPIiIZGJ5ERDIwPImIZGB4EhHJwPAkIpKB4UlEJIPH8GxubsbPfvYz5OXlISMjA8uXL0dZWRk+/fRTp9qbN29i06ZNSE9Px7Jly7Bv3z4MDQ051VksFhw4cADZ2dlIS0tDYWEhrly54psjIiKaAh7D83e/+x0uXryIpUuXYu/evSgsLMQ//vEP5Ofno729XaozGAwoKSmBIAgoLy/Hhg0bUFdXh7KyMqd9lpeX48SJE1izZg327t2L0NBQ7NixA7du3fLt0RERTZIwTwUlJSXQ6XQIDw+X2vLy8vCDH/wAx48fx7vvvgsAOHjwIL72ta/h5MmTiIyMBAA8//zzePvtt3HlyhVkZWUBGDmTPXv2LPbs2YOSkhIAQH5+PlavXg2dToeamhpfHyMRkc95PPPMzMx0CE4AeOGFF7BgwQLpzNNkMuHy5cvIz8+XghMA1q5dC5VKhXPnzkltDQ0NUCgUKCgokNqUSiU2bNiAGzduoLu7e8IHRUQ02WTdMBJFEV988QViYmIAAC0tLbDZbFi4cKFDXXh4OJKTk2EwGKQ2g8GAefPmOYQsAKSlpUEURYdaIqJA5XHa7spf//pXdHV1SdczjUYjAECtVjvVqtVq3L59W/rZaDQiPj7eZR0AWWees2ZFeV2rVkePe/8TIfYMIjoqwm2NQhHmsUalUkIdq/Jl16bUVI87fYVjPznGHZ7t7e34+c9/jsWLF2Pt2rUAALPZDABO03tgZEo+un20VqFQuKwDAEEQxtslPHpkgt0ueqxTq6NhNPaPe/8TMSjY0G8yu62xWj3XDA4KMA4P+7JrU8Yf404jOPbyhYaGuD0xG9e03Wg04kc/+hFmzpyJw4cPIzR05OURESNnTRaLxek1giBI20drrVaryzrgqxAlIgpkXp959vf3Y8eOHejv70dtba3DFH30v0en72MZjUbExcU51Lqamo++dmwtEVGg8urMUxAEvPbaa/jPf/6D9957D/Pnz3fYnpiYiLCwMNy9e9eh3WKxwGAwIDk5WWpLSkpCR0cHBgYGHGrv3LkjbSciCnQew3N4eBhvvvkmbt++jcOHDyMjI8OpJjo6GllZWdDr9Q6hqNfrMTg4CK1WK7VptVpYrVacOnVKarNYLKivr0dmZqbLm0lERIHG47T93XffxYcffogVK1bgf//7H/R6vbQtMjISubm5AICysjJs3LgRxcXFKCgoQGdnJ6qrq/HSSy9h6dKl0mvS09Oh1Wqh0+lgNBqRkJCA06dP4+HDh6isrJyEQwwOIaEhGBBsHuuUijCEccUCoknnMTw//vhjAMClS5dw6dIlh21z5syRwjMlJQXV1dXQ6XSorKxEVFQUCgsLsWvXLqd97t+/H4cOHYJer0dvby80Gg2OHTuGxYsX++KYgpJgHcadVudryo/7dnI8wpSynkAjonEIEUXR8zM+AS6QH1UaEGz4p6HLbU16otpjMHpTA4yEZ2SAhScfl/Efjr18Pn1UiYiIRjA8iYhkCKz5HU2YNzeWeFOJaOIYnkHGmxtLvKlENHE8/yAikoHhSUQkA+duE2CzA4LV/fVFL56gIqJpiOE5AYLVu2c4iSj4cNpORCQDw5OISAaGJxGRDAxPIiIZGJ5ERDIwPImIZGB4EhHJwPAkIpKB4UlEJAPDk4hIBoYnEZEMDE8iIhkYnkREMjA8iYhkYHgSEcnA8CQikoHhSUQkA8OTiEgGhicRkQwMTyIiGRieREQyeBWe3d3d0Ol0KC4uxqJFi6DRaHDt2jWXtU1NTVi3bh1SU1OxfPlyVFVVwWZz/nrevr4+VFRUYMmSJcjIyMDWrVthMBgmdjRERFPEq/Ds6OjA8ePH0dXVBY1G88S6jz76CKWlpZg5cyYqKiqQm5uLI0eOoLKy0qHObrfj1VdfxdmzZ7Flyxbs3r0bjx49QnFxMR48eDCxIyIimgJefW97SkoKrl69ipiYGDQ2NqK0tNRl3f79+/HNb34T77//PmbMmAEAiIyMxLFjx1BcXIwXXngBANDQ0IBbt27hyJEjyM3NBQCsWrUKK1euRFVVFfbv3++DQyMimjxenXlGRUUhJibGbU1bWxva2tpQVFQkBScAbN68GXa7HRcuXJDazp8/j7i4OOTk5EhtsbGxWLVqFRobG2G1Wsd7HEREU8pnN4zu378PAFi4cKFDe3x8PGbPni1tBwCDwYCUlBSEhIQ41KampmJgYIBTdyIKeD4LT6PRCABQq9VO29RqNbq7ux1q4+LinOpG28bWEhEFIq+ueXrDbDYDAMLDw522KZVKDA0NOdS6qhttG92Xt2bNivK6Vq2OHte+3RF7BhEdFeG2RqEIm7Iab+tUKiXUsSqP+/IlX447jQ/HfnL4LDwjIkZ+YS0Wi9M2QRCk7aO1rupG28bWeuPRIxPsdtFjnVodDaOxf1z7dmdQsKHf5D7ordapq/G2bnBQgHF42OO+fMXX407e49jLFxoa4vbEzGfT9tHp+uj0fazHp+mPT+NHjba5mtITEQUSn4VncnIyAODu3bsO7V1dXejs7JS2A0BSUhLu3bsHUXQ8W2xuboZKpUJCQoKvukVENCl8Fp4LFizA/PnzUVdXh+ExU8La2lqEhobi5Zdfltq0Wi26u7vR1NQktfX09KChoQE5OTlQKBS+6hYR0aTw+prn0aNHAQDt7e0AAL1ejxs3buDZZ5/Fli1bAABvvfUWdu7cie3btyMvLw+tra2oqalBUVER5s2bJ+1r5cqVyMjIwFtvvYVt27YhJiYGtbW1sNvteOONN3x5fORCSGgIBgTnj8yOpVSEIYwrHxA9kdfhefjwYYef//KXvwAA5syZI4XnihUrUFVVhaqqKvziF79AbGwsdu7ciddff93htTNmzMCxY8ewf/9+nDx5EoIgIDU1Fb/85S8xd+7ciR4TeSBYh3Gn1fna9FjfTo5HmNJn9xOJgo7Xvx0tLS1e1eXm5kofuXRn5syZeOedd/DOO+942wUiooDBiRkRkQwMTyIiGRieREQyMDyJiGRgeBIRycBnUZ7AZgcEq/tnIb34OD0RBSmG5xMIVhv+aehyW5Oe6Lz8HhE9HThtJyKSgeFJRCQDw5OISAaGJxGRDAxPIiIZGJ5ERDLwUSVyiWt+ErnH8CSXuOYnkXs8byAikoHhSUQkA8OTiEgGhicRkQxP5dV+rphERBP1VIYnV0wioonitJ2ISAaGJxGRDAxPIiIZGJ5ERDIwPImIZGB4EhHJwPAkIpLhqXzOk3zD22XriIIR/88m2bxZtu7FlNno7hnEoJuQ5bqgNB35LTwtFgsOHz4MvV6Pvr4+JCUloaysDFlZWf7qEk0CwToMw6fd6DeZn1jzYspsCFb3n4dlwFKg8Vt4lpeX48KFC9i6dSvmzp2L06dPY8eOHTh58iQWLVrkr26RH/hq4WVv1ixgCJOv+CU8m5ubcfbsWezZswclJSUAgPz8fKxevRo6nQ41NTX+6BYFMG+ur9pF4MbH7tcsCMQQZuhPT34Jz4aGBigUChQUFEhtSqUSGzZswK9//Wt0d3cjLi7OH12jAOXN2ak3i7lMZQgD3q/g5env46WNwOOX8DQYDJg3bx4iIyMd2tPS0iCKIgwGw7jCMzQ0ZFy1YTNCoYpQuK2bjjWB2KewGaF4RhmGYduT66ayP8N2EYaOHrc1yfNiPf9dihkQbHa3NcBIMN7zwd/nTb/TE9UYtjkG7Bf/G3LoZ3jYDMzwQcAO2wGLbdhtTVjYDNg81PiqP5PBU66EiKI45StXrl69GvHx8Xj//fcd2tva2vD9738f+/btczgrJSIKNH7JfLPZDIXC+V9apVIJABAEYaq7REQ0Ln4Jz4iICFitVqf20dAcDVEiokDll/BUq9Xo7u52ajcaR24I8GYREQU6v4RnUlISOjo6MDAw4NB+584daTsRUSDzS3hqtVpYrVacOnVKarNYLKivr0dmZibi4+P90S0iIq/55VGl9PR0aLVa6HQ6GI1GJCQk4PTp03j48CEqKyv90SUionHxy6NKwMjNoUOHDuHMmTPo7e2FRqPBrl27sHTpUn90h4hoXPwWnkRE01mAPttPRBTYGJ5ERDIEfXhaLBYcOHAA2dnZSEtLQ2FhIa5cueLvbgWNa9euQaPRuPzT3t7uUHvz5k1s2rQJ6enpWLZsGfbt24ehoSE/9Xx66e7uhk6nQ3FxMRYtWgSNRoNr1665rG1qasK6deuQmpqK5cuXo6qqCjab8+IkfX19qKiowJIlS5CRkYGtW7fCYDBM9qEEjaBfSZ7rhk6NV155BSkpKQ5tYx85MxgMKCkpwTe+8Q2Ul5ejs7MTv//97/Hf//4Xv/3tb6e6u9NOR0cHjh8/jrlz50Kj0eDWrVsu6z766COUlpZiyZIlqKioQGtrK44cOYIvv/wSFRUVUp3dbserr76K1tZWbNu2DTExMfjTn/6E4uJi1NfXIyEhYaoObfoSg9idO3fExMREsbq6Wmozm81ibm6uuHnzZv91LIhcvXpVTExMFC9evOi27oc//KH43e9+VzSZTFLbn//8ZzExMVG8fPnyZHdz2uvv7xd7enpEURTFixcviomJieLVq1ed6vLy8sR169aJNptNajt48KCYlJQkdnR0SG1nz551et8ePXokfutb3xJ37949eQcSRIJ62u5u3dAbN264/IgoyWcymVxOD00mEy5fvoz8/HyHZQjXrl0LlUqFc+fOTWU3p6WoqCjExMS4rWlra0NbWxuKioowY8YMqX3z5s2w2+24cOGC1Hb+/HnExcUhJydHaouNjcWqVavQ2Njocu0JchTU4enNuqHkG7t378bixYuRnp6Obdu2oaWlRdrW0tICm82GhQsXOrwmPDwcycnJfB985P79+wDgNM7x8fGYPXu2tB0Y+d1ISUlBSIjjmpWpqakYGBjAgwcPJr/D01xQh6fRaHS5yIhaPbLiOM88J06hUGDlypXYu3cvjh49itLSUjQ3N2Pz5s3o6OgA8NWCL6PjPtaTFomh8RvPOD/pd2O0je+JZ0F9w4jrhk6+zMxMZGZmSj/n5OTge9/7HtavX4+qqir86le/gtk88s2Z4eHhTq9XKpXSdpoYT+M89skGs9nssm60je+JZ0F95sl1Q/0jKSkJWVlZuHr1KoCR9wEYeWzscYIgSNtpYsYzzhERES7rRtv4nngW1OHJdUP957nnnkNvby+Ar6aRo+M+1pOmjzR+4xnnJ/1ujLbxPfEsqMOT64b6z2effSbdHU5MTERYWBju3r3rUGOxWGAwGJCcnOyPLgad0XF8fJy7urrQ2dnpMM5JSUm4d+8exMeWtmhuboZKpeJznl4I6vDkuqGTr6fH+Rsdr1+/jmvXriE7OxsAEB0djaysLOj1eod/yPR6PQYHB6HVaqesv8FswYIFmD9/Purq6jA8/NW3VtbW1iI0NBQvv/yy1KbVatHd3Y2mpiapraenBw0NDcjJyXF5r4AcBf2qSj/+8Y/R1NSEV155RVo39O7duzhx4gQWL17s7+5Ne1u3bsUzzzyDRYsWISYmBp988gnq6uoQHR2NDz74AF//+tcBAPfu3cPGjRuxYMECFBQUoLOzE9XV1fjOd76D48eP+/kopoejR48CANrb2/G3v/0N69evx/PPP49nn30WW7ZsAQBcunQJO3fuxJIlS5CXl4fW1lbU1NSgqKgIP/3pT6V9DQ8PY/Pmzfjkk0+kTxjV1tbi888/R319PebOneuPQ5xWgj48uW7o5PrjH/+IM2fO4MGDBzCZTIiNjUV2djbeeOMNKThHXb9+HTqdDvfv30dUVBTy8vKwa9cuqFQqP/V+etFoNC7b58yZgw8//FD6ubGxEVVVVWhvb0dsbCzWr1+P119/HWFhjg/X9Pb2Yv/+/WhsbIQgCEhNTUV5ebnTx2zJtaAPTyKiyRDU1zyJiCYLw5OISAaGJxGRDAxPIiIZGJ5ERDIwPImIZGB4EhHJwPAkIpKB4UlEJAPDk4hIhv8DeXRf3J2Kk7gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = [ 'FDA_APPROVED','CT_TOX']\n",
    "raw_filename = \"/home/sxh/Research/AttentiveFP/data/clintox.csv\"\n",
    "\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 888\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.5\n",
    "fingerprint_dim = 200\n",
    "\n",
    "radius = 3\n",
    "T = 3\n",
    "weight_decay = 3 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>FDA_APPROVED</th>\n",
       "      <th>CT_TOX</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Se]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Se]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C(#N)[Fe-2](C#N)(C#N)(C#N)(C#N)N=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                smiles  FDA_APPROVED  CT_TOX  \\\n",
       "12                                [Se]             0       1   \n",
       "20  C(#N)[Fe-2](C#N)(C#N)(C#N)(C#N)N=O             1       0   \n",
       "\n",
       "                         cano_smiles  \n",
       "12                              [Se]  \n",
       "20  N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<151]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "32 0\n",
      "32 1\n",
      "32 2\n",
      "32 3\n",
      "32 4\n",
      "128 0\n",
      "128 1\n",
      "128 2\n",
      "128 3\n",
      "128 4\n",
      "512 0\n",
      "512 1\n",
      "512 2\n",
      "512 3\n",
      "512 4\n",
      "1024 0\n",
      "1024 1\n",
      "1024 2\n",
      "1024 3\n",
      "1024 4\n"
     ]
    }
   ],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "task_name = 'ClinTox'\n",
    "\n",
    "\n",
    "for seed in [2, 32, 128, 512, 1024]:\n",
    "    for fold in [0,1,2,3,4]: #\n",
    "        \n",
    "        print(seed, fold)\n",
    "        df_test = pd.read_csv('./%s/seed_%s/fold_%s/test.csv' % (task_name, seed, fold))\n",
    "        df_valid = pd.read_csv('./%s/seed_%s/fold_%s/valid.csv' % (task_name,seed,  fold))\n",
    "        df_train = pd.read_csv('./%s/seed_%s/fold_%s/train.csv' % (task_name,seed, fold))\n",
    "\n",
    "        pred = './%s/seed_%s/fold_%s/pred_test.csv' % (task_name, seed, fold)\n",
    "        pred2 = './%s/seed_%s/fold_%s/pred_valid.csv' % (task_name,seed,  fold)\n",
    "        if (os.path.exists(pred)) & (os.path.exists(pred2)):\n",
    "            continue\n",
    "\n",
    "        test_df = remained_df[remained_df.smiles.isin(df_test.smiles)].reset_index(drop=True)\n",
    "        valid_df = remained_df[remained_df.smiles.isin(df_valid.smiles)].reset_index(drop=True)\n",
    "        train_df = remained_df[remained_df.smiles.isin(df_train.smiles)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        print(len(train_df),len(valid_df),len(test_df),)\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "        num_atom_features = x_atom.shape[-1]\n",
    "        num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "        loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight)) for weight in weights]\n",
    "        model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "                    fingerprint_dim, output_units_num, p_dropout)\n",
    "        model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "        best_param ={}\n",
    "        best_param[\"roc_epoch\"] = 0\n",
    "        best_param[\"loss_epoch\"] = 0\n",
    "        best_param[\"valid_roc\"] = 0\n",
    "        best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "        for epoch in range(epochs):    \n",
    "            train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "            valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "            train_roc_mean = np.array(train_roc).mean()\n",
    "            valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "            if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "                best_param[\"roc_epoch\"] = epoch\n",
    "                best_param[\"valid_roc\"] = valid_roc_mean\n",
    "                if valid_roc_mean > 0.68:\n",
    "                     torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "\n",
    "            if valid_loss < best_param[\"valid_loss\"]:\n",
    "                best_param[\"loss_epoch\"] = epoch\n",
    "                best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "            print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "                +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "                +\"valid_roc\"+\":\"+str(valid_roc)+'\\n')\n",
    "            if epoch - best_param[\"roc_epoch\"] > 15:        \n",
    "                break\n",
    "\n",
    "            train(model, train_df, optimizer, loss_function)\n",
    "\n",
    "        # evaluate model\n",
    "        best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "        test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "        print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "              +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "              +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "             )\n",
    "\n",
    "        pred_test = predict(best_model, test_df)\n",
    "        \n",
    "        pd.DataFrame(pred_test, index = test_df['smiles'],\n",
    "                     columns = [tasks]).to_csv('./%s/seed_%s/fold_%s/pred_test.csv' % (task_name, seed, fold))\n",
    "\n",
    "        pd.DataFrame(test_df[tasks].values, index = test_df['smiles'],\n",
    "                     columns = [tasks]).to_csv('./%s/seed_%s/fold_%s/test.csv' % (task_name,seed,  fold))\n",
    "\n",
    "        pred_valid = predict(best_model, valid_df)\n",
    "        pd.DataFrame(pred_valid, index = valid_df['smiles'], \n",
    "                     columns = [tasks]).to_csv('./%s/seed_%s/fold_%s/pred_valid.csv' % (task_name, seed, fold))\n",
    "\n",
    "        pd.DataFrame(valid_df[tasks].values, index = valid_df['smiles'],\n",
    "                     columns = [tasks]).to_csv('./%s/seed_%s/fold_%s/valid.csv' % (task_name, seed,  fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
