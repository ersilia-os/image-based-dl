{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [00:10:04] Enabling RDKit 2019.09.2 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "np.random.seed(7)\n",
    "tf.compat.v1.set_random_seed(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_feature_dir = './tmpignore'\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 16896\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "from molmap import dataset\n",
    "data = dataset.load_CYP450()\n",
    "df = data.data\n",
    "X_smiles = df.smiles.tolist()\n",
    "task_name = 'CYP450'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16896, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASK = -1\n",
    "tasks = ['label_1a2', 'label_2c19', 'label_2c9', 'label_2d6', 'label_3a4']\n",
    "Y = df[tasks].astype('float').fillna(MASK).values\n",
    "if Y.shape[1] == 0:\n",
    "    Y = Y.reshape(-1, 1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')\n",
    "\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfor a 10 fold Cross-validation to find best epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10, shuffle=True, random_state=123)\n",
    "\n",
    "train_valid_idx = df[df.group != 'test set'].index.tolist()\n",
    "test_idx = df[df.group == 'test set'].index.tolist()\n",
    "testX = (X1[test_idx], X2[test_idx])\n",
    "testY = Y[test_idx]\n",
    "\n",
    "def get_pos_weights(trainY):\n",
    "    \"\"\"pos_weights: neg_n / pos_n \"\"\"\n",
    "    dfY = pd.DataFrame(trainY)\n",
    "    pos = dfY == 1\n",
    "    pos_n = pos.sum(axis=0)\n",
    "    neg = dfY == 0\n",
    "    neg_n = neg.sum(axis=0)\n",
    "    pos_weights = (neg_n / pos_n).values\n",
    "    neg_weights = (pos_n / neg_n).values\n",
    "    return pos_weights, neg_weights\n",
    "\n",
    "pos_weights, neg_weights = get_pos_weights(Y[train_valid_idx])\n",
    "\n",
    "epochs = 800\n",
    "patience = 10 #early stopping\n",
    "\n",
    "dense_layers = [256, 128, 32]\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "monitor = 'val_auc'\n",
    "metric = 'ROC'\n",
    "dense_avf = 'relu'\n",
    "last_avf = None #sigmoid in loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 fold-cv performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "i = 0\n",
    "for train_idx, valid_idx in kf.split(train_valid_idx):\n",
    "    \n",
    "    filename = 'model-fold-%s.csv' % str(i).zfill(2)\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "    opt = tfa.optimizers.AdamW(weight_decay = 0.0,learning_rate=lr,beta_1=0.9,beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "    performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                (validX, validY), \n",
    "                                                                patience = patience,\n",
    "                                                                metric = metric,\n",
    "                                                                criteria = monitor)\n",
    "\n",
    "    model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs=epochs, verbose= 0, shuffle = True, \n",
    "              validation_data = (validX, validY), \n",
    "              callbacks=[performance]) \n",
    "\n",
    "\n",
    "    best_epoch = performance.best_epoch\n",
    "    train_pfs = performance.evaluate(trainX, trainY)            \n",
    "    valid_pfs = performance.evaluate(validX, validY)            \n",
    "    final_res = {    'fold':i,\n",
    "                     'task_name':task_name,            \n",
    "                     'train_pfs':train_pfs, \n",
    "                     'metric': metric,\n",
    "                     'valid_pfs':valid_pfs,                      \n",
    "                     'best_epoch': best_epoch,\n",
    "                     'batch_size':batch_size,\n",
    "                     'trainable_params': model.count_params(),\n",
    "                     'lr': lr,\n",
    "                     'weight_decay':weight_decay\n",
    "                    }\n",
    "    \n",
    "    \n",
    "    pd.DataFrame([final_res]).to_csv(filename)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the final model using the same Hyperparameters, and test on the external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_pfs</th>\n",
       "      <th>metric</th>\n",
       "      <th>valid_pfs</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9874567195572976, 0.9738906675505736, 0.990...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9490147443847321, 0.8935858711631306, 0.908...</td>\n",
       "      <td>61</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9741909012094102, 0.9501959277403189, 0.976...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9507553234977144, 0.9131923439881918, 0.927...</td>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9794194858383412, 0.9712625715859213, 0.985...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9456466250709019, 0.911163739385852, 0.9278...</td>\n",
       "      <td>56</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9624161673656005, 0.936330747601789, 0.9508...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9486500259610392, 0.8955121766022572, 0.908...</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9695334924093093, 0.9466458384578187, 0.965...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9438940878882017, 0.8930659049511509, 0.910...</td>\n",
       "      <td>41</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9759679586157101, 0.9586982189110491, 0.975...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.944468861249066, 0.9071703424840086, 0.9149...</td>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9817337929595712, 0.9629797182474445, 0.977...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9375272350933257, 0.9001070181367579, 0.922...</td>\n",
       "      <td>53</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9839607916934181, 0.9674159823631325, 0.987...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.946979019942175, 0.8919884270651575, 0.9216...</td>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9815696344422685, 0.9640635372888541, 0.980...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9383434758168977, 0.9018265212849308, 0.920...</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>CYP450</td>\n",
       "      <td>[0.9860715012616572, 0.9789726263249825, 0.991...</td>\n",
       "      <td>ROC</td>\n",
       "      <td>[0.9489664831449822, 0.8941442162924048, 0.912...</td>\n",
       "      <td>61</td>\n",
       "      <td>128</td>\n",
       "      <td>803813</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold task_name                                          train_pfs metric  \\\n",
       "0     0    CYP450  [0.9874567195572976, 0.9738906675505736, 0.990...    ROC   \n",
       "0     1    CYP450  [0.9741909012094102, 0.9501959277403189, 0.976...    ROC   \n",
       "0     2    CYP450  [0.9794194858383412, 0.9712625715859213, 0.985...    ROC   \n",
       "0     3    CYP450  [0.9624161673656005, 0.936330747601789, 0.9508...    ROC   \n",
       "0     4    CYP450  [0.9695334924093093, 0.9466458384578187, 0.965...    ROC   \n",
       "0     5    CYP450  [0.9759679586157101, 0.9586982189110491, 0.975...    ROC   \n",
       "0     6    CYP450  [0.9817337929595712, 0.9629797182474445, 0.977...    ROC   \n",
       "0     7    CYP450  [0.9839607916934181, 0.9674159823631325, 0.987...    ROC   \n",
       "0     8    CYP450  [0.9815696344422685, 0.9640635372888541, 0.980...    ROC   \n",
       "0     9    CYP450  [0.9860715012616572, 0.9789726263249825, 0.991...    ROC   \n",
       "\n",
       "                                           valid_pfs  best_epoch  batch_size  \\\n",
       "0  [0.9490147443847321, 0.8935858711631306, 0.908...          61         128   \n",
       "0  [0.9507553234977144, 0.9131923439881918, 0.927...          46         128   \n",
       "0  [0.9456466250709019, 0.911163739385852, 0.9278...          56         128   \n",
       "0  [0.9486500259610392, 0.8955121766022572, 0.908...          30         128   \n",
       "0  [0.9438940878882017, 0.8930659049511509, 0.910...          41         128   \n",
       "0  [0.944468861249066, 0.9071703424840086, 0.9149...          46         128   \n",
       "0  [0.9375272350933257, 0.9001070181367579, 0.922...          53         128   \n",
       "0  [0.946979019942175, 0.8919884270651575, 0.9216...          54         128   \n",
       "0  [0.9383434758168977, 0.9018265212849308, 0.920...          51         128   \n",
       "0  [0.9489664831449822, 0.8941442162924048, 0.912...          61         128   \n",
       "\n",
       "   trainable_params      lr  weight_decay  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  \n",
       "0            803813  0.0001             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs = glob('./model-*.csv')\n",
    "dfp = pd.concat([pd.read_csv(i, index_col = 0) for i in csvs])\n",
    "dfp = dfp.sort_values('fold')\n",
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.valid_pfs = dfp.valid_pfs.apply(lambda x:[float(i.replace('[','').replace(']','')) for i in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1a2</th>\n",
       "      <th>label_2c19</th>\n",
       "      <th>label_2c9</th>\n",
       "      <th>label_2d6</th>\n",
       "      <th>label_3a4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.949015</td>\n",
       "      <td>0.893586</td>\n",
       "      <td>0.908405</td>\n",
       "      <td>0.885345</td>\n",
       "      <td>0.908443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.950755</td>\n",
       "      <td>0.913192</td>\n",
       "      <td>0.927266</td>\n",
       "      <td>0.878216</td>\n",
       "      <td>0.923830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.945647</td>\n",
       "      <td>0.911164</td>\n",
       "      <td>0.927832</td>\n",
       "      <td>0.887480</td>\n",
       "      <td>0.916079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.948650</td>\n",
       "      <td>0.895512</td>\n",
       "      <td>0.908302</td>\n",
       "      <td>0.888027</td>\n",
       "      <td>0.908995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.943894</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>0.910136</td>\n",
       "      <td>0.899558</td>\n",
       "      <td>0.907428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.944469</td>\n",
       "      <td>0.907170</td>\n",
       "      <td>0.914973</td>\n",
       "      <td>0.883796</td>\n",
       "      <td>0.896696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.937527</td>\n",
       "      <td>0.900107</td>\n",
       "      <td>0.922658</td>\n",
       "      <td>0.906264</td>\n",
       "      <td>0.911466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.946979</td>\n",
       "      <td>0.891988</td>\n",
       "      <td>0.921601</td>\n",
       "      <td>0.893148</td>\n",
       "      <td>0.915804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.938343</td>\n",
       "      <td>0.901827</td>\n",
       "      <td>0.920993</td>\n",
       "      <td>0.889568</td>\n",
       "      <td>0.923266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.948966</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.912266</td>\n",
       "      <td>0.877357</td>\n",
       "      <td>0.920157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_1a2  label_2c19  label_2c9  label_2d6  label_3a4\n",
       "0   0.949015    0.893586   0.908405   0.885345   0.908443\n",
       "1   0.950755    0.913192   0.927266   0.878216   0.923830\n",
       "2   0.945647    0.911164   0.927832   0.887480   0.916079\n",
       "3   0.948650    0.895512   0.908302   0.888027   0.908995\n",
       "4   0.943894    0.893066   0.910136   0.899558   0.907428\n",
       "5   0.944469    0.907170   0.914973   0.883796   0.896696\n",
       "6   0.937527    0.900107   0.922658   0.906264   0.911466\n",
       "7   0.946979    0.891988   0.921601   0.893148   0.915804\n",
       "8   0.938343    0.901827   0.920993   0.889568   0.923266\n",
       "9   0.948966    0.894144   0.912266   0.877357   0.920157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performances = pd.DataFrame(dfp.valid_pfs.to_list(), columns= tasks)\n",
    "cv_performances.to_csv('10foldcsv_auc.csv')\n",
    "cv_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_1a2     0.945\n",
       "label_2c19    0.900\n",
       "label_2c9     0.917\n",
       "label_2d6     0.889\n",
       "label_3a4     0.913\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performances.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_1a2     0.005\n",
       "label_2c19    0.008\n",
       "label_2c9     0.008\n",
       "label_2d6     0.009\n",
       "label_3a4     0.008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performances.std().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp.best_epoch.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001, loss: 0.8188 - val_loss: 0.6775; auc: 0.7976 - val_auc: 0.7831                                                                                                    \n",
      "epoch: 0002, loss: 0.7191 - val_loss: 0.6578; auc: 0.8512 - val_auc: 0.8245                                                                                                    \n",
      "epoch: 0003, loss: 0.6716 - val_loss: 0.6498; auc: 0.8698 - val_auc: 0.8368                                                                                                    \n",
      "epoch: 0004, loss: 0.6517 - val_loss: 0.6472; auc: 0.8791 - val_auc: 0.8426                                                                                                    \n",
      "epoch: 0005, loss: 0.6373 - val_loss: 0.6524; auc: 0.8851 - val_auc: 0.8448                                                                                                    \n",
      "epoch: 0006, loss: 0.6304 - val_loss: 0.6563; auc: 0.8899 - val_auc: 0.8481                                                                                                    \n",
      "epoch: 0007, loss: 0.6219 - val_loss: 0.6409; auc: 0.8938 - val_auc: 0.8501                                                                                                    \n",
      "epoch: 0008, loss: 0.6126 - val_loss: 0.6436; auc: 0.8983 - val_auc: 0.8522                                                                                                    \n",
      "epoch: 0009, loss: 0.6042 - val_loss: 0.6415; auc: 0.9025 - val_auc: 0.8528                                                                                                    \n",
      "epoch: 0010, loss: 0.5999 - val_loss: 0.6374; auc: 0.9057 - val_auc: 0.8564                                                                                                    \n",
      "epoch: 0011, loss: 0.5932 - val_loss: 0.6437; auc: 0.9093 - val_auc: 0.8585                                                                                                    \n",
      "epoch: 0012, loss: 0.5849 - val_loss: 0.6350; auc: 0.9123 - val_auc: 0.8612                                                                                                    \n",
      "epoch: 0013, loss: 0.5779 - val_loss: 0.6375; auc: 0.9153 - val_auc: 0.8611                                                                                                    \n",
      "epoch: 0014, loss: 0.5782 - val_loss: 0.6300; auc: 0.9176 - val_auc: 0.8659                                                                                                    \n",
      "epoch: 0015, loss: 0.5714 - val_loss: 0.6399; auc: 0.9205 - val_auc: 0.8659                                                                                                    \n",
      "epoch: 0016, loss: 0.5634 - val_loss: 0.6326; auc: 0.9233 - val_auc: 0.8674                                                                                                    \n",
      "epoch: 0017, loss: 0.5524 - val_loss: 0.6303; auc: 0.9268 - val_auc: 0.8697                                                                                                    \n",
      "epoch: 0018, loss: 0.5491 - val_loss: 0.6478; auc: 0.9302 - val_auc: 0.8711                                                                                                    \n",
      "epoch: 0019, loss: 0.5404 - val_loss: 0.6348; auc: 0.9313 - val_auc: 0.8720                                                                                                    \n",
      "epoch: 0020, loss: 0.5346 - val_loss: 0.6332; auc: 0.9354 - val_auc: 0.8725                                                                                                    \n",
      "epoch: 0021, loss: 0.5324 - val_loss: 0.6242; auc: 0.9370 - val_auc: 0.8764                                                                                                    \n",
      "epoch: 0022, loss: 0.5229 - val_loss: 0.6340; auc: 0.9397 - val_auc: 0.8752                                                                                                    \n",
      "epoch: 0023, loss: 0.5181 - val_loss: 0.6299; auc: 0.9424 - val_auc: 0.8778                                                                                                    \n",
      "epoch: 0024, loss: 0.5109 - val_loss: 0.6266; auc: 0.9458 - val_auc: 0.8798                                                                                                    \n",
      "epoch: 0025, loss: 0.5052 - val_loss: 0.6454; auc: 0.9482 - val_auc: 0.8815                                                                                                    \n",
      "epoch: 0026, loss: 0.4954 - val_loss: 0.6264; auc: 0.9475 - val_auc: 0.8795                                                                                                    \n",
      "epoch: 0027, loss: 0.4959 - val_loss: 0.6366; auc: 0.9522 - val_auc: 0.8818                                                                                                    \n",
      "epoch: 0028, loss: 0.4812 - val_loss: 0.6473; auc: 0.9524 - val_auc: 0.8784                                                                                                    \n",
      "epoch: 0029, loss: 0.4788 - val_loss: 0.6329; auc: 0.9570 - val_auc: 0.8817                                                                                                    \n",
      "epoch: 0030, loss: 0.4717 - val_loss: 0.6347; auc: 0.9583 - val_auc: 0.8808                                                                                                    \n",
      "epoch: 0031, loss: 0.4644 - val_loss: 0.6408; auc: 0.9601 - val_auc: 0.8830                                                                                                    \n",
      "epoch: 0032, loss: 0.4614 - val_loss: 0.6498; auc: 0.9618 - val_auc: 0.8812                                                                                                    \n",
      "epoch: 0033, loss: 0.4520 - val_loss: 0.6311; auc: 0.9637 - val_auc: 0.8827                                                                                                    \n",
      "epoch: 0034, loss: 0.4503 - val_loss: 0.6376; auc: 0.9647 - val_auc: 0.8825                                                                                                    \n",
      "epoch: 0035, loss: 0.4359 - val_loss: 0.6333; auc: 0.9663 - val_auc: 0.8815                                                                                                    \n",
      "epoch: 0036, loss: 0.4348 - val_loss: 0.6423; auc: 0.9685 - val_auc: 0.8836                                                                                                    \n",
      "epoch: 0037, loss: 0.4243 - val_loss: 0.6330; auc: 0.9695 - val_auc: 0.8829                                                                                                    \n",
      "epoch: 0038, loss: 0.4252 - val_loss: 0.6429; auc: 0.9695 - val_auc: 0.8820                                                                                                    \n",
      "epoch: 0039, loss: 0.4175 - val_loss: 0.6425; auc: 0.9722 - val_auc: 0.8846                                                                                                    \n",
      "epoch: 0040, loss: 0.4156 - val_loss: 0.6402; auc: 0.9735 - val_auc: 0.8817                                                                                                    \n",
      "epoch: 0041, loss: 0.4090 - val_loss: 0.6732; auc: 0.9728 - val_auc: 0.8851                                                                                                    \n",
      "epoch: 0042, loss: 0.4041 - val_loss: 0.6402; auc: 0.9757 - val_auc: 0.8843                                                                                                    \n",
      "epoch: 0043, loss: 0.3963 - val_loss: 0.6456; auc: 0.9767 - val_auc: 0.8822                                                                                                    \n",
      "epoch: 0044, loss: 0.3888 - val_loss: 0.6556; auc: 0.9782 - val_auc: 0.8836                                                                                                    \n",
      "epoch: 0045, loss: 0.3900 - val_loss: 0.6379; auc: 0.9781 - val_auc: 0.8815                                                                                                    \n",
      "epoch: 0046, loss: 0.3833 - val_loss: 0.6521; auc: 0.9794 - val_auc: 0.8839                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb64803e470>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = (X1[train_valid_idx], X2[train_valid_idx])\n",
    "trainY = Y[train_valid_idx]\n",
    "\n",
    "loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "\n",
    "model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                   n_outputs=Y.shape[-1], \n",
    "                                   dense_layers=dense_layers, \n",
    "                                   dense_avf = dense_avf, \n",
    "                                   last_avf=last_avf)\n",
    "model.compile(optimizer = opt, loss = loss)\n",
    "\n",
    "performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                            (testX, testY), \n",
    "                                                            patience = 1000000,\n",
    "                                                            metric = metric,\n",
    "                                                            criteria = monitor)\n",
    "\n",
    "model.fit(trainX, trainY, batch_size=batch_size, \n",
    "          epochs=best_epoch, verbose= 0, shuffle = True, \n",
    "          validation_data = (testX, testY), \n",
    "          callbacks=[performance]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9746272458316189,\n",
       " 0.8042402039654447,\n",
       " 0.8195457640307363,\n",
       " 0.8997232275920801,\n",
       " 0.9213991020507221]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.evaluate(testX, testY) # test roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839071086941204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(performance.evaluate(testX, testY)) # test roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
