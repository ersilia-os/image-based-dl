{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sxh/Research/AttentiveFP/code',)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "        \n",
    "    preds = []\n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        probs = F.softmax(mol_prediction,dim=-1).data.cpu().numpy()[:,1]\n",
    "        preds.append(probs)\n",
    "    return np.concatenate(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['Class']\n",
    "data_path = '/home/sxh/Research/bidd-molmap/paper/07_BACE_HPs/data'\n",
    "bace_path = os.path.join(data_path,'bace.csv')\n",
    "drug_path  = os.path.join(data_path,'drugs.csv.dmpnn.csv')\n",
    "novel_path  = os.path.join(data_path,'bace_chembl_novel.csv.dmpnn.csv')\n",
    "common_path  = os.path.join(data_path,'bace_chembl_common.csv.dmpnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(bace_path)\n",
    "df2 = pd.read_csv(drug_path)\n",
    "df3 = pd.read_csv(novel_path)\n",
    "df4 = pd.read_csv(common_path)\n",
    "smiles_tasks_df = df1[['smiles', 'Class']].append(df2).append(df3).append(df4)\n",
    "smiles_tasks_df['mol'] = smiles_tasks_df.smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_filename = '/raid/shenwanxiang/BACE/attentiveFP/feature.pkl'\n",
    "prefix_filename = 'bace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  7259\n",
      "number of successfully processed smiles:  7259\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smilesList = smiles_tasks_df.mol.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"mol\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "#assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 88\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dicts file saved as /raid/shenwanxiang/BACE/attentiveFP/feature.pkl.pickle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Class</th>\n",
       "      <th>mol</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [smiles, Class, mol, cano_smiles]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList, feature_filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
    "df_valid = pd.read_csv(os.path.join(data_path, 'val.csv'))\n",
    "df_train = pd.read_csv(os.path.join(data_path, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210 151 152\n",
      "EPOCH:\t0\n",
      "train_roc:[0.5463655226928397]\n",
      "valid_roc:[0.5242190242190242]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.6973739103704192]\n",
      "valid_roc:[0.6382941382941383]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.6966685330347143]\n",
      "valid_roc:[0.6368901368901368]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.6952193531387918]\n",
      "valid_roc:[0.6367146367146367]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7010929231715083]\n",
      "valid_roc:[0.6402246402246402]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.7009447115912435]\n",
      "valid_roc:[0.6395226395226394]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.7140888830336166]\n",
      "valid_roc:[0.6437346437346437]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.7196330939990778]\n",
      "valid_roc:[0.6432081432081431]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.7289155303778846]\n",
      "valid_roc:[0.6398736398736399]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.7370424653624048]\n",
      "valid_roc:[0.6363636363636365]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.7481281426344335]\n",
      "valid_roc:[0.6340821340821341]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.7492699207342511]\n",
      "valid_roc:[0.634959634959635]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.75225062029291]\n",
      "valid_roc:[0.6354861354861355]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.7594114353468151]\n",
      "valid_roc:[0.6358371358371359]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.7677332411127945]\n",
      "valid_roc:[0.6328536328536328]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.7706370902224271]\n",
      "valid_roc:[0.6353106353106354]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.7773450365588566]\n",
      "valid_roc:[0.6388206388206388]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.7817913839668006]\n",
      "valid_roc:[0.641102141102141]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.7856174384647475]\n",
      "valid_roc:[0.6418041418041418]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.7899347869046834]\n",
      "valid_roc:[0.6435591435591436]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.7939749247963463]\n",
      "valid_roc:[0.6460161460161461]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.7952978503831544]\n",
      "valid_roc:[0.6553176553176553]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.7990772456799069]\n",
      "valid_roc:[0.6526851526851527]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.8013333552906046]\n",
      "valid_roc:[0.6577746577746577]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.8042509276947061]\n",
      "valid_roc:[0.6611091611091611]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.8063204005006257]\n",
      "valid_roc:[0.6683046683046683]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.8093258019893287]\n",
      "valid_roc:[0.6730431730431731]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.8114721252442746]\n",
      "valid_roc:[0.676026676026676]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.813346727268735]\n",
      "valid_roc:[0.6825201825201823]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.8145159519574907]\n",
      "valid_roc:[0.6858546858546859]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.8160145357135016]\n",
      "valid_roc:[0.6846261846261845]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.8185396218957908]\n",
      "valid_roc:[0.6869076869076869]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.8186741101815866]\n",
      "valid_roc:[0.6855036855036855]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.8203812880135255]\n",
      "valid_roc:[0.6891891891891891]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.8218194892738729]\n",
      "valid_roc:[0.6948051948051949]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.8249923149550973]\n",
      "valid_roc:[0.702000702000702]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.8268092791427881]\n",
      "valid_roc:[0.7016497016497016]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.8299601475528622]\n",
      "valid_roc:[0.7072657072657073]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.8319939397931624]\n",
      "valid_roc:[0.7204282204282204]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.8346837055090793]\n",
      "valid_roc:[0.7172692172692173]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8387540346485739]\n",
      "valid_roc:[0.7244647244647244]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.8404063193026372]\n",
      "valid_roc:[0.7253422253422254]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.8438700788266034]\n",
      "valid_roc:[0.7314847314847315]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.8458983817491164]\n",
      "valid_roc:[0.7342927342927343]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.8486951891618908]\n",
      "valid_roc:[0.7483327483327484]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.8514865072568782]\n",
      "valid_roc:[0.7532467532467533]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.8520656302834684]\n",
      "valid_roc:[0.7546507546507546]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.850018114748699]\n",
      "valid_roc:[0.7493857493857494]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.8524361592341305]\n",
      "valid_roc:[0.7516672516672518]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.8546950135037216]\n",
      "valid_roc:[0.7527202527202527]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.8561606613530071]\n",
      "valid_roc:[0.755001755001755]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.8583289418791034]\n",
      "valid_roc:[0.7583362583362584]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.8602502031047581]\n",
      "valid_roc:[0.7644787644787644]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.8616197878927607]\n",
      "valid_roc:[0.7697437697437697]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.8635437937773094]\n",
      "valid_roc:[0.7602667602667603]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.8639609819291658]\n",
      "valid_roc:[0.7644787644787646]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.864726741760534]\n",
      "valid_roc:[0.7643032643032642]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.865058845486683]\n",
      "valid_roc:[0.769041769041769]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.8670597018202579]\n",
      "valid_roc:[0.7671112671112671]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.86792975868959]\n",
      "valid_roc:[0.7614952614952615]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.8677403772259185]\n",
      "valid_roc:[0.7741312741312741]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.8712315833388229]\n",
      "valid_roc:[0.7739557739557741]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.8718546209077137]\n",
      "valid_roc:[0.7641277641277641]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.8722827876951452]\n",
      "valid_roc:[0.7695682695682696]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.8723651274619589]\n",
      "valid_roc:[0.7637767637767638]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.8742424741453132]\n",
      "valid_roc:[0.7599157599157599]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.8718161956832005]\n",
      "valid_roc:[0.7593892593892595]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.8736112025997409]\n",
      "valid_roc:[0.7664092664092664]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.8751948707814594]\n",
      "valid_roc:[0.7681642681642681]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.8754748259886261]\n",
      "valid_roc:[0.7718497718497718]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.877212195068397]\n",
      "valid_roc:[0.7718497718497719]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.878296335331445]\n",
      "valid_roc:[0.7772902772902772]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.8797510045451552]\n",
      "valid_roc:[0.7778167778167778]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.8804344246097094]\n",
      "valid_roc:[0.7772902772902772]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.8816063939573588]\n",
      "valid_roc:[0.7734292734292735]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.8828744263662912]\n",
      "valid_roc:[0.7785187785187785]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.883434336780625]\n",
      "valid_roc:[0.7825552825552825]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.8845898381749115]\n",
      "valid_roc:[0.7815022815022815]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.8850921107524756]\n",
      "valid_roc:[0.7811512811512812]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.8859731462573831]\n",
      "valid_roc:[0.7813267813267812]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.887060031179325]\n",
      "valid_roc:[0.7800982800982801]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.8880892782644972]\n",
      "valid_roc:[0.7832572832572834]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.8889428671804668]\n",
      "valid_roc:[0.7802737802737802]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.8790483718683442]\n",
      "valid_roc:[0.770972270972271]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.8847188371429199]\n",
      "valid_roc:[0.7785187785187785]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.8864863974705225]\n",
      "valid_roc:[0.7825552825552826]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.8880096831565772]\n",
      "valid_roc:[0.7841347841347841]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.8894012252157302]\n",
      "valid_roc:[0.7864162864162865]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.8890938234196255]\n",
      "valid_roc:[0.7883467883467884]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.8885531256175483]\n",
      "valid_roc:[0.7929097929097929]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.8918823968557188]\n",
      "valid_roc:[0.7858897858897859]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.8927167731594318]\n",
      "valid_roc:[0.783081783081783]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.8921760753573547]\n",
      "valid_roc:[0.787118287118287]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.8924779878356718]\n",
      "valid_roc:[0.7916812916812915]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.8934303844718179]\n",
      "valid_roc:[0.7878202878202878]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.8948548624376963]\n",
      "valid_roc:[0.7853632853632854]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.8931833651713765]\n",
      "valid_roc:[0.7837837837837838]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.8950799244669873]\n",
      "valid_roc:[0.7862407862407862]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.8953626243330479]\n",
      "valid_roc:[0.7906282906282907]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.8962244472256988]\n",
      "valid_roc:[0.7904527904527905]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.8971439079551194]\n",
      "valid_roc:[0.794840294840295]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.8979673056232572]\n",
      "valid_roc:[0.7876447876447876]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.8979480930110006]\n",
      "valid_roc:[0.7888732888732889]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.8978986891509124]\n",
      "valid_roc:[0.7925587925587925]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.8995866543705948]\n",
      "valid_roc:[0.7897507897507897]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.8990294886151549]\n",
      "valid_roc:[0.7906282906282907]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.8996250795951078]\n",
      "valid_roc:[0.7967707967707968]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.8998254396943546]\n",
      "valid_roc:[0.795015795015795]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.9007558790593505]\n",
      "valid_roc:[0.7936117936117937]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.90200744351492]\n",
      "valid_roc:[0.7885222885222885]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.9016204466108952]\n",
      "valid_roc:[0.7946647946647947]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.9017851261445229]\n",
      "valid_roc:[0.7937872937872938]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.9014173418527545]\n",
      "valid_roc:[0.7974727974727974]\n",
      "\n",
      "EPOCH:\t113\n",
      "train_roc:[0.9009397712052345]\n",
      "valid_roc:[0.782906282906283]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.9012554069780208]\n",
      "valid_roc:[0.7864162864162864]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.9014338098061172]\n",
      "valid_roc:[0.792032292032292]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.8997513339042225]\n",
      "valid_roc:[0.7837837837837838]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.8981319851568846]\n",
      "valid_roc:[0.7937872937872937]\n",
      "\n",
      "EPOCH:\t118\n",
      "train_roc:[0.9013404914037284]\n",
      "valid_roc:[0.7943137943137943]\n",
      "\n",
      "EPOCH:\t119\n",
      "train_roc:[0.9012005138001449]\n",
      "valid_roc:[0.7932607932607932]\n",
      "\n",
      "EPOCH:\t120\n",
      "train_roc:[0.9033248797839406]\n",
      "valid_roc:[0.7958932958932958]\n",
      "\n",
      "EPOCH:\t121\n",
      "train_roc:[0.9033111564894715]\n",
      "valid_roc:[0.7944892944892945]\n",
      "\n",
      "EPOCH:\t122\n",
      "train_roc:[0.9027210548273061]\n",
      "valid_roc:[0.7978237978237979]\n",
      "\n",
      "EPOCH:\t123\n",
      "train_roc:[0.9045188064027403]\n",
      "valid_roc:[0.7978237978237979]\n",
      "\n",
      "EPOCH:\t124\n",
      "train_roc:[0.9038024504314605]\n",
      "valid_roc:[0.8018603018603019]\n",
      "\n",
      "EPOCH:\t125\n",
      "train_roc:[0.9056249039369386]\n",
      "valid_roc:[0.8022113022113022]\n",
      "\n",
      "EPOCH:\t126\n",
      "train_roc:[0.9067831499901192]\n",
      "valid_roc:[0.7936117936117936]\n",
      "\n",
      "EPOCH:\t127\n",
      "train_roc:[0.9028857343609336]\n",
      "valid_roc:[0.7911547911547911]\n",
      "\n",
      "EPOCH:\t128\n",
      "train_roc:[0.9058499659662298]\n",
      "valid_roc:[0.7978237978237979]\n",
      "\n",
      "EPOCH:\t129\n",
      "train_roc:[0.9060722833366268]\n",
      "valid_roc:[0.802913302913303]\n",
      "\n",
      "EPOCH:\t130\n",
      "train_roc:[0.9063824297916253]\n",
      "valid_roc:[0.8013338013338013]\n",
      "\n",
      "EPOCH:\t131\n",
      "train_roc:[0.9073128691566211]\n",
      "valid_roc:[0.8048438048438048]\n",
      "\n",
      "EPOCH:\t132\n",
      "train_roc:[0.9066788529521551]\n",
      "valid_roc:[0.8023868023868023]\n",
      "\n",
      "EPOCH:\t133\n",
      "train_roc:[0.9054492457677359]\n",
      "valid_roc:[0.7987012987012987]\n",
      "\n",
      "EPOCH:\t134\n",
      "train_roc:[0.9073512943811343]\n",
      "valid_roc:[0.799052299052299]\n",
      "\n",
      "EPOCH:\t135\n",
      "train_roc:[0.9090529828952858]\n",
      "valid_roc:[0.7951912951912952]\n",
      "\n",
      "EPOCH:\t136\n",
      "train_roc:[0.9092451090178514]\n",
      "valid_roc:[0.8018603018603018]\n",
      "\n",
      "EPOCH:\t137\n",
      "train_roc:[0.9098901038578926]\n",
      "valid_roc:[0.8006318006318006]\n",
      "\n",
      "EPOCH:\t138\n",
      "train_roc:[0.9104253123421822]\n",
      "valid_roc:[0.8034398034398035]\n",
      "\n",
      "EPOCH:\t139\n",
      "train_roc:[0.9100602727093077]\n",
      "valid_roc:[0.8051948051948052]\n",
      "\n",
      "EPOCH:\t140\n",
      "train_roc:[0.9113145818237709]\n",
      "valid_roc:[0.8044928044928045]\n",
      "\n",
      "EPOCH:\t141\n",
      "train_roc:[0.9109413082142152]\n",
      "valid_roc:[0.8069498069498069]\n",
      "\n",
      "EPOCH:\t142\n",
      "train_roc:[0.9104829501789518]\n",
      "valid_roc:[0.8081783081783082]\n",
      "\n",
      "EPOCH:\t143\n",
      "train_roc:[0.9124618492413763]\n",
      "valid_roc:[0.8057213057213057]\n",
      "\n",
      "EPOCH:\t144\n",
      "train_roc:[0.9124371473113322]\n",
      "valid_roc:[0.8027378027378027]\n",
      "\n",
      "EPOCH:\t145\n",
      "train_roc:[0.9074583360779922]\n",
      "valid_roc:[0.8043173043173042]\n",
      "\n",
      "EPOCH:\t146\n",
      "train_roc:[0.9120062358650067]\n",
      "valid_roc:[0.8044928044928044]\n",
      "\n",
      "EPOCH:\t147\n",
      "train_roc:[0.9130986101047363]\n",
      "valid_roc:[0.803088803088803]\n",
      "\n",
      "EPOCH:\t148\n",
      "train_roc:[0.9132303537316382]\n",
      "valid_roc:[0.803966303966304]\n",
      "\n",
      "EPOCH:\t149\n",
      "train_roc:[0.9127774850141626]\n",
      "valid_roc:[0.8041418041418041]\n",
      "\n",
      "EPOCH:\t150\n",
      "train_roc:[0.9129311859122148]\n",
      "valid_roc:[0.8076518076518077]\n",
      "\n",
      "EPOCH:\t151\n",
      "train_roc:[0.9132825022506204]\n",
      "valid_roc:[0.8027378027378027]\n",
      "\n",
      "EPOCH:\t152\n",
      "train_roc:[0.9149073403157456]\n",
      "valid_roc:[0.8034398034398035]\n",
      "\n",
      "EPOCH:\t153\n",
      "train_roc:[0.9153602090332214]\n",
      "valid_roc:[0.8053703053703054]\n",
      "\n",
      "EPOCH:\t154\n",
      "train_roc:[0.9135706914344686]\n",
      "valid_roc:[0.8116883116883117]\n",
      "\n",
      "EPOCH:\t155\n",
      "train_roc:[0.9157060360538394]\n",
      "valid_roc:[0.8102843102843102]\n",
      "\n",
      "EPOCH:\t156\n",
      "train_roc:[0.915947566036493]\n",
      "valid_roc:[0.8015093015093016]\n",
      "\n",
      "EPOCH:\t157\n",
      "train_roc:[0.91712502470193]\n",
      "valid_roc:[0.8008073008073008]\n",
      "\n",
      "EPOCH:\t158\n",
      "train_roc:[0.9166831346200295]\n",
      "valid_roc:[0.803088803088803]\n",
      "\n",
      "EPOCH:\t159\n",
      "train_roc:[0.9164608172496322]\n",
      "valid_roc:[0.8064233064233064]\n",
      "\n",
      "EPOCH:\t160\n",
      "train_roc:[0.9157609292317151]\n",
      "valid_roc:[0.8032643032643032]\n",
      "\n",
      "EPOCH:\t161\n",
      "train_roc:[0.9169960257339218]\n",
      "valid_roc:[0.8041418041418041]\n",
      "\n",
      "EPOCH:\t162\n",
      "train_roc:[0.9180554640669258]\n",
      "valid_roc:[0.806949806949807]\n",
      "\n",
      "EPOCH:\t163\n",
      "train_roc:[0.9175971060316624]\n",
      "valid_roc:[0.8071253071253072]\n",
      "\n",
      "EPOCH:\t164\n",
      "train_roc:[0.9181021232681202]\n",
      "valid_roc:[0.8097578097578098]\n",
      "\n",
      "EPOCH:\t165\n",
      "train_roc:[0.918277781437323]\n",
      "valid_roc:[0.8034398034398034]\n",
      "\n",
      "EPOCH:\t166\n",
      "train_roc:[0.9183024833673672]\n",
      "valid_roc:[0.8055458055458056]\n",
      "\n",
      "EPOCH:\t167\n",
      "train_roc:[0.9189145423006828]\n",
      "valid_roc:[0.8018603018603018]\n",
      "\n",
      "EPOCH:\t168\n",
      "train_roc:[0.9184067804053313]\n",
      "valid_roc:[0.8122148122148122]\n",
      "\n",
      "EPOCH:\t169\n",
      "train_roc:[0.919216454779]\n",
      "valid_roc:[0.8092313092313093]\n",
      "\n",
      "EPOCH:\t170\n",
      "train_roc:[0.9197681312166524]\n",
      "valid_roc:[0.8139698139698139]\n",
      "\n",
      "EPOCH:\t171\n",
      "train_roc:[0.9176712118217949]\n",
      "valid_roc:[0.8153738153738154]\n",
      "\n",
      "EPOCH:\t172\n",
      "train_roc:[0.9209812704477087]\n",
      "valid_roc:[0.8037908037908038]\n",
      "\n",
      "EPOCH:\t173\n",
      "train_roc:[0.9207809103484619]\n",
      "valid_roc:[0.8057213057213057]\n",
      "\n",
      "EPOCH:\t174\n",
      "train_roc:[0.9195403245284676]\n",
      "valid_roc:[0.8074763074763075]\n",
      "\n",
      "EPOCH:\t175\n",
      "train_roc:[0.9199135981380233]\n",
      "valid_roc:[0.8044928044928045]\n",
      "\n",
      "EPOCH:\t176\n",
      "train_roc:[0.9209675471532399]\n",
      "valid_roc:[0.8036153036153035]\n",
      "\n",
      "EPOCH:\t177\n",
      "train_roc:[0.9209730364710274]\n",
      "valid_roc:[0.8088803088803089]\n",
      "\n",
      "EPOCH:\t178\n",
      "train_roc:[0.9196336429308566]\n",
      "valid_roc:[0.8095823095823096]\n",
      "\n",
      "EPOCH:\t179\n",
      "train_roc:[0.9208248248907626]\n",
      "valid_roc:[0.808178308178308]\n",
      "\n",
      "EPOCH:\t180\n",
      "train_roc:[0.9201770853918275]\n",
      "valid_roc:[0.8102843102843102]\n",
      "\n",
      "EPOCH:\t181\n",
      "train_roc:[0.9190819664932044]\n",
      "valid_roc:[0.8101088101088101]\n",
      "\n",
      "EPOCH:\t182\n",
      "train_roc:[0.9190298179742222]\n",
      "valid_roc:[0.806949806949807]\n",
      "\n",
      "EPOCH:\t183\n",
      "train_roc:[0.9200700436949696]\n",
      "valid_roc:[0.8051948051948052]\n",
      "\n",
      "EPOCH:\t184\n",
      "train_roc:[0.9199190874558111]\n",
      "valid_roc:[0.8113373113373114]\n",
      "\n",
      "EPOCH:\t185\n",
      "train_roc:[0.9215823507454494]\n",
      "valid_roc:[0.8130923130923131]\n",
      "\n",
      "EPOCH:\t186\n",
      "train_roc:[0.9227021715741168]\n",
      "valid_roc:[0.8111618111618111]\n",
      "\n",
      "EPOCH:\t187\n",
      "train_roc:[0.9226445337373471]\n",
      "valid_roc:[0.8122148122148123]\n",
      "\n",
      "EPOCH:\t188\n",
      "train_roc:[0.9237012274114573]\n",
      "valid_roc:[0.8067743067743067]\n",
      "\n",
      "EPOCH:\t189\n",
      "train_roc:[0.9241952660123399]\n",
      "valid_roc:[0.8116883116883117]\n",
      "\n",
      "EPOCH:\t190\n",
      "train_roc:[0.9221806863842963]\n",
      "valid_roc:[0.8087048087048088]\n",
      "\n",
      "best epoch:171\n",
      "test_roc:[0.8449019607843137]\n",
      "test_roc_mean: 0.8449019607843137\n"
     ]
    }
   ],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "task_name = 'BACE'\n",
    "\n",
    "test_df = remained_df[remained_df.smiles.isin(df_test.smiles)].reset_index(drop=True)\n",
    "valid_df = remained_df[remained_df.smiles.isin(df_valid.smiles)].reset_index(drop=True)\n",
    "train_df = remained_df[remained_df.smiles.isin(df_train.smiles)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = train_df[train_df[task] == 0][[\"mol\",task]]\n",
    "    positive_df = train_df[train_df[task] == 1][[\"mol\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "\n",
    "print(len(train_df),len(valid_df),len(test_df),)\n",
    "\n",
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight)) for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.80:\n",
    "             torch.save(model, '/raid/shenwanxiang/BACE/attentiveFP/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "\n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n')\n",
    "    if epoch - best_param[\"roc_epoch\"] > 18:        \n",
    "        break\n",
    "\n",
    "    train(model, train_df, optimizer, loss_function)\n",
    "\n",
    "# evaluate model\n",
    "best_model = torch.load('/raid/shenwanxiang/BACE/attentiveFP/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = remained_df[remained_df.smiles.isin(df2.smiles)].reset_index(drop=True)\n",
    "df33 = remained_df[remained_df.smiles.isin(df3.smiles)].reset_index(drop=True)\n",
    "df44 = remained_df[remained_df.smiles.isin(df4.smiles)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predict(best_model, test_df)\n",
    "dftt = pd.DataFrame(pred_test, index = test_df['smiles'],\n",
    "             columns = ['attfp_pred'])\n",
    "\n",
    "test_df.set_index('smiles').join(dftt).drop_duplicates().loc[test_df.smiles][['attfp_pred']].to_csv('./ATTFP_pred_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = predict(best_model, valid_df)\n",
    "dfv = pd.DataFrame(pred_valid, index = valid_df['smiles'], \n",
    "                   columns = ['attfp_pred'])\n",
    "valid_df.set_index('smiles').join(dfv).drop_duplicates().loc[valid_df.smiles][['attfp_pred']].to_csv('./ATTFP_pred_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_drug = predict(best_model, df22)\n",
    "dfd = pd.DataFrame(pred_drug, index = df22['smiles'], \n",
    "             columns = ['attfp_pred'])\n",
    "df2.set_index('smiles').join(dfd).drop_duplicates().loc[df2.smiles][['attfp_pred']].to_csv('./ATTFP_pred_drug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sxh/anaconda3/envs/rdkit2020/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "pred_novel = predict(best_model, df33)\n",
    "dfn = pd.DataFrame(pred_novel, index = df33['smiles'], \n",
    "             columns = ['attfp_pred'])\n",
    "df3.set_index('smiles').join(dfn).drop_duplicates().loc[df3.smiles][['attfp_pred']].to_csv('./ATTFP_pred_novel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sxh/anaconda3/envs/rdkit2020/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "pred_common = predict(best_model, df44)\n",
    "dfc = pd.DataFrame(pred_common, index = df44['smiles'], \n",
    "             columns = ['attfp_pred'])\n",
    "df4.set_index('smiles').join(dfc).drop_duplicates().loc[df4.smiles][['attfp_pred']].to_csv('./ATTFP_pred_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
