{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "import time\n",
    "\n",
    "from molmap import dataset\n",
    "from molmap import loadmap\n",
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "#use GPU, if negative value, CPUs will be used\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "## fix random seed to get repeatale results\n",
    "seed = 123\n",
    "tqdm.pandas(ascii=True)\n",
    "np.random.seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "def get_pos_weights(trainY):\n",
    "    \"\"\"pos_weights: neg_n / pos_n \"\"\"\n",
    "    dfY = pd.DataFrame(trainY)\n",
    "    pos = dfY == 1\n",
    "    pos_n = pos.sum(axis=0)\n",
    "    neg = dfY == 0\n",
    "    neg_n = neg.sum(axis=0)\n",
    "    pos_weights = (neg_n / pos_n).values\n",
    "    neg_weights = (pos_n / neg_n).values\n",
    "    return pos_weights, neg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: Tox21 number of split times: 3\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Tox21'\n",
    "from chembench import load_data\n",
    "df, induces = load_data(task_name)\n",
    "\n",
    "MASK = -1\n",
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').fillna(MASK).values\n",
    "if Y.shape[1] == 0:\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    \n",
    "tmp_feature_dir = './tmpignore'\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "    \n",
    "train_idx, valid_idx, test_idx = induces[0]\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]\n",
    "trainY = Y[train_idx]\n",
    "validY = Y[valid_idx]\n",
    "testY = Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "patience = 10 #early stopping, 100 epochs to select best\n",
    "dense_layers = [256, 128]\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "metric = 'ROC'\n",
    "monitor = 'val_auc'\n",
    "dense_avf = 'relu'\n",
    "last_avf = None #sigmoid in loss\n",
    "\n",
    "\n",
    "method = 'umap'\n",
    "min_dist = 0.9\n",
    "n_neighbors = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n",
      "     learning_rate=1.0, local_connectivity=1.0, metric='precomputed',\n",
      "     metric_kwds=None, min_dist=0.9, n_components=2, n_epochs=None,\n",
      "     n_neighbors=10, negative_sample_rate=5, random_state=1,\n",
      "     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n",
      "     target_metric='categorical', target_metric_kwds=None,\n",
      "     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n",
      "     transform_seed=42, verbose=2)\n",
      "Construct fuzzy simplicial set\n",
      "Mon Feb  3 22:31:55 2020 Finding Nearest Neighbors\n",
      "Mon Feb  3 22:31:55 2020 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 22:31:55 2020 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sxh/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/umap/spectral.py:229: UserWarning: Embedding a total of 2 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Feb  3 22:31:58 2020 Finished embedding\n",
      "2020-02-03 22:31:58,398 - \u001b[32mINFO\u001b[0m - [bidd-molmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n",
      "2020-02-03 22:32:00,518 - \u001b[32mINFO\u001b[0m - [bidd-molmap]\u001b[0m - Finished\u001b[0m\n",
      "UMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n",
      "     learning_rate=1.0, local_connectivity=1.0, metric='precomputed',\n",
      "     metric_kwds=None, min_dist=0.9, n_components=2, n_epochs=None,\n",
      "     n_neighbors=10, negative_sample_rate=5, random_state=1,\n",
      "     repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n",
      "     target_metric='categorical', target_metric_kwds=None,\n",
      "     target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n",
      "     transform_seed=42, verbose=2)\n",
      "Construct fuzzy simplicial set\n",
      "Mon Feb  3 22:32:00 2020 Finding Nearest Neighbors\n",
      "Mon Feb  3 22:32:00 2020 Finished Nearest Neighbor Search\n",
      "Mon Feb  3 22:32:00 2020 Construct embedding\n",
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Feb  3 22:32:02 2020 Finished embedding\n",
      "2020-02-03 22:32:02,737 - \u001b[32mINFO\u001b[0m - [bidd-molmap]\u001b[0m - Applying grid feature map(assignment), this may take several minutes(1~30 min)\u001b[0m\n",
      "2020-02-03 22:32:04,840 - \u001b[32mINFO\u001b[0m - [bidd-molmap]\u001b[0m - Finished\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./optimized_fp.mp']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp1_opt = molmap.loadmap('../descriptor.mp')\n",
    "mp1_opt.fit(method = method, n_neighbors = n_neighbors, min_dist = min_dist)\n",
    "mp1_opt.save('./optimized_des.mp')\n",
    "mp2_opt = molmap.loadmap('../fingerprint.mp')\n",
    "mp2_opt.fit(method = method, n_neighbors = n_neighbors, min_dist = min_dist)\n",
    "mp2_opt.save('./optimized_fp.mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 7831/7831 [00:02<00:00, 2657.56it/s]\n",
      "100%|##########| 7831/7831 [00:01<00:00, 4461.12it/s]\n"
     ]
    }
   ],
   "source": [
    "X1_new = mp1.rearrangement(X1, mp1_opt)\n",
    "X2_new = mp2.rearrangement(X2, mp2_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6264 783 784\n",
      "epoch: 0001, loss: 1.1649 - val_loss: 1.1592; auc: 0.7119 - val_auc: 0.7251                                                                                                    \n",
      "epoch: 0002, loss: 1.1072 - val_loss: 1.0913; auc: 0.7352 - val_auc: 0.7524                                                                                                    \n",
      "epoch: 0003, loss: 1.0583 - val_loss: 1.0355; auc: 0.7456 - val_auc: 0.7584                                                                                                    \n",
      "epoch: 0004, loss: 1.0305 - val_loss: 1.0142; auc: 0.7584 - val_auc: 0.7666                                                                                                    \n",
      "epoch: 0005, loss: 1.0066 - val_loss: 1.0099; auc: 0.7735 - val_auc: 0.7753                                                                                                    \n",
      "epoch: 0006, loss: 0.9923 - val_loss: 0.9919; auc: 0.7796 - val_auc: 0.7766                                                                                                    \n",
      "epoch: 0007, loss: 0.9761 - val_loss: 0.9813; auc: 0.7895 - val_auc: 0.7806                                                                                                    \n",
      "epoch: 0008, loss: 0.9601 - val_loss: 0.9719; auc: 0.8070 - val_auc: 0.7894                                                                                                    \n",
      "epoch: 0009, loss: 0.9433 - val_loss: 0.9664; auc: 0.8140 - val_auc: 0.7942                                                                                                    \n",
      "epoch: 0010, loss: 0.9331 - val_loss: 0.9676; auc: 0.8266 - val_auc: 0.8012                                                                                                    \n",
      "epoch: 0011, loss: 0.9155 - val_loss: 0.9480; auc: 0.8337 - val_auc: 0.8042                                                                                                    \n",
      "epoch: 0012, loss: 0.8963 - val_loss: 0.9401; auc: 0.8375 - val_auc: 0.8067                                                                                                    \n",
      "epoch: 0013, loss: 0.8858 - val_loss: 0.9517; auc: 0.8519 - val_auc: 0.8126                                                                                                    \n",
      "epoch: 0014, loss: 0.8708 - val_loss: 0.9556; auc: 0.8572 - val_auc: 0.8160                                                                                                    \n",
      "epoch: 0015, loss: 0.8583 - val_loss: 0.9226; auc: 0.8643 - val_auc: 0.8203                                                                                                    \n",
      "epoch: 0016, loss: 0.8457 - val_loss: 0.9174; auc: 0.8687 - val_auc: 0.8228                                                                                                    \n",
      "epoch: 0017, loss: 0.8310 - val_loss: 0.9052; auc: 0.8727 - val_auc: 0.8251                                                                                                    \n",
      "epoch: 0018, loss: 0.8131 - val_loss: 0.8953; auc: 0.8745 - val_auc: 0.8287                                                                                                    \n",
      "epoch: 0019, loss: 0.8080 - val_loss: 0.9054; auc: 0.8797 - val_auc: 0.8310                                                                                                    \n",
      "epoch: 0020, loss: 0.7901 - val_loss: 0.9269; auc: 0.8894 - val_auc: 0.8296                                                                                                    \n",
      "epoch: 0021, loss: 0.7807 - val_loss: 0.9287; auc: 0.8913 - val_auc: 0.8336                                                                                                    \n",
      "epoch: 0022, loss: 0.7716 - val_loss: 0.8792; auc: 0.8949 - val_auc: 0.8371                                                                                                    \n",
      "epoch: 0023, loss: 0.7569 - val_loss: 0.9556; auc: 0.9005 - val_auc: 0.8349                                                                                                    \n",
      "epoch: 0024, loss: 0.7484 - val_loss: 0.9352; auc: 0.9037 - val_auc: 0.8390                                                                                                    \n",
      "epoch: 0025, loss: 0.7419 - val_loss: 0.9499; auc: 0.9067 - val_auc: 0.8385                                                                                                    \n",
      "epoch: 0026, loss: 0.7361 - val_loss: 0.8791; auc: 0.9070 - val_auc: 0.8411                                                                                                    \n",
      "epoch: 0027, loss: 0.7196 - val_loss: 0.8733; auc: 0.9107 - val_auc: 0.8428                                                                                                    \n",
      "epoch: 0028, loss: 0.7058 - val_loss: 0.8700; auc: 0.9136 - val_auc: 0.8431                                                                                                    \n",
      "epoch: 0029, loss: 0.6960 - val_loss: 0.8846; auc: 0.9120 - val_auc: 0.8453                                                                                                    \n",
      "epoch: 0030, loss: 0.7021 - val_loss: 1.0006; auc: 0.9199 - val_auc: 0.8386                                                                                                    \n",
      "epoch: 0031, loss: 0.6861 - val_loss: 0.8790; auc: 0.9205 - val_auc: 0.8456                                                                                                    \n",
      "epoch: 0032, loss: 0.6684 - val_loss: 0.8919; auc: 0.9231 - val_auc: 0.8475                                                                                                    \n",
      "epoch: 0033, loss: 0.6633 - val_loss: 0.8873; auc: 0.9256 - val_auc: 0.8479                                                                                                    \n",
      "epoch: 0034, loss: 0.6497 - val_loss: 0.8684; auc: 0.9264 - val_auc: 0.8470                                                                                                    \n",
      "epoch: 0035, loss: 0.6441 - val_loss: 0.9204; auc: 0.9293 - val_auc: 0.8467                                                                                                    \n",
      "epoch: 0036, loss: 0.6335 - val_loss: 0.8689; auc: 0.9287 - val_auc: 0.8497                                                                                                    \n",
      "epoch: 0037, loss: 0.6309 - val_loss: 0.8715; auc: 0.9318 - val_auc: 0.8501                                                                                                    \n",
      "epoch: 0038, loss: 0.6186 - val_loss: 0.8646; auc: 0.9340 - val_auc: 0.8510                                                                                                    \n",
      "epoch: 0039, loss: 0.6115 - val_loss: 0.9101; auc: 0.9365 - val_auc: 0.8501                                                                                                    \n",
      "epoch: 0040, loss: 0.6022 - val_loss: 0.8818; auc: 0.9364 - val_auc: 0.8514                                                                                                    \n",
      "epoch: 0041, loss: 0.6012 - val_loss: 0.9283; auc: 0.9397 - val_auc: 0.8486                                                                                                    \n",
      "epoch: 0042, loss: 0.5898 - val_loss: 0.9755; auc: 0.9422 - val_auc: 0.8473                                                                                                    \n",
      "epoch: 0043, loss: 0.5815 - val_loss: 0.8834; auc: 0.9407 - val_auc: 0.8505                                                                                                    \n",
      "epoch: 0044, loss: 0.5803 - val_loss: 0.9242; auc: 0.9435 - val_auc: 0.8507                                                                                                    \n",
      "epoch: 0045, loss: 0.5698 - val_loss: 0.9469; auc: 0.9460 - val_auc: 0.8483                                                                                                    \n",
      "epoch: 0046, loss: 0.5565 - val_loss: 0.9203; auc: 0.9471 - val_auc: 0.8485                                                                                                    \n",
      "epoch: 0047, loss: 0.5494 - val_loss: 0.9575; auc: 0.9468 - val_auc: 0.8517                                                                                                    \n",
      "epoch: 0048, loss: 0.5523 - val_loss: 1.0667; auc: 0.9491 - val_auc: 0.8500                                                                                                    \n",
      "epoch: 0049, loss: 0.5409 - val_loss: 0.9319; auc: 0.9500 - val_auc: 0.8519                                                                                                    \n",
      "epoch: 0050, loss: 0.5347 - val_loss: 0.9323; auc: 0.9509 - val_auc: 0.8520                                                                                                    \n",
      "epoch: 0051, loss: 0.5316 - val_loss: 0.9402; auc: 0.9511 - val_auc: 0.8528                                                                                                    \n",
      "epoch: 0052, loss: 0.5295 - val_loss: 1.0182; auc: 0.9540 - val_auc: 0.8473                                                                                                    \n",
      "epoch: 0053, loss: 0.5129 - val_loss: 0.9804; auc: 0.9549 - val_auc: 0.8491                                                                                                    \n",
      "epoch: 0054, loss: 0.5125 - val_loss: 0.8953; auc: 0.9535 - val_auc: 0.8553                                                                                                    \n",
      "epoch: 0055, loss: 0.5128 - val_loss: 0.9740; auc: 0.9559 - val_auc: 0.8511                                                                                                    \n",
      "epoch: 0056, loss: 0.5006 - val_loss: 0.9838; auc: 0.9566 - val_auc: 0.8510                                                                                                    \n",
      "epoch: 0057, loss: 0.4990 - val_loss: 0.9851; auc: 0.9582 - val_auc: 0.8486                                                                                                    \n",
      "epoch: 0058, loss: 0.4891 - val_loss: 1.1903; auc: 0.9588 - val_auc: 0.8432                                                                                                    \n",
      "epoch: 0059, loss: 0.4898 - val_loss: 0.9737; auc: 0.9597 - val_auc: 0.8492                                                                                                    \n",
      "epoch: 0060, loss: 0.4758 - val_loss: 1.0413; auc: 0.9605 - val_auc: 0.8477                                                                                                    \n",
      "epoch: 0061, loss: 0.4764 - val_loss: 1.0011; auc: 0.9612 - val_auc: 0.8486                                                                                                    \n",
      "epoch: 0062, loss: 0.4723 - val_loss: 0.9435; auc: 0.9610 - val_auc: 0.8522                                                                                                    \n",
      "epoch: 0063, loss: 0.4653 - val_loss: 1.0193; auc: 0.9623 - val_auc: 0.8512                                                                                                    \n",
      "epoch: 0064, loss: 0.4613 - val_loss: 0.9954; auc: 0.9625 - val_auc: 0.8484                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00064: early stopping\n",
      "{'task_name': 'Tox21', 'train_auc': 0.9534785894145443, 'valid_auc': 0.8552976433834781, 'test_auc': 0.8427460460943278, 'metric': 'ROC', '# trainable params': 801068, 'best_epoch': 53, 'batch_size': 128, 'lr': 0.0001, 'weight_decay': 0}\n",
      "6264 783 784\n",
      "epoch: 0001, loss: 1.1746 - val_loss: 1.1551; auc: 0.7238 - val_auc: 0.7146                                                                                                    \n",
      "epoch: 0002, loss: 1.1387 - val_loss: 1.0882; auc: 0.7284 - val_auc: 0.7415                                                                                                    \n",
      "epoch: 0003, loss: 1.0837 - val_loss: 1.0360; auc: 0.7381 - val_auc: 0.7479                                                                                                    \n",
      "epoch: 0004, loss: 1.0453 - val_loss: 1.0051; auc: 0.7537 - val_auc: 0.7664                                                                                                    \n",
      "epoch: 0005, loss: 1.0252 - val_loss: 0.9838; auc: 0.7649 - val_auc: 0.7759                                                                                                    \n",
      "epoch: 0006, loss: 1.0058 - val_loss: 0.9852; auc: 0.7761 - val_auc: 0.7829                                                                                                    \n",
      "epoch: 0007, loss: 0.9906 - val_loss: 0.9530; auc: 0.7833 - val_auc: 0.7914                                                                                                    \n",
      "epoch: 0008, loss: 0.9736 - val_loss: 0.9433; auc: 0.7942 - val_auc: 0.8002                                                                                                    \n",
      "epoch: 0009, loss: 0.9592 - val_loss: 0.9337; auc: 0.8023 - val_auc: 0.8076                                                                                                    \n",
      "epoch: 0010, loss: 0.9468 - val_loss: 0.9152; auc: 0.8140 - val_auc: 0.8183                                                                                                    \n",
      "epoch: 0011, loss: 0.9235 - val_loss: 0.9018; auc: 0.8259 - val_auc: 0.8265                                                                                                    \n",
      "epoch: 0012, loss: 0.9268 - val_loss: 0.9107; auc: 0.8337 - val_auc: 0.8295                                                                                                    \n",
      "epoch: 0013, loss: 0.9021 - val_loss: 0.8939; auc: 0.8414 - val_auc: 0.8360                                                                                                    \n",
      "epoch: 0014, loss: 0.8893 - val_loss: 0.8772; auc: 0.8488 - val_auc: 0.8399                                                                                                    \n",
      "epoch: 0015, loss: 0.8779 - val_loss: 0.8691; auc: 0.8528 - val_auc: 0.8420                                                                                                    \n",
      "epoch: 0016, loss: 0.8647 - val_loss: 0.8664; auc: 0.8563 - val_auc: 0.8441                                                                                                    \n",
      "epoch: 0017, loss: 0.8636 - val_loss: 0.8600; auc: 0.8624 - val_auc: 0.8483                                                                                                    \n",
      "epoch: 0018, loss: 0.8493 - val_loss: 0.8529; auc: 0.8655 - val_auc: 0.8478                                                                                                    \n",
      "epoch: 0019, loss: 0.8328 - val_loss: 0.8562; auc: 0.8732 - val_auc: 0.8494                                                                                                    \n",
      "epoch: 0020, loss: 0.8206 - val_loss: 0.8566; auc: 0.8738 - val_auc: 0.8511                                                                                                    \n",
      "epoch: 0021, loss: 0.8201 - val_loss: 0.8584; auc: 0.8801 - val_auc: 0.8534                                                                                                    \n",
      "epoch: 0022, loss: 0.8070 - val_loss: 0.8478; auc: 0.8804 - val_auc: 0.8531                                                                                                    \n",
      "epoch: 0023, loss: 0.7992 - val_loss: 0.8673; auc: 0.8881 - val_auc: 0.8535                                                                                                    \n",
      "epoch: 0024, loss: 0.7850 - val_loss: 0.8361; auc: 0.8915 - val_auc: 0.8544                                                                                                    \n",
      "epoch: 0025, loss: 0.7735 - val_loss: 0.8450; auc: 0.8922 - val_auc: 0.8571                                                                                                    \n",
      "epoch: 0026, loss: 0.7667 - val_loss: 0.8715; auc: 0.8982 - val_auc: 0.8555                                                                                                    \n",
      "epoch: 0027, loss: 0.7563 - val_loss: 0.8326; auc: 0.8992 - val_auc: 0.8574                                                                                                    \n",
      "epoch: 0028, loss: 0.7533 - val_loss: 0.8376; auc: 0.9008 - val_auc: 0.8583                                                                                                    \n",
      "epoch: 0029, loss: 0.7407 - val_loss: 0.8528; auc: 0.9057 - val_auc: 0.8590                                                                                                    \n",
      "epoch: 0030, loss: 0.7333 - val_loss: 0.8347; auc: 0.9098 - val_auc: 0.8547                                                                                                    \n",
      "epoch: 0031, loss: 0.7149 - val_loss: 0.8223; auc: 0.9113 - val_auc: 0.8596                                                                                                    \n",
      "epoch: 0032, loss: 0.7072 - val_loss: 0.8288; auc: 0.9142 - val_auc: 0.8586                                                                                                    \n",
      "epoch: 0033, loss: 0.6999 - val_loss: 0.8260; auc: 0.9157 - val_auc: 0.8608                                                                                                    \n",
      "epoch: 0034, loss: 0.6904 - val_loss: 0.8344; auc: 0.9184 - val_auc: 0.8589                                                                                                    \n",
      "epoch: 0035, loss: 0.6941 - val_loss: 0.8296; auc: 0.9203 - val_auc: 0.8604                                                                                                    \n",
      "epoch: 0036, loss: 0.6896 - val_loss: 0.8673; auc: 0.9229 - val_auc: 0.8609                                                                                                    \n",
      "epoch: 0037, loss: 0.6677 - val_loss: 0.8206; auc: 0.9242 - val_auc: 0.8599                                                                                                    \n",
      "epoch: 0038, loss: 0.6685 - val_loss: 0.8296; auc: 0.9271 - val_auc: 0.8577                                                                                                    \n",
      "epoch: 0039, loss: 0.6673 - val_loss: 0.8631; auc: 0.9291 - val_auc: 0.8596                                                                                                    \n",
      "epoch: 0040, loss: 0.6423 - val_loss: 0.8316; auc: 0.9306 - val_auc: 0.8598                                                                                                    \n",
      "epoch: 0041, loss: 0.6403 - val_loss: 0.8177; auc: 0.9300 - val_auc: 0.8636                                                                                                    \n",
      "epoch: 0042, loss: 0.6255 - val_loss: 0.8399; auc: 0.9341 - val_auc: 0.8591                                                                                                    \n",
      "epoch: 0043, loss: 0.6214 - val_loss: 0.8361; auc: 0.9354 - val_auc: 0.8592                                                                                                    \n",
      "epoch: 0044, loss: 0.6167 - val_loss: 0.8507; auc: 0.9367 - val_auc: 0.8611                                                                                                    \n",
      "epoch: 0045, loss: 0.6046 - val_loss: 0.8775; auc: 0.9385 - val_auc: 0.8578                                                                                                    \n",
      "epoch: 0046, loss: 0.6038 - val_loss: 0.8831; auc: 0.9401 - val_auc: 0.8562                                                                                                    \n",
      "epoch: 0047, loss: 0.6027 - val_loss: 0.8747; auc: 0.9400 - val_auc: 0.8598                                                                                                    \n",
      "epoch: 0048, loss: 0.5910 - val_loss: 0.9024; auc: 0.9434 - val_auc: 0.8556                                                                                                    \n",
      "epoch: 0049, loss: 0.5864 - val_loss: 0.8450; auc: 0.9422 - val_auc: 0.8606                                                                                                    \n",
      "epoch: 0050, loss: 0.5751 - val_loss: 0.8600; auc: 0.9445 - val_auc: 0.8598                                                                                                    \n",
      "epoch: 0051, loss: 0.5663 - val_loss: 0.8511; auc: 0.9457 - val_auc: 0.8597                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00051: early stopping\n",
      "{'task_name': 'Tox21', 'train_auc': 0.9299751647943265, 'valid_auc': 0.8636192259814454, 'test_auc': 0.8513898971620963, 'metric': 'ROC', '# trainable params': 801068, 'best_epoch': 40, 'batch_size': 128, 'lr': 0.0001, 'weight_decay': 0}\n",
      "6264 783 784\n",
      "epoch: 0001, loss: 1.1750 - val_loss: 1.2259; auc: 0.6922 - val_auc: 0.6844                                                                                                    \n",
      "epoch: 0002, loss: 1.1370 - val_loss: 1.1716; auc: 0.7112 - val_auc: 0.7046                                                                                                    \n",
      "epoch: 0003, loss: 1.0860 - val_loss: 1.1197; auc: 0.7337 - val_auc: 0.7309                                                                                                    \n",
      "epoch: 0004, loss: 1.0515 - val_loss: 1.0933; auc: 0.7502 - val_auc: 0.7511                                                                                                    \n",
      "epoch: 0005, loss: 1.0230 - val_loss: 1.0572; auc: 0.7607 - val_auc: 0.7631                                                                                                    \n",
      "epoch: 0006, loss: 1.0075 - val_loss: 1.0527; auc: 0.7705 - val_auc: 0.7725                                                                                                    \n",
      "epoch: 0007, loss: 0.9981 - val_loss: 1.0591; auc: 0.7874 - val_auc: 0.7874                                                                                                    \n",
      "epoch: 0008, loss: 0.9806 - val_loss: 1.0143; auc: 0.7895 - val_auc: 0.7869                                                                                                    \n",
      "epoch: 0009, loss: 0.9667 - val_loss: 1.0121; auc: 0.7977 - val_auc: 0.7938                                                                                                    \n",
      "epoch: 0010, loss: 0.9537 - val_loss: 1.0038; auc: 0.8074 - val_auc: 0.8017                                                                                                    \n",
      "epoch: 0011, loss: 0.9368 - val_loss: 0.9743; auc: 0.8186 - val_auc: 0.8107                                                                                                    \n",
      "epoch: 0012, loss: 0.9210 - val_loss: 0.9674; auc: 0.8295 - val_auc: 0.8207                                                                                                    \n",
      "epoch: 0013, loss: 0.9086 - val_loss: 0.9435; auc: 0.8346 - val_auc: 0.8233                                                                                                    \n",
      "epoch: 0014, loss: 0.8928 - val_loss: 0.9315; auc: 0.8441 - val_auc: 0.8310                                                                                                    \n",
      "epoch: 0015, loss: 0.8805 - val_loss: 0.9274; auc: 0.8495 - val_auc: 0.8368                                                                                                    \n",
      "epoch: 0016, loss: 0.8670 - val_loss: 0.9248; auc: 0.8539 - val_auc: 0.8355                                                                                                    \n",
      "epoch: 0017, loss: 0.8842 - val_loss: 0.9382; auc: 0.8626 - val_auc: 0.8440                                                                                                    \n",
      "epoch: 0018, loss: 0.8516 - val_loss: 0.9189; auc: 0.8641 - val_auc: 0.8442                                                                                                    \n",
      "epoch: 0019, loss: 0.8338 - val_loss: 0.9144; auc: 0.8728 - val_auc: 0.8503                                                                                                    \n",
      "epoch: 0020, loss: 0.8262 - val_loss: 0.8899; auc: 0.8754 - val_auc: 0.8530                                                                                                    \n",
      "epoch: 0021, loss: 0.8164 - val_loss: 0.8847; auc: 0.8786 - val_auc: 0.8518                                                                                                    \n",
      "epoch: 0022, loss: 0.8031 - val_loss: 0.8811; auc: 0.8820 - val_auc: 0.8528                                                                                                    \n",
      "epoch: 0023, loss: 0.8001 - val_loss: 0.9001; auc: 0.8873 - val_auc: 0.8581                                                                                                    \n",
      "epoch: 0024, loss: 0.7770 - val_loss: 0.8794; auc: 0.8907 - val_auc: 0.8581                                                                                                    \n",
      "epoch: 0025, loss: 0.7715 - val_loss: 0.9092; auc: 0.8952 - val_auc: 0.8616                                                                                                    \n",
      "epoch: 0026, loss: 0.7561 - val_loss: 0.8538; auc: 0.8987 - val_auc: 0.8626                                                                                                    \n",
      "epoch: 0027, loss: 0.7529 - val_loss: 0.8736; auc: 0.9023 - val_auc: 0.8639                                                                                                    \n",
      "epoch: 0028, loss: 0.7496 - val_loss: 0.8900; auc: 0.9057 - val_auc: 0.8640                                                                                                    \n",
      "epoch: 0029, loss: 0.7321 - val_loss: 0.9068; auc: 0.9091 - val_auc: 0.8644                                                                                                    \n",
      "epoch: 0030, loss: 0.7221 - val_loss: 0.8645; auc: 0.9098 - val_auc: 0.8651                                                                                                    \n",
      "epoch: 0031, loss: 0.7149 - val_loss: 0.8736; auc: 0.9142 - val_auc: 0.8671                                                                                                    \n",
      "epoch: 0032, loss: 0.7005 - val_loss: 0.8382; auc: 0.9142 - val_auc: 0.8642                                                                                                    \n",
      "epoch: 0033, loss: 0.6916 - val_loss: 0.9348; auc: 0.9169 - val_auc: 0.8690                                                                                                    \n",
      "epoch: 0034, loss: 0.6865 - val_loss: 0.8718; auc: 0.9192 - val_auc: 0.8666                                                                                                    \n",
      "epoch: 0035, loss: 0.6817 - val_loss: 0.8317; auc: 0.9207 - val_auc: 0.8675                                                                                                    \n",
      "epoch: 0036, loss: 0.6643 - val_loss: 0.8577; auc: 0.9237 - val_auc: 0.8676                                                                                                    \n",
      "epoch: 0037, loss: 0.6577 - val_loss: 0.8557; auc: 0.9260 - val_auc: 0.8655                                                                                                    \n",
      "epoch: 0038, loss: 0.6588 - val_loss: 0.8343; auc: 0.9283 - val_auc: 0.8667                                                                                                    \n",
      "epoch: 0039, loss: 0.6394 - val_loss: 0.8427; auc: 0.9300 - val_auc: 0.8691                                                                                                    \n",
      "epoch: 0040, loss: 0.6332 - val_loss: 0.8403; auc: 0.9308 - val_auc: 0.8665                                                                                                    \n",
      "epoch: 0041, loss: 0.6269 - val_loss: 0.8752; auc: 0.9341 - val_auc: 0.8667                                                                                                    \n",
      "epoch: 0042, loss: 0.6115 - val_loss: 0.8659; auc: 0.9326 - val_auc: 0.8673                                                                                                    \n",
      "epoch: 0043, loss: 0.6080 - val_loss: 0.8369; auc: 0.9366 - val_auc: 0.8705                                                                                                    \n",
      "epoch: 0044, loss: 0.6005 - val_loss: 0.9040; auc: 0.9390 - val_auc: 0.8662                                                                                                    \n",
      "epoch: 0045, loss: 0.5924 - val_loss: 1.0505; auc: 0.9386 - val_auc: 0.8680                                                                                                    \n",
      "epoch: 0046, loss: 0.5814 - val_loss: 0.9768; auc: 0.9428 - val_auc: 0.8667                                                                                                    \n",
      "epoch: 0047, loss: 0.5828 - val_loss: 0.9216; auc: 0.9423 - val_auc: 0.8673                                                                                                    \n",
      "epoch: 0048, loss: 0.5723 - val_loss: 0.9959; auc: 0.9446 - val_auc: 0.8679                                                                                                    \n",
      "epoch: 0049, loss: 0.5599 - val_loss: 1.0112; auc: 0.9453 - val_auc: 0.8673                                                                                                    \n",
      "epoch: 0050, loss: 0.5575 - val_loss: 0.9252; auc: 0.9470 - val_auc: 0.8663                                                                                                    \n",
      "epoch: 0051, loss: 0.5481 - val_loss: 0.9186; auc: 0.9480 - val_auc: 0.8657                                                                                                    \n",
      "epoch: 0052, loss: 0.5530 - val_loss: 0.8870; auc: 0.9475 - val_auc: 0.8677                                                                                                    \n",
      "epoch: 0053, loss: 0.5504 - val_loss: 1.0249; auc: 0.9508 - val_auc: 0.8678                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00053: early stopping\n",
      "{'task_name': 'Tox21', 'train_auc': 0.9365921203306331, 'valid_auc': 0.870505844913724, 'test_auc': 0.8468503034271411, 'metric': 'ROC', '# trainable params': 801068, 'best_epoch': 42, 'batch_size': 128, 'lr': 0.0001, 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "    trainY = Y[train_idx]\n",
    "    validY = Y[valid_idx]\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "    trainX = (X1_new[train_idx], X2_new[train_idx])\n",
    "    validX = (X1_new[valid_idx], X2_new[valid_idx])\n",
    "    testX = (X1_new[test_idx], X2_new[test_idx])    \n",
    "    \n",
    "    \n",
    "    pos_weights, neg_weights = get_pos_weights(trainY)\n",
    "    loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "    \n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "\n",
    "    performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                   (validX, validY), \n",
    "                                                                   patience = patience, \n",
    "                                                                   criteria = monitor,\n",
    "                                                                   metric = metric,\n",
    "                                                                  )\n",
    "    model.fit(trainX, trainY, batch_size=batch_size, \n",
    "          epochs=epochs, verbose= 0, shuffle = True, \n",
    "          validation_data = (validX, validY), \n",
    "          callbacks=[performance]) \n",
    "\n",
    "    \n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "    \n",
    "    train_aucs = performance.evaluate(trainX, trainY)            \n",
    "    valid_aucs = performance.evaluate(validX, validY)            \n",
    "    test_aucs = performance.evaluate(testX, testY)\n",
    "\n",
    "\n",
    "    final_res = {\n",
    "                     'task_name':task_name,            \n",
    "                     'train_auc':np.nanmean(train_aucs), \n",
    "                     'valid_auc':np.nanmean(valid_aucs),                      \n",
    "                     'test_auc':np.nanmean(test_aucs), \n",
    "                     'metric':metric,\n",
    "                     '# trainable params': trainable_params,\n",
    "                     'best_epoch': best_epoch,\n",
    "                     'batch_size':batch_size,\n",
    "                     'lr': lr,\n",
    "                     'weight_decay':weight_decay\n",
    "                    }\n",
    "    \n",
    "    results.append(final_res)\n",
    "    print(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>metric</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tox21</td>\n",
       "      <td>0.953479</td>\n",
       "      <td>0.855298</td>\n",
       "      <td>0.842746</td>\n",
       "      <td>ROC</td>\n",
       "      <td>801068</td>\n",
       "      <td>53</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tox21</td>\n",
       "      <td>0.929975</td>\n",
       "      <td>0.863619</td>\n",
       "      <td>0.851390</td>\n",
       "      <td>ROC</td>\n",
       "      <td>801068</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Tox21</td>\n",
       "      <td>0.936592</td>\n",
       "      <td>0.870506</td>\n",
       "      <td>0.846850</td>\n",
       "      <td>ROC</td>\n",
       "      <td>801068</td>\n",
       "      <td>42</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  train_auc  valid_auc  test_auc metric  # trainable params  \\\n",
       "0     Tox21   0.953479   0.855298  0.842746    ROC              801068   \n",
       "1     Tox21   0.929975   0.863619  0.851390    ROC              801068   \n",
       "2     Tox21   0.936592   0.870506  0.846850    ROC              801068   \n",
       "\n",
       "   best_epoch  batch_size      lr  weight_decay  \n",
       "0          53         128  0.0001             0  \n",
       "1          40         128  0.0001             0  \n",
       "2          42         128  0.0001             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./%s_optimized.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469954155611884"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631409047595492"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).valid_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
