{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "np.random.seed(123)\n",
    "tf.compat.v1.set_random_seed(123)\n",
    "\n",
    "\n",
    "tmp_feature_dir = './tmpignore'\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: FreeSolv number of split times: 3\n"
     ]
    }
   ],
   "source": [
    "task_name = 'FreeSolv'\n",
    "\n",
    "from chembench import load_data\n",
    "\n",
    "df, induces = load_data(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').values\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 800\n",
    "patience = 50 #early stopping\n",
    "\n",
    "dense_layers = [256, 128, 32]\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "loss = 'mse'\n",
    "monitor = 'val_loss'\n",
    "dense_avf = 'relu'\n",
    "last_avf = 'linear'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513 64 65\n",
      "WARNING:tensorflow:From /home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "epoch: 0001, loss: 29.6670 - val_loss: 23.5951; rmse: 5.3053 - rmse_val: 4.8575;  r2: 0.3325 - r2_val: 0.2927                                                                                                    \n",
      "epoch: 0002, loss: 27.5512 - val_loss: 21.5351; rmse: 5.0819 - rmse_val: 4.6406;  r2: 0.3354 - r2_val: 0.2789                                                                                                    \n",
      "epoch: 0003, loss: 24.7973 - val_loss: 18.3580; rmse: 4.7148 - rmse_val: 4.2846;  r2: 0.3202 - r2_val: 0.2779                                                                                                    \n",
      "epoch: 0004, loss: 21.0463 - val_loss: 15.0559; rmse: 4.2862 - rmse_val: 3.8802;  r2: 0.3143 - r2_val: 0.2804                                                                                                    \n",
      "epoch: 0005, loss: 17.2007 - val_loss: 12.1800; rmse: 3.8364 - rmse_val: 3.4900;  r2: 0.3106 - r2_val: 0.2823                                                                                                    \n",
      "epoch: 0006, loss: 14.0271 - val_loss: 11.4324; rmse: 3.6135 - rmse_val: 3.3812;  r2: 0.3101 - r2_val: 0.2837                                                                                                    \n",
      "epoch: 0007, loss: 13.2463 - val_loss: 13.4001; rmse: 3.7659 - rmse_val: 3.6606;  r2: 0.3125 - r2_val: 0.2872                                                                                                    \n",
      "epoch: 0008, loss: 14.2445 - val_loss: 12.6583; rmse: 3.6744 - rmse_val: 3.5579;  r2: 0.3283 - r2_val: 0.3030                                                                                                    \n",
      "epoch: 0009, loss: 12.9629 - val_loss: 10.8150; rmse: 3.4952 - rmse_val: 3.2886;  r2: 0.3499 - r2_val: 0.3222                                                                                                    \n",
      "epoch: 0010, loss: 12.2600 - val_loss: 10.3659; rmse: 3.4445 - rmse_val: 3.2196;  r2: 0.3661 - r2_val: 0.3337                                                                                                    \n",
      "epoch: 0011, loss: 12.0544 - val_loss: 11.4695; rmse: 3.5034 - rmse_val: 3.3867;  r2: 0.3665 - r2_val: 0.3310                                                                                                    \n",
      "epoch: 0012, loss: 12.3642 - val_loss: 11.3267; rmse: 3.4738 - rmse_val: 3.3655;  r2: 0.3825 - r2_val: 0.3430                                                                                                    \n",
      "epoch: 0013, loss: 11.8248 - val_loss: 10.1754; rmse: 3.3544 - rmse_val: 3.1899;  r2: 0.4077 - r2_val: 0.3631                                                                                                    \n",
      "epoch: 0014, loss: 11.2094 - val_loss: 9.7088; rmse: 3.3208 - rmse_val: 3.1159;  r2: 0.4263 - r2_val: 0.3781                                                                                                    \n",
      "epoch: 0015, loss: 10.9747 - val_loss: 9.5169; rmse: 3.2915 - rmse_val: 3.0849;  r2: 0.4338 - r2_val: 0.3847                                                                                                    \n",
      "epoch: 0016, loss: 10.7849 - val_loss: 9.3422; rmse: 3.2612 - rmse_val: 3.0565;  r2: 0.4409 - r2_val: 0.3909                                                                                                    \n",
      "epoch: 0017, loss: 10.5731 - val_loss: 9.2086; rmse: 3.2215 - rmse_val: 3.0346;  r2: 0.4443 - r2_val: 0.3942                                                                                                    \n",
      "epoch: 0018, loss: 10.3300 - val_loss: 9.0408; rmse: 3.1906 - rmse_val: 3.0068;  r2: 0.4515 - r2_val: 0.4005                                                                                                    \n",
      "epoch: 0019, loss: 10.1125 - val_loss: 8.9600; rmse: 3.1518 - rmse_val: 2.9933;  r2: 0.4525 - r2_val: 0.4017                                                                                                    \n",
      "epoch: 0020, loss: 10.0366 - val_loss: 9.2976; rmse: 3.1567 - rmse_val: 3.0492;  r2: 0.4459 - r2_val: 0.3960                                                                                                    \n",
      "epoch: 0021, loss: 9.7729 - val_loss: 8.5532; rmse: 3.0720 - rmse_val: 2.9246;  r2: 0.4566 - r2_val: 0.4062                                                                                                    \n",
      "epoch: 0022, loss: 9.4082 - val_loss: 8.3358; rmse: 3.0767 - rmse_val: 2.8872;  r2: 0.4702 - r2_val: 0.4179                                                                                                    \n",
      "epoch: 0023, loss: 9.4791 - val_loss: 8.1921; rmse: 3.0489 - rmse_val: 2.8622;  r2: 0.4779 - r2_val: 0.4243                                                                                                    \n",
      "epoch: 0024, loss: 9.1807 - val_loss: 8.0388; rmse: 2.9649 - rmse_val: 2.8353;  r2: 0.4762 - r2_val: 0.4245                                                                                                    \n",
      "epoch: 0025, loss: 9.0011 - val_loss: 8.9613; rmse: 3.0501 - rmse_val: 2.9935;  r2: 0.4701 - r2_val: 0.4201                                                                                                    \n",
      "epoch: 0026, loss: 9.1870 - val_loss: 8.1576; rmse: 2.9396 - rmse_val: 2.8561;  r2: 0.4853 - r2_val: 0.4328                                                                                                    \n",
      "epoch: 0027, loss: 8.4751 - val_loss: 7.4947; rmse: 2.8726 - rmse_val: 2.7376;  r2: 0.5048 - r2_val: 0.4496                                                                                                    \n",
      "epoch: 0028, loss: 8.3225 - val_loss: 7.3798; rmse: 2.8612 - rmse_val: 2.7166;  r2: 0.5180 - r2_val: 0.4600                                                                                                    \n",
      "epoch: 0029, loss: 8.0546 - val_loss: 7.3392; rmse: 2.8053 - rmse_val: 2.7091;  r2: 0.5223 - r2_val: 0.4643                                                                                                    \n",
      "epoch: 0030, loss: 7.8578 - val_loss: 7.3389; rmse: 2.7843 - rmse_val: 2.7090;  r2: 0.5307 - r2_val: 0.4715                                                                                                    \n",
      "epoch: 0031, loss: 7.6511 - val_loss: 6.9600; rmse: 2.7371 - rmse_val: 2.6382;  r2: 0.5459 - r2_val: 0.4833                                                                                                    \n",
      "epoch: 0032, loss: 7.5067 - val_loss: 6.8845; rmse: 2.7332 - rmse_val: 2.6238;  r2: 0.5587 - r2_val: 0.4927                                                                                                    \n",
      "epoch: 0033, loss: 7.4334 - val_loss: 6.6542; rmse: 2.6684 - rmse_val: 2.5796;  r2: 0.5678 - r2_val: 0.5018                                                                                                    \n",
      "epoch: 0034, loss: 6.9726 - val_loss: 6.7284; rmse: 2.6312 - rmse_val: 2.5939;  r2: 0.5697 - r2_val: 0.5078                                                                                                    \n",
      "epoch: 0035, loss: 7.1427 - val_loss: 7.2002; rmse: 2.6917 - rmse_val: 2.6833;  r2: 0.5720 - r2_val: 0.5128                                                                                                    \n",
      "epoch: 0036, loss: 7.0145 - val_loss: 6.1715; rmse: 2.5357 - rmse_val: 2.4843;  r2: 0.5933 - r2_val: 0.5284                                                                                                    \n",
      "epoch: 0037, loss: 6.7074 - val_loss: 6.1117; rmse: 2.5259 - rmse_val: 2.4722;  r2: 0.6046 - r2_val: 0.5374                                                                                                    \n",
      "epoch: 0038, loss: 6.5727 - val_loss: 7.3823; rmse: 2.7054 - rmse_val: 2.7170;  r2: 0.5951 - r2_val: 0.5362                                                                                                    \n",
      "epoch: 0039, loss: 7.2085 - val_loss: 6.3068; rmse: 2.5262 - rmse_val: 2.5113;  r2: 0.6098 - r2_val: 0.5502                                                                                                    \n",
      "epoch: 0040, loss: 6.1817 - val_loss: 5.7476; rmse: 2.4435 - rmse_val: 2.3974;  r2: 0.6277 - r2_val: 0.5634                                                                                                    \n",
      "epoch: 0041, loss: 6.0029 - val_loss: 5.7766; rmse: 2.4438 - rmse_val: 2.4035;  r2: 0.6368 - r2_val: 0.5704                                                                                                    \n",
      "epoch: 0042, loss: 5.9117 - val_loss: 5.5003; rmse: 2.3616 - rmse_val: 2.3453;  r2: 0.6423 - r2_val: 0.5779                                                                                                    \n",
      "epoch: 0043, loss: 5.5117 - val_loss: 5.4255; rmse: 2.3383 - rmse_val: 2.3293;  r2: 0.6470 - r2_val: 0.5857                                                                                                    \n",
      "epoch: 0044, loss: 5.4365 - val_loss: 5.2476; rmse: 2.3317 - rmse_val: 2.2908;  r2: 0.6597 - r2_val: 0.6001                                                                                                    \n",
      "epoch: 0045, loss: 5.4849 - val_loss: 5.3195; rmse: 2.3563 - rmse_val: 2.3064;  r2: 0.6653 - r2_val: 0.6096                                                                                                    \n",
      "epoch: 0046, loss: 5.4873 - val_loss: 5.0766; rmse: 2.3080 - rmse_val: 2.2531;  r2: 0.6760 - r2_val: 0.6205                                                                                                    \n",
      "epoch: 0047, loss: 5.3252 - val_loss: 5.0966; rmse: 2.2991 - rmse_val: 2.2576;  r2: 0.6814 - r2_val: 0.6258                                                                                                    \n",
      "epoch: 0048, loss: 5.2424 - val_loss: 5.0121; rmse: 2.2650 - rmse_val: 2.2388;  r2: 0.6863 - r2_val: 0.6293                                                                                                    \n",
      "epoch: 0049, loss: 5.0542 - val_loss: 4.8665; rmse: 2.2085 - rmse_val: 2.2060;  r2: 0.6896 - r2_val: 0.6278                                                                                                    \n",
      "epoch: 0050, loss: 4.8668 - val_loss: 4.8362; rmse: 2.1824 - rmse_val: 2.1991;  r2: 0.6930 - r2_val: 0.6284                                                                                                    \n",
      "epoch: 0051, loss: 4.8131 - val_loss: 5.0188; rmse: 2.2219 - rmse_val: 2.2403;  r2: 0.6978 - r2_val: 0.6379                                                                                                    \n",
      "epoch: 0052, loss: 4.8516 - val_loss: 4.6718; rmse: 2.1396 - rmse_val: 2.1614;  r2: 0.7047 - r2_val: 0.6421                                                                                                    \n",
      "epoch: 0053, loss: 4.5713 - val_loss: 4.6620; rmse: 2.1307 - rmse_val: 2.1592;  r2: 0.7110 - r2_val: 0.6450                                                                                                    \n",
      "epoch: 0054, loss: 4.4801 - val_loss: 4.5242; rmse: 2.0932 - rmse_val: 2.1270;  r2: 0.7160 - r2_val: 0.6528                                                                                                    \n",
      "epoch: 0055, loss: 4.3661 - val_loss: 4.4713; rmse: 2.0755 - rmse_val: 2.1145;  r2: 0.7213 - r2_val: 0.6581                                                                                                    \n",
      "epoch: 0056, loss: 4.2816 - val_loss: 4.4740; rmse: 2.0650 - rmse_val: 2.1152;  r2: 0.7275 - r2_val: 0.6612                                                                                                    \n",
      "epoch: 0057, loss: 4.5733 - val_loss: 4.5595; rmse: 2.0714 - rmse_val: 2.1353;  r2: 0.7304 - r2_val: 0.6633                                                                                                    \n",
      "epoch: 0058, loss: 4.2131 - val_loss: 5.0002; rmse: 2.1872 - rmse_val: 2.2361;  r2: 0.7271 - r2_val: 0.6678                                                                                                    \n",
      "epoch: 0059, loss: 4.7702 - val_loss: 4.3178; rmse: 2.0227 - rmse_val: 2.0779;  r2: 0.7378 - r2_val: 0.6744                                                                                                    \n",
      "epoch: 0060, loss: 4.0791 - val_loss: 4.6276; rmse: 2.1037 - rmse_val: 2.1512;  r2: 0.7470 - r2_val: 0.6771                                                                                                    \n",
      "epoch: 0061, loss: 4.4901 - val_loss: 4.5017; rmse: 2.0685 - rmse_val: 2.1217;  r2: 0.7529 - r2_val: 0.6821                                                                                                    \n",
      "epoch: 0062, loss: 4.2978 - val_loss: 4.1363; rmse: 1.9545 - rmse_val: 2.0338;  r2: 0.7549 - r2_val: 0.6852                                                                                                    \n",
      "epoch: 0063, loss: 3.8613 - val_loss: 4.1200; rmse: 1.9375 - rmse_val: 2.0298;  r2: 0.7557 - r2_val: 0.6865                                                                                                    \n",
      "epoch: 0064, loss: 3.7739 - val_loss: 4.3667; rmse: 1.9943 - rmse_val: 2.0897;  r2: 0.7607 - r2_val: 0.6888                                                                                                    \n",
      "epoch: 0065, loss: 3.8527 - val_loss: 4.0396; rmse: 1.9095 - rmse_val: 2.0099;  r2: 0.7630 - r2_val: 0.6924                                                                                                    \n",
      "epoch: 0066, loss: 3.7287 - val_loss: 4.0439; rmse: 1.9098 - rmse_val: 2.0109;  r2: 0.7676 - r2_val: 0.6967                                                                                                    \n",
      "epoch: 0067, loss: 3.5466 - val_loss: 3.9569; rmse: 1.8853 - rmse_val: 1.9892;  r2: 0.7760 - r2_val: 0.7039                                                                                                    \n",
      "epoch: 0068, loss: 3.5412 - val_loss: 3.8153; rmse: 1.8398 - rmse_val: 1.9533;  r2: 0.7801 - r2_val: 0.7074                                                                                                    \n",
      "epoch: 0069, loss: 3.4764 - val_loss: 3.8340; rmse: 1.8399 - rmse_val: 1.9581;  r2: 0.7833 - r2_val: 0.7101                                                                                                    \n",
      "epoch: 0070, loss: 3.3608 - val_loss: 3.7365; rmse: 1.8093 - rmse_val: 1.9330;  r2: 0.7893 - r2_val: 0.7157                                                                                                    \n",
      "epoch: 0071, loss: 3.2623 - val_loss: 3.6684; rmse: 1.7852 - rmse_val: 1.9153;  r2: 0.7934 - r2_val: 0.7191                                                                                                    \n",
      "epoch: 0072, loss: 3.2819 - val_loss: 3.7425; rmse: 1.7840 - rmse_val: 1.9346;  r2: 0.7945 - r2_val: 0.7201                                                                                                    \n",
      "epoch: 0073, loss: 3.2695 - val_loss: 4.1395; rmse: 1.8974 - rmse_val: 2.0346;  r2: 0.7922 - r2_val: 0.7177                                                                                                    \n",
      "epoch: 0074, loss: 3.5258 - val_loss: 3.5701; rmse: 1.7390 - rmse_val: 1.8895;  r2: 0.8025 - r2_val: 0.7273                                                                                                    \n",
      "epoch: 0075, loss: 3.0620 - val_loss: 4.5990; rmse: 2.0340 - rmse_val: 2.1445;  r2: 0.8074 - r2_val: 0.7337                                                                                                    \n",
      "epoch: 0076, loss: 5.3185 - val_loss: 4.9014; rmse: 2.1724 - rmse_val: 2.2139;  r2: 0.8180 - r2_val: 0.7471                                                                                                    \n",
      "epoch: 0077, loss: 3.9516 - val_loss: 4.0714; rmse: 1.9340 - rmse_val: 2.0178;  r2: 0.8173 - r2_val: 0.7353                                                                                                    \n",
      "epoch: 0078, loss: 3.8604 - val_loss: 3.8416; rmse: 1.8709 - rmse_val: 1.9600;  r2: 0.8205 - r2_val: 0.7390                                                                                                    \n",
      "epoch: 0079, loss: 3.3056 - val_loss: 3.6604; rmse: 1.8276 - rmse_val: 1.9132;  r2: 0.8266 - r2_val: 0.7500                                                                                                    \n",
      "epoch: 0080, loss: 3.4320 - val_loss: 3.4375; rmse: 1.7252 - rmse_val: 1.8540;  r2: 0.8241 - r2_val: 0.7461                                                                                                    \n",
      "epoch: 0081, loss: 3.0514 - val_loss: 3.6712; rmse: 1.7651 - rmse_val: 1.9160;  r2: 0.8149 - r2_val: 0.7361                                                                                                    \n",
      "epoch: 0082, loss: 2.9551 - val_loss: 3.4654; rmse: 1.6743 - rmse_val: 1.8616;  r2: 0.8161 - r2_val: 0.7374                                                                                                    \n",
      "epoch: 0083, loss: 2.8657 - val_loss: 3.6246; rmse: 1.7123 - rmse_val: 1.9038;  r2: 0.8142 - r2_val: 0.7360                                                                                                    \n",
      "epoch: 0084, loss: 2.9223 - val_loss: 3.4392; rmse: 1.6499 - rmse_val: 1.8545;  r2: 0.8214 - r2_val: 0.7420                                                                                                    \n",
      "epoch: 0085, loss: 2.6853 - val_loss: 3.3287; rmse: 1.6193 - rmse_val: 1.8245;  r2: 0.8278 - r2_val: 0.7475                                                                                                    \n",
      "epoch: 0086, loss: 2.7484 - val_loss: 3.3792; rmse: 1.6422 - rmse_val: 1.8383;  r2: 0.8309 - r2_val: 0.7496                                                                                                    \n",
      "epoch: 0087, loss: 2.6479 - val_loss: 4.2355; rmse: 1.8706 - rmse_val: 2.0580;  r2: 0.8389 - r2_val: 0.7567                                                                                                    \n",
      "epoch: 0088, loss: 4.3542 - val_loss: 4.3409; rmse: 1.9324 - rmse_val: 2.0835;  r2: 0.8469 - r2_val: 0.7644                                                                                                    \n",
      "epoch: 0089, loss: 3.1043 - val_loss: 3.2788; rmse: 1.6342 - rmse_val: 1.8107;  r2: 0.8504 - r2_val: 0.7630                                                                                                    \n",
      "epoch: 0090, loss: 2.8566 - val_loss: 3.3728; rmse: 1.6491 - rmse_val: 1.8365;  r2: 0.8512 - r2_val: 0.7619                                                                                                    \n",
      "epoch: 0091, loss: 2.5631 - val_loss: 3.0596; rmse: 1.5342 - rmse_val: 1.7492;  r2: 0.8564 - r2_val: 0.7678                                                                                                    \n",
      "epoch: 0092, loss: 2.3386 - val_loss: 3.0213; rmse: 1.5022 - rmse_val: 1.7382;  r2: 0.8570 - r2_val: 0.7679                                                                                                    \n",
      "epoch: 0093, loss: 2.2908 - val_loss: 3.0455; rmse: 1.4928 - rmse_val: 1.7451;  r2: 0.8569 - r2_val: 0.7672                                                                                                    \n",
      "epoch: 0094, loss: 2.1912 - val_loss: 3.1985; rmse: 1.5222 - rmse_val: 1.7884;  r2: 0.8594 - r2_val: 0.7707                                                                                                    \n",
      "epoch: 0095, loss: 2.3929 - val_loss: 3.1973; rmse: 1.5212 - rmse_val: 1.7881;  r2: 0.8624 - r2_val: 0.7741                                                                                                    \n",
      "epoch: 0096, loss: 2.2639 - val_loss: 2.9300; rmse: 1.4430 - rmse_val: 1.7117;  r2: 0.8662 - r2_val: 0.7772                                                                                                    \n",
      "epoch: 0097, loss: 2.0631 - val_loss: 2.8963; rmse: 1.4366 - rmse_val: 1.7019;  r2: 0.8689 - r2_val: 0.7783                                                                                                    \n",
      "epoch: 0098, loss: 2.1162 - val_loss: 4.0463; rmse: 1.7931 - rmse_val: 2.0115;  r2: 0.8652 - r2_val: 0.7705                                                                                                    \n",
      "epoch: 0099, loss: 5.1869 - val_loss: 4.5848; rmse: 1.9034 - rmse_val: 2.1412;  r2: 0.8575 - r2_val: 0.7564                                                                                                    \n",
      "epoch: 0100, loss: 3.3655 - val_loss: 5.5404; rmse: 2.0016 - rmse_val: 2.3538;  r2: 0.8495 - r2_val: 0.7451                                                                                                    \n",
      "epoch: 0101, loss: 3.0376 - val_loss: 3.7595; rmse: 1.6420 - rmse_val: 1.9389;  r2: 0.8582 - r2_val: 0.7525                                                                                                    \n",
      "epoch: 0102, loss: 2.4643 - val_loss: 3.2874; rmse: 1.4679 - rmse_val: 1.8131;  r2: 0.8601 - r2_val: 0.7554                                                                                                    \n",
      "epoch: 0103, loss: 2.2148 - val_loss: 3.2553; rmse: 1.4748 - rmse_val: 1.8042;  r2: 0.8637 - r2_val: 0.7595                                                                                                    \n",
      "epoch: 0104, loss: 2.1517 - val_loss: 3.0741; rmse: 1.4241 - rmse_val: 1.7533;  r2: 0.8708 - r2_val: 0.7646                                                                                                    \n",
      "epoch: 0105, loss: 2.0813 - val_loss: 2.9879; rmse: 1.3819 - rmse_val: 1.7285;  r2: 0.8769 - r2_val: 0.7704                                                                                                    \n",
      "epoch: 0106, loss: 1.9690 - val_loss: 3.0598; rmse: 1.3882 - rmse_val: 1.7492;  r2: 0.8825 - r2_val: 0.7767                                                                                                    \n",
      "epoch: 0107, loss: 1.8415 - val_loss: 2.9877; rmse: 1.3662 - rmse_val: 1.7285;  r2: 0.8866 - r2_val: 0.7768                                                                                                    \n",
      "epoch: 0108, loss: 1.8103 - val_loss: 2.9600; rmse: 1.3406 - rmse_val: 1.7205;  r2: 0.8908 - r2_val: 0.7829                                                                                                    \n",
      "epoch: 0109, loss: 1.8919 - val_loss: 3.0264; rmse: 1.3729 - rmse_val: 1.7396;  r2: 0.8913 - r2_val: 0.7809                                                                                                    \n",
      "epoch: 0110, loss: 2.9643 - val_loss: 3.2558; rmse: 1.4793 - rmse_val: 1.8044;  r2: 0.8952 - r2_val: 0.7874                                                                                                    \n",
      "epoch: 0111, loss: 1.8211 - val_loss: 3.8305; rmse: 1.6506 - rmse_val: 1.9572;  r2: 0.9010 - r2_val: 0.8062                                                                                                    \n",
      "epoch: 0112, loss: 2.3713 - val_loss: 2.6306; rmse: 1.2583 - rmse_val: 1.6219;  r2: 0.9016 - r2_val: 0.8001                                                                                                    \n",
      "epoch: 0113, loss: 1.8482 - val_loss: 2.5405; rmse: 1.2346 - rmse_val: 1.5939;  r2: 0.9059 - r2_val: 0.8093                                                                                                    \n",
      "epoch: 0114, loss: 2.7175 - val_loss: 2.6895; rmse: 1.3261 - rmse_val: 1.6400;  r2: 0.9091 - r2_val: 0.8217                                                                                                    \n",
      "epoch: 0115, loss: 2.8133 - val_loss: 6.2839; rmse: 2.3680 - rmse_val: 2.5068;  r2: 0.8919 - r2_val: 0.7896                                                                                                    \n",
      "epoch: 0116, loss: 3.9446 - val_loss: 2.8803; rmse: 1.3643 - rmse_val: 1.6971;  r2: 0.8954 - r2_val: 0.8098                                                                                                    \n",
      "epoch: 0117, loss: 2.6693 - val_loss: 3.3348; rmse: 1.5061 - rmse_val: 1.8262;  r2: 0.8931 - r2_val: 0.8088                                                                                                    \n",
      "epoch: 0118, loss: 1.9137 - val_loss: 3.0221; rmse: 1.4728 - rmse_val: 1.7384;  r2: 0.8923 - r2_val: 0.7972                                                                                                    \n",
      "epoch: 0119, loss: 2.0586 - val_loss: 2.6265; rmse: 1.2832 - rmse_val: 1.6207;  r2: 0.8963 - r2_val: 0.8077                                                                                                    \n",
      "epoch: 0120, loss: 2.3230 - val_loss: 4.0262; rmse: 1.7292 - rmse_val: 2.0065;  r2: 0.8973 - r2_val: 0.8159                                                                                                    \n",
      "epoch: 0121, loss: 2.5002 - val_loss: 2.5481; rmse: 1.2492 - rmse_val: 1.5963;  r2: 0.9000 - r2_val: 0.8068                                                                                                    \n",
      "epoch: 0122, loss: 1.6950 - val_loss: 2.6969; rmse: 1.3075 - rmse_val: 1.6422;  r2: 0.9003 - r2_val: 0.8023                                                                                                    \n",
      "epoch: 0123, loss: 1.5852 - val_loss: 2.7601; rmse: 1.3042 - rmse_val: 1.6613;  r2: 0.9050 - r2_val: 0.8128                                                                                                    \n",
      "epoch: 0124, loss: 1.8610 - val_loss: 2.6606; rmse: 1.2612 - rmse_val: 1.6311;  r2: 0.9070 - r2_val: 0.8139                                                                                                    \n",
      "epoch: 0125, loss: 1.5458 - val_loss: 2.5524; rmse: 1.2349 - rmse_val: 1.5976;  r2: 0.9072 - r2_val: 0.8091                                                                                                    \n",
      "epoch: 0126, loss: 1.4636 - val_loss: 2.4365; rmse: 1.1694 - rmse_val: 1.5609;  r2: 0.9102 - r2_val: 0.8149                                                                                                    \n",
      "epoch: 0127, loss: 1.3812 - val_loss: 2.6050; rmse: 1.2227 - rmse_val: 1.6140;  r2: 0.9123 - r2_val: 0.8192                                                                                                    \n",
      "epoch: 0128, loss: 1.5773 - val_loss: 2.5567; rmse: 1.1992 - rmse_val: 1.5990;  r2: 0.9138 - r2_val: 0.8191                                                                                                    \n",
      "epoch: 0129, loss: 1.3633 - val_loss: 2.3943; rmse: 1.1461 - rmse_val: 1.5474;  r2: 0.9145 - r2_val: 0.8166                                                                                                    \n",
      "epoch: 0130, loss: 1.2982 - val_loss: 2.4495; rmse: 1.1595 - rmse_val: 1.5651;  r2: 0.9169 - r2_val: 0.8224                                                                                                    \n",
      "epoch: 0131, loss: 1.3986 - val_loss: 2.4245; rmse: 1.1617 - rmse_val: 1.5571;  r2: 0.9160 - r2_val: 0.8176                                                                                                    \n",
      "epoch: 0132, loss: 2.3926 - val_loss: 3.7246; rmse: 1.6537 - rmse_val: 1.9299;  r2: 0.9084 - r2_val: 0.8055                                                                                                    \n",
      "epoch: 0133, loss: 1.8940 - val_loss: 3.0070; rmse: 1.3365 - rmse_val: 1.7341;  r2: 0.9149 - r2_val: 0.8204                                                                                                    \n",
      "epoch: 0134, loss: 1.7852 - val_loss: 2.3681; rmse: 1.1261 - rmse_val: 1.5389;  r2: 0.9171 - r2_val: 0.8214                                                                                                    \n",
      "epoch: 0135, loss: 1.4226 - val_loss: 3.0130; rmse: 1.4301 - rmse_val: 1.7358;  r2: 0.9165 - r2_val: 0.8166                                                                                                    \n",
      "epoch: 0136, loss: 1.8839 - val_loss: 2.2802; rmse: 1.1402 - rmse_val: 1.5100;  r2: 0.9217 - r2_val: 0.8281                                                                                                    \n",
      "epoch: 0137, loss: 1.3472 - val_loss: 2.6622; rmse: 1.2946 - rmse_val: 1.6316;  r2: 0.9228 - r2_val: 0.8363                                                                                                    \n",
      "epoch: 0138, loss: 1.7520 - val_loss: 2.3013; rmse: 1.1447 - rmse_val: 1.5170;  r2: 0.9243 - r2_val: 0.8350                                                                                                    \n",
      "epoch: 0139, loss: 1.2847 - val_loss: 2.5696; rmse: 1.2652 - rmse_val: 1.6030;  r2: 0.9238 - r2_val: 0.8266                                                                                                    \n",
      "epoch: 0140, loss: 1.5613 - val_loss: 2.1918; rmse: 1.0854 - rmse_val: 1.4805;  r2: 0.9264 - r2_val: 0.8325                                                                                                    \n",
      "epoch: 0141, loss: 1.2274 - val_loss: 2.6638; rmse: 1.2694 - rmse_val: 1.6321;  r2: 0.9277 - r2_val: 0.8387                                                                                                    \n",
      "epoch: 0142, loss: 1.5383 - val_loss: 2.1932; rmse: 1.0648 - rmse_val: 1.4810;  r2: 0.9272 - r2_val: 0.8317                                                                                                    \n",
      "epoch: 0143, loss: 1.3311 - val_loss: 2.6599; rmse: 1.2621 - rmse_val: 1.6309;  r2: 0.9235 - r2_val: 0.8224                                                                                                    \n",
      "epoch: 0144, loss: 1.3651 - val_loss: 2.6817; rmse: 1.2317 - rmse_val: 1.6376;  r2: 0.9280 - r2_val: 0.8341                                                                                                    \n",
      "epoch: 0145, loss: 2.2799 - val_loss: 3.2228; rmse: 1.4446 - rmse_val: 1.7952;  r2: 0.9303 - r2_val: 0.8362                                                                                                    \n",
      "epoch: 0146, loss: 1.5745 - val_loss: 2.4820; rmse: 1.1743 - rmse_val: 1.5754;  r2: 0.9285 - r2_val: 0.8225                                                                                                    \n",
      "epoch: 0147, loss: 1.4084 - val_loss: 2.3326; rmse: 1.1127 - rmse_val: 1.5273;  r2: 0.9300 - r2_val: 0.8246                                                                                                    \n",
      "epoch: 0148, loss: 1.2310 - val_loss: 2.4389; rmse: 1.1576 - rmse_val: 1.5617;  r2: 0.9319 - r2_val: 0.8298                                                                                                    \n",
      "epoch: 0149, loss: 1.2692 - val_loss: 2.2503; rmse: 1.0630 - rmse_val: 1.5001;  r2: 0.9313 - r2_val: 0.8280                                                                                                    \n",
      "epoch: 0150, loss: 1.1266 - val_loss: 2.2395; rmse: 1.0548 - rmse_val: 1.4965;  r2: 0.9315 - r2_val: 0.8288                                                                                                    \n",
      "epoch: 0151, loss: 1.0956 - val_loss: 2.1798; rmse: 1.0227 - rmse_val: 1.4764;  r2: 0.9328 - r2_val: 0.8327                                                                                                    \n",
      "epoch: 0152, loss: 1.0499 - val_loss: 2.2068; rmse: 1.0304 - rmse_val: 1.4855;  r2: 0.9341 - r2_val: 0.8367                                                                                                    \n",
      "epoch: 0153, loss: 1.0614 - val_loss: 2.1461; rmse: 1.0067 - rmse_val: 1.4649;  r2: 0.9350 - r2_val: 0.8378                                                                                                    \n",
      "epoch: 0154, loss: 1.0036 - val_loss: 2.1045; rmse: 0.9966 - rmse_val: 1.4507;  r2: 0.9357 - r2_val: 0.8384                                                                                                    \n",
      "epoch: 0155, loss: 0.9868 - val_loss: 2.0759; rmse: 0.9858 - rmse_val: 1.4408;  r2: 0.9371 - r2_val: 0.8409                                                                                                    \n",
      "epoch: 0156, loss: 0.9710 - val_loss: 2.0702; rmse: 0.9799 - rmse_val: 1.4388;  r2: 0.9383 - r2_val: 0.8426                                                                                                    \n",
      "epoch: 0157, loss: 0.9660 - val_loss: 2.0682; rmse: 0.9716 - rmse_val: 1.4381;  r2: 0.9386 - r2_val: 0.8421                                                                                                    \n",
      "epoch: 0158, loss: 0.9943 - val_loss: 2.1505; rmse: 1.0135 - rmse_val: 1.4665;  r2: 0.9378 - r2_val: 0.8383                                                                                                    \n",
      "epoch: 0159, loss: 0.9940 - val_loss: 2.1139; rmse: 0.9715 - rmse_val: 1.4539;  r2: 0.9392 - r2_val: 0.8418                                                                                                    \n",
      "epoch: 0160, loss: 0.9372 - val_loss: 2.0761; rmse: 0.9583 - rmse_val: 1.4409;  r2: 0.9399 - r2_val: 0.8419                                                                                                    \n",
      "epoch: 0161, loss: 0.9157 - val_loss: 2.0682; rmse: 0.9530 - rmse_val: 1.4381;  r2: 0.9407 - r2_val: 0.8434                                                                                                    \n",
      "epoch: 0162, loss: 0.9165 - val_loss: 2.0549; rmse: 0.9563 - rmse_val: 1.4335;  r2: 0.9408 - r2_val: 0.8432                                                                                                    \n",
      "epoch: 0163, loss: 1.0551 - val_loss: 2.2702; rmse: 1.0806 - rmse_val: 1.5067;  r2: 0.9394 - r2_val: 0.8399                                                                                                    \n",
      "epoch: 0164, loss: 1.0658 - val_loss: 2.1592; rmse: 0.9868 - rmse_val: 1.4694;  r2: 0.9419 - r2_val: 0.8480                                                                                                    \n",
      "epoch: 0165, loss: 1.2099 - val_loss: 2.0140; rmse: 0.9415 - rmse_val: 1.4191;  r2: 0.9427 - r2_val: 0.8495                                                                                                    \n",
      "epoch: 0166, loss: 1.2761 - val_loss: 2.6783; rmse: 1.2941 - rmse_val: 1.6365;  r2: 0.9387 - r2_val: 0.8390                                                                                                    \n",
      "epoch: 0167, loss: 1.2646 - val_loss: 2.4187; rmse: 1.1067 - rmse_val: 1.5552;  r2: 0.9426 - r2_val: 0.8513                                                                                                    \n",
      "epoch: 0168, loss: 1.5160 - val_loss: 2.2163; rmse: 1.0221 - rmse_val: 1.4887;  r2: 0.9427 - r2_val: 0.8495                                                                                                    \n",
      "epoch: 0169, loss: 0.9599 - val_loss: 2.1945; rmse: 1.0481 - rmse_val: 1.4814;  r2: 0.9405 - r2_val: 0.8406                                                                                                    \n",
      "epoch: 0170, loss: 0.9738 - val_loss: 2.0612; rmse: 0.9532 - rmse_val: 1.4357;  r2: 0.9438 - r2_val: 0.8477                                                                                                    \n",
      "epoch: 0171, loss: 0.9570 - val_loss: 2.0466; rmse: 0.9462 - rmse_val: 1.4306;  r2: 0.9447 - r2_val: 0.8486                                                                                                    \n",
      "epoch: 0172, loss: 0.8684 - val_loss: 1.9832; rmse: 0.9253 - rmse_val: 1.4083;  r2: 0.9452 - r2_val: 0.8477                                                                                                    \n",
      "epoch: 0173, loss: 0.8428 - val_loss: 2.0254; rmse: 0.9450 - rmse_val: 1.4232;  r2: 0.9472 - r2_val: 0.8536                                                                                                    \n",
      "epoch: 0174, loss: 0.9236 - val_loss: 1.9697; rmse: 0.9234 - rmse_val: 1.4035;  r2: 0.9476 - r2_val: 0.8551                                                                                                    \n",
      "epoch: 0175, loss: 0.8262 - val_loss: 1.9049; rmse: 0.9035 - rmse_val: 1.3802;  r2: 0.9475 - r2_val: 0.8539                                                                                                    \n",
      "epoch: 0176, loss: 0.8119 - val_loss: 1.9132; rmse: 0.9101 - rmse_val: 1.3832;  r2: 0.9483 - r2_val: 0.8536                                                                                                    \n",
      "epoch: 0177, loss: 0.8995 - val_loss: 1.9270; rmse: 0.9051 - rmse_val: 1.3881;  r2: 0.9496 - r2_val: 0.8530                                                                                                    \n",
      "epoch: 0178, loss: 0.8044 - val_loss: 2.1791; rmse: 1.0130 - rmse_val: 1.4762;  r2: 0.9510 - r2_val: 0.8601                                                                                                    \n",
      "epoch: 0179, loss: 1.0367 - val_loss: 2.1984; rmse: 1.0332 - rmse_val: 1.4827;  r2: 0.9517 - r2_val: 0.8626                                                                                                    \n",
      "epoch: 0180, loss: 1.2421 - val_loss: 1.9260; rmse: 0.9354 - rmse_val: 1.3878;  r2: 0.9517 - r2_val: 0.8619                                                                                                    \n",
      "epoch: 0181, loss: 1.1376 - val_loss: 2.3825; rmse: 1.1795 - rmse_val: 1.5435;  r2: 0.9501 - r2_val: 0.8523                                                                                                    \n",
      "epoch: 0182, loss: 1.0622 - val_loss: 2.1549; rmse: 1.0138 - rmse_val: 1.4680;  r2: 0.9518 - r2_val: 0.8624                                                                                                    \n",
      "epoch: 0183, loss: 1.1308 - val_loss: 1.9834; rmse: 0.9160 - rmse_val: 1.4083;  r2: 0.9516 - r2_val: 0.8588                                                                                                    \n",
      "epoch: 0184, loss: 0.7822 - val_loss: 1.9181; rmse: 0.8964 - rmse_val: 1.3849;  r2: 0.9506 - r2_val: 0.8533                                                                                                    \n",
      "epoch: 0185, loss: 0.7682 - val_loss: 1.9531; rmse: 0.8766 - rmse_val: 1.3975;  r2: 0.9514 - r2_val: 0.8552                                                                                                    \n",
      "epoch: 0186, loss: 0.7542 - val_loss: 2.0872; rmse: 0.9363 - rmse_val: 1.4447;  r2: 0.9522 - r2_val: 0.8571                                                                                                    \n",
      "epoch: 0187, loss: 1.2122 - val_loss: 2.3469; rmse: 1.0802 - rmse_val: 1.5320;  r2: 0.9521 - r2_val: 0.8570                                                                                                    \n",
      "epoch: 0188, loss: 0.9841 - val_loss: 2.0703; rmse: 0.9711 - rmse_val: 1.4389;  r2: 0.9483 - r2_val: 0.8458                                                                                                    \n",
      "epoch: 0189, loss: 0.9760 - val_loss: 2.1841; rmse: 1.0385 - rmse_val: 1.4779;  r2: 0.9477 - r2_val: 0.8450                                                                                                    \n",
      "epoch: 0190, loss: 1.1918 - val_loss: 1.9034; rmse: 0.8964 - rmse_val: 1.3796;  r2: 0.9508 - r2_val: 0.8552                                                                                                    \n",
      "epoch: 0191, loss: 1.0601 - val_loss: 2.4129; rmse: 1.1310 - rmse_val: 1.5533;  r2: 0.9534 - r2_val: 0.8643                                                                                                    \n",
      "epoch: 0192, loss: 1.0315 - val_loss: 2.0758; rmse: 1.0114 - rmse_val: 1.4408;  r2: 0.9526 - r2_val: 0.8539                                                                                                    \n",
      "epoch: 0193, loss: 1.0052 - val_loss: 1.9344; rmse: 0.9052 - rmse_val: 1.3908;  r2: 0.9542 - r2_val: 0.8584                                                                                                    \n",
      "epoch: 0194, loss: 1.1420 - val_loss: 2.2023; rmse: 1.0142 - rmse_val: 1.4840;  r2: 0.9547 - r2_val: 0.8592                                                                                                    \n",
      "epoch: 0195, loss: 0.8624 - val_loss: 2.4232; rmse: 1.1328 - rmse_val: 1.5567;  r2: 0.9495 - r2_val: 0.8432                                                                                                    \n",
      "epoch: 0196, loss: 1.5065 - val_loss: 1.9771; rmse: 0.8732 - rmse_val: 1.4061;  r2: 0.9520 - r2_val: 0.8482                                                                                                    \n",
      "epoch: 0197, loss: 0.9708 - val_loss: 2.8398; rmse: 1.2549 - rmse_val: 1.6852;  r2: 0.9548 - r2_val: 0.8592                                                                                                    \n",
      "epoch: 0198, loss: 1.2537 - val_loss: 1.9582; rmse: 0.8843 - rmse_val: 1.3993;  r2: 0.9532 - r2_val: 0.8509                                                                                                    \n",
      "epoch: 0199, loss: 0.9498 - val_loss: 2.0262; rmse: 0.9351 - rmse_val: 1.4234;  r2: 0.9533 - r2_val: 0.8508                                                                                                    \n",
      "epoch: 0200, loss: 0.7789 - val_loss: 1.9884; rmse: 0.8863 - rmse_val: 1.4101;  r2: 0.9558 - r2_val: 0.8588                                                                                                    \n",
      "epoch: 0201, loss: 0.7444 - val_loss: 1.8439; rmse: 0.8388 - rmse_val: 1.3579;  r2: 0.9558 - r2_val: 0.8586                                                                                                    \n",
      "epoch: 0202, loss: 0.7081 - val_loss: 1.8441; rmse: 0.8366 - rmse_val: 1.3580;  r2: 0.9566 - r2_val: 0.8623                                                                                                    \n",
      "epoch: 0203, loss: 0.7653 - val_loss: 1.8305; rmse: 0.8266 - rmse_val: 1.3530;  r2: 0.9565 - r2_val: 0.8626                                                                                                    \n",
      "epoch: 0204, loss: 0.7720 - val_loss: 1.9257; rmse: 0.9222 - rmse_val: 1.3877;  r2: 0.9546 - r2_val: 0.8587                                                                                                    \n",
      "epoch: 0205, loss: 0.7410 - val_loss: 2.0595; rmse: 0.9224 - rmse_val: 1.4351;  r2: 0.9554 - r2_val: 0.8651                                                                                                    \n",
      "epoch: 0206, loss: 0.8614 - val_loss: 1.8489; rmse: 0.8279 - rmse_val: 1.3597;  r2: 0.9559 - r2_val: 0.8634                                                                                                    \n",
      "epoch: 0207, loss: 0.6939 - val_loss: 1.8413; rmse: 0.8468 - rmse_val: 1.3569;  r2: 0.9566 - r2_val: 0.8609                                                                                                    \n",
      "epoch: 0208, loss: 0.6926 - val_loss: 1.8195; rmse: 0.7995 - rmse_val: 1.3489;  r2: 0.9585 - r2_val: 0.8640                                                                                                    \n",
      "epoch: 0209, loss: 0.6595 - val_loss: 1.8194; rmse: 0.7916 - rmse_val: 1.3489;  r2: 0.9596 - r2_val: 0.8640                                                                                                    \n",
      "epoch: 0210, loss: 0.6253 - val_loss: 1.8488; rmse: 0.8253 - rmse_val: 1.3597;  r2: 0.9596 - r2_val: 0.8600                                                                                                    \n",
      "epoch: 0211, loss: 0.6585 - val_loss: 1.8094; rmse: 0.7760 - rmse_val: 1.3452;  r2: 0.9612 - r2_val: 0.8635                                                                                                    \n",
      "epoch: 0212, loss: 0.6378 - val_loss: 1.7958; rmse: 0.7666 - rmse_val: 1.3401;  r2: 0.9616 - r2_val: 0.8629                                                                                                    \n",
      "epoch: 0213, loss: 0.6705 - val_loss: 2.0513; rmse: 0.9268 - rmse_val: 1.4322;  r2: 0.9606 - r2_val: 0.8565                                                                                                    \n",
      "epoch: 0214, loss: 0.7940 - val_loss: 1.8229; rmse: 0.7650 - rmse_val: 1.3502;  r2: 0.9625 - r2_val: 0.8626                                                                                                    \n",
      "epoch: 0215, loss: 0.6593 - val_loss: 1.8467; rmse: 0.7792 - rmse_val: 1.3589;  r2: 0.9627 - r2_val: 0.8635                                                                                                    \n",
      "epoch: 0216, loss: 0.5941 - val_loss: 1.8291; rmse: 0.7684 - rmse_val: 1.3524;  r2: 0.9625 - r2_val: 0.8600                                                                                                    \n",
      "epoch: 0217, loss: 0.5766 - val_loss: 2.0571; rmse: 0.8700 - rmse_val: 1.4343;  r2: 0.9626 - r2_val: 0.8621                                                                                                    \n",
      "epoch: 0218, loss: 0.7611 - val_loss: 1.8671; rmse: 0.7561 - rmse_val: 1.3664;  r2: 0.9630 - r2_val: 0.8587                                                                                                    \n",
      "epoch: 0219, loss: 0.5840 - val_loss: 1.9191; rmse: 0.8007 - rmse_val: 1.3853;  r2: 0.9630 - r2_val: 0.8558                                                                                                    \n",
      "epoch: 0220, loss: 0.6255 - val_loss: 1.8411; rmse: 0.7475 - rmse_val: 1.3569;  r2: 0.9643 - r2_val: 0.8597                                                                                                    \n",
      "epoch: 0221, loss: 0.5702 - val_loss: 1.8291; rmse: 0.7482 - rmse_val: 1.3524;  r2: 0.9651 - r2_val: 0.8621                                                                                                    \n",
      "epoch: 0222, loss: 0.5644 - val_loss: 1.8331; rmse: 0.7772 - rmse_val: 1.3539;  r2: 0.9653 - r2_val: 0.8613                                                                                                    \n",
      "epoch: 0223, loss: 0.5889 - val_loss: 1.7877; rmse: 0.7347 - rmse_val: 1.3370;  r2: 0.9661 - r2_val: 0.8653                                                                                                    \n",
      "epoch: 0224, loss: 0.5732 - val_loss: 1.8074; rmse: 0.7356 - rmse_val: 1.3444;  r2: 0.9663 - r2_val: 0.8655                                                                                                    \n",
      "epoch: 0225, loss: 0.5232 - val_loss: 1.7979; rmse: 0.7381 - rmse_val: 1.3409;  r2: 0.9662 - r2_val: 0.8625                                                                                                    \n",
      "epoch: 0226, loss: 0.5215 - val_loss: 1.8401; rmse: 0.7397 - rmse_val: 1.3565;  r2: 0.9669 - r2_val: 0.8654                                                                                                    \n",
      "epoch: 0227, loss: 0.5648 - val_loss: 1.7906; rmse: 0.7121 - rmse_val: 1.3381;  r2: 0.9672 - r2_val: 0.8645                                                                                                    \n",
      "epoch: 0228, loss: 0.5140 - val_loss: 1.7933; rmse: 0.7278 - rmse_val: 1.3391;  r2: 0.9672 - r2_val: 0.8629                                                                                                    \n",
      "epoch: 0229, loss: 0.5127 - val_loss: 1.7739; rmse: 0.7029 - rmse_val: 1.3319;  r2: 0.9681 - r2_val: 0.8657                                                                                                    \n",
      "epoch: 0230, loss: 0.4963 - val_loss: 1.7829; rmse: 0.7068 - rmse_val: 1.3353;  r2: 0.9685 - r2_val: 0.8669                                                                                                    \n",
      "epoch: 0231, loss: 0.5137 - val_loss: 1.7513; rmse: 0.6916 - rmse_val: 1.3234;  r2: 0.9688 - r2_val: 0.8660                                                                                                    \n",
      "epoch: 0232, loss: 0.4901 - val_loss: 1.7472; rmse: 0.6984 - rmse_val: 1.3218;  r2: 0.9691 - r2_val: 0.8658                                                                                                    \n",
      "epoch: 0233, loss: 0.4768 - val_loss: 1.8649; rmse: 0.7575 - rmse_val: 1.3656;  r2: 0.9698 - r2_val: 0.8699                                                                                                    \n",
      "epoch: 0234, loss: 0.7092 - val_loss: 1.7391; rmse: 0.6896 - rmse_val: 1.3188;  r2: 0.9694 - r2_val: 0.8676                                                                                                    \n",
      "epoch: 0235, loss: 0.5856 - val_loss: 1.7792; rmse: 0.7331 - rmse_val: 1.3339;  r2: 0.9685 - r2_val: 0.8647                                                                                                    \n",
      "epoch: 0236, loss: 0.5406 - val_loss: 1.9334; rmse: 0.7750 - rmse_val: 1.3905;  r2: 0.9680 - r2_val: 0.8666                                                                                                    \n",
      "epoch: 0237, loss: 0.5339 - val_loss: 1.8236; rmse: 0.6970 - rmse_val: 1.3504;  r2: 0.9687 - r2_val: 0.8634                                                                                                    \n",
      "epoch: 0238, loss: 0.7015 - val_loss: 2.0501; rmse: 0.8317 - rmse_val: 1.4318;  r2: 0.9683 - r2_val: 0.8625                                                                                                    \n",
      "epoch: 0239, loss: 0.5795 - val_loss: 1.9426; rmse: 0.7946 - rmse_val: 1.3938;  r2: 0.9676 - r2_val: 0.8548                                                                                                    \n",
      "epoch: 0240, loss: 0.5967 - val_loss: 1.9267; rmse: 0.7511 - rmse_val: 1.3881;  r2: 0.9680 - r2_val: 0.8581                                                                                                    \n",
      "epoch: 0241, loss: 0.6161 - val_loss: 1.9328; rmse: 0.7361 - rmse_val: 1.3903;  r2: 0.9682 - r2_val: 0.8583                                                                                                    \n",
      "epoch: 0242, loss: 0.5002 - val_loss: 1.8946; rmse: 0.7339 - rmse_val: 1.3764;  r2: 0.9679 - r2_val: 0.8560                                                                                                    \n",
      "epoch: 0243, loss: 0.5667 - val_loss: 1.8432; rmse: 0.6878 - rmse_val: 1.3576;  r2: 0.9689 - r2_val: 0.8600                                                                                                    \n",
      "epoch: 0244, loss: 0.4860 - val_loss: 1.8387; rmse: 0.6869 - rmse_val: 1.3560;  r2: 0.9698 - r2_val: 0.8633                                                                                                    \n",
      "epoch: 0245, loss: 0.4608 - val_loss: 1.7791; rmse: 0.6847 - rmse_val: 1.3338;  r2: 0.9704 - r2_val: 0.8636                                                                                                    \n",
      "epoch: 0246, loss: 0.4612 - val_loss: 1.7831; rmse: 0.6738 - rmse_val: 1.3353;  r2: 0.9713 - r2_val: 0.8673                                                                                                    \n",
      "epoch: 0247, loss: 0.4738 - val_loss: 1.7433; rmse: 0.6574 - rmse_val: 1.3203;  r2: 0.9719 - r2_val: 0.8675                                                                                                    \n",
      "epoch: 0248, loss: 0.4540 - val_loss: 1.7661; rmse: 0.6950 - rmse_val: 1.3289;  r2: 0.9720 - r2_val: 0.8655                                                                                                    \n",
      "epoch: 0249, loss: 0.4655 - val_loss: 1.7927; rmse: 0.6824 - rmse_val: 1.3389;  r2: 0.9729 - r2_val: 0.8701                                                                                                    \n",
      "epoch: 0250, loss: 0.5353 - val_loss: 1.7179; rmse: 0.6502 - rmse_val: 1.3107;  r2: 0.9732 - r2_val: 0.8696                                                                                                    \n",
      "epoch: 0251, loss: 0.4779 - val_loss: 1.7160; rmse: 0.6730 - rmse_val: 1.3100;  r2: 0.9733 - r2_val: 0.8689                                                                                                    \n",
      "epoch: 0252, loss: 0.4626 - val_loss: 1.7968; rmse: 0.6900 - rmse_val: 1.3404;  r2: 0.9736 - r2_val: 0.8715                                                                                                    \n",
      "epoch: 0253, loss: 0.4509 - val_loss: 1.7873; rmse: 0.7026 - rmse_val: 1.3369;  r2: 0.9733 - r2_val: 0.8657                                                                                                    \n",
      "epoch: 0254, loss: 0.4627 - val_loss: 1.7788; rmse: 0.6573 - rmse_val: 1.3337;  r2: 0.9738 - r2_val: 0.8695                                                                                                    \n",
      "epoch: 0255, loss: 0.4620 - val_loss: 1.7252; rmse: 0.6304 - rmse_val: 1.3135;  r2: 0.9740 - r2_val: 0.8692                                                                                                    \n",
      "epoch: 0256, loss: 0.4131 - val_loss: 1.7039; rmse: 0.6252 - rmse_val: 1.3053;  r2: 0.9744 - r2_val: 0.8696                                                                                                    \n",
      "epoch: 0257, loss: 0.4142 - val_loss: 1.8541; rmse: 0.7322 - rmse_val: 1.3617;  r2: 0.9752 - r2_val: 0.8742                                                                                                    \n",
      "epoch: 0258, loss: 0.5310 - val_loss: 1.6794; rmse: 0.6585 - rmse_val: 1.2959;  r2: 0.9753 - r2_val: 0.8727                                                                                                    \n",
      "epoch: 0259, loss: 0.4975 - val_loss: 1.7028; rmse: 0.6823 - rmse_val: 1.3049;  r2: 0.9752 - r2_val: 0.8720                                                                                                    \n",
      "epoch: 0260, loss: 0.4518 - val_loss: 1.6779; rmse: 0.6394 - rmse_val: 1.2953;  r2: 0.9757 - r2_val: 0.8735                                                                                                    \n",
      "epoch: 0261, loss: 0.4202 - val_loss: 1.7046; rmse: 0.6177 - rmse_val: 1.3056;  r2: 0.9755 - r2_val: 0.8703                                                                                                    \n",
      "epoch: 0262, loss: 0.5014 - val_loss: 1.7785; rmse: 0.6493 - rmse_val: 1.3336;  r2: 0.9755 - r2_val: 0.8693                                                                                                    \n",
      "epoch: 0263, loss: 0.4069 - val_loss: 1.7975; rmse: 0.6742 - rmse_val: 1.3407;  r2: 0.9750 - r2_val: 0.8651                                                                                                    \n",
      "epoch: 0264, loss: 0.4083 - val_loss: 1.7935; rmse: 0.6544 - rmse_val: 1.3392;  r2: 0.9752 - r2_val: 0.8694                                                                                                    \n",
      "epoch: 0265, loss: 0.4167 - val_loss: 1.7155; rmse: 0.6124 - rmse_val: 1.3098;  r2: 0.9755 - r2_val: 0.8688                                                                                                    \n",
      "epoch: 0266, loss: 0.3785 - val_loss: 1.7019; rmse: 0.6154 - rmse_val: 1.3046;  r2: 0.9761 - r2_val: 0.8696                                                                                                    \n",
      "epoch: 0267, loss: 0.3819 - val_loss: 1.6898; rmse: 0.6036 - rmse_val: 1.2999;  r2: 0.9767 - r2_val: 0.8724                                                                                                    \n",
      "epoch: 0268, loss: 0.4043 - val_loss: 1.6486; rmse: 0.5998 - rmse_val: 1.2840;  r2: 0.9769 - r2_val: 0.8733                                                                                                    \n",
      "epoch: 0269, loss: 0.4449 - val_loss: 1.6124; rmse: 0.6021 - rmse_val: 1.2698;  r2: 0.9772 - r2_val: 0.8766                                                                                                    \n",
      "epoch: 0270, loss: 0.4770 - val_loss: 1.6620; rmse: 0.6401 - rmse_val: 1.2892;  r2: 0.9772 - r2_val: 0.8787                                                                                                    \n",
      "epoch: 0271, loss: 0.4320 - val_loss: 1.7145; rmse: 0.6945 - rmse_val: 1.3094;  r2: 0.9769 - r2_val: 0.8742                                                                                                    \n",
      "epoch: 0272, loss: 0.4166 - val_loss: 1.6444; rmse: 0.6211 - rmse_val: 1.2824;  r2: 0.9774 - r2_val: 0.8785                                                                                                    \n",
      "epoch: 0273, loss: 0.3758 - val_loss: 1.6548; rmse: 0.6470 - rmse_val: 1.2864;  r2: 0.9770 - r2_val: 0.8752                                                                                                    \n",
      "epoch: 0274, loss: 0.4070 - val_loss: 1.6442; rmse: 0.6095 - rmse_val: 1.2823;  r2: 0.9770 - r2_val: 0.8781                                                                                                    \n",
      "epoch: 0275, loss: 0.3941 - val_loss: 1.6498; rmse: 0.6112 - rmse_val: 1.2844;  r2: 0.9770 - r2_val: 0.8782                                                                                                    \n",
      "epoch: 0276, loss: 0.3620 - val_loss: 1.6594; rmse: 0.6058 - rmse_val: 1.2882;  r2: 0.9774 - r2_val: 0.8776                                                                                                    \n",
      "epoch: 0277, loss: 0.4246 - val_loss: 1.7342; rmse: 0.6109 - rmse_val: 1.3169;  r2: 0.9776 - r2_val: 0.8738                                                                                                    \n",
      "epoch: 0278, loss: 0.3538 - val_loss: 1.8474; rmse: 0.7183 - rmse_val: 1.3592;  r2: 0.9768 - r2_val: 0.8678                                                                                                    \n",
      "epoch: 0279, loss: 0.5413 - val_loss: 1.7353; rmse: 0.6043 - rmse_val: 1.3173;  r2: 0.9784 - r2_val: 0.8737                                                                                                    \n",
      "epoch: 0280, loss: 0.4653 - val_loss: 1.6840; rmse: 0.5810 - rmse_val: 1.2977;  r2: 0.9787 - r2_val: 0.8740                                                                                                    \n",
      "epoch: 0281, loss: 0.3477 - val_loss: 1.6649; rmse: 0.5725 - rmse_val: 1.2903;  r2: 0.9791 - r2_val: 0.8735                                                                                                    \n",
      "epoch: 0282, loss: 0.4657 - val_loss: 1.7460; rmse: 0.6252 - rmse_val: 1.3214;  r2: 0.9791 - r2_val: 0.8722                                                                                                    \n",
      "epoch: 0283, loss: 0.4159 - val_loss: 1.7108; rmse: 0.5975 - rmse_val: 1.3080;  r2: 0.9784 - r2_val: 0.8688                                                                                                    \n",
      "epoch: 0284, loss: 0.4155 - val_loss: 1.8366; rmse: 0.7059 - rmse_val: 1.3552;  r2: 0.9793 - r2_val: 0.8765                                                                                                    \n",
      "epoch: 0285, loss: 0.4092 - val_loss: 1.9239; rmse: 0.7891 - rmse_val: 1.3871;  r2: 0.9779 - r2_val: 0.8688                                                                                                    \n",
      "epoch: 0286, loss: 0.7707 - val_loss: 1.7174; rmse: 0.5933 - rmse_val: 1.3105;  r2: 0.9777 - r2_val: 0.8716                                                                                                    \n",
      "epoch: 0287, loss: 0.5089 - val_loss: 1.8309; rmse: 0.6684 - rmse_val: 1.3531;  r2: 0.9771 - r2_val: 0.8722                                                                                                    \n",
      "epoch: 0288, loss: 0.4024 - val_loss: 1.8506; rmse: 0.7092 - rmse_val: 1.3604;  r2: 0.9766 - r2_val: 0.8671                                                                                                    \n",
      "epoch: 0289, loss: 0.4192 - val_loss: 1.7062; rmse: 0.5884 - rmse_val: 1.3062;  r2: 0.9784 - r2_val: 0.8725                                                                                                    \n",
      "epoch: 0290, loss: 0.3392 - val_loss: 1.6860; rmse: 0.5831 - rmse_val: 1.2985;  r2: 0.9788 - r2_val: 0.8713                                                                                                    \n",
      "epoch: 0291, loss: 0.3532 - val_loss: 1.6540; rmse: 0.5701 - rmse_val: 1.2861;  r2: 0.9797 - r2_val: 0.8733                                                                                                    \n",
      "epoch: 0292, loss: 0.3199 - val_loss: 1.6682; rmse: 0.5656 - rmse_val: 1.2916;  r2: 0.9804 - r2_val: 0.8757                                                                                                    \n",
      "epoch: 0293, loss: 0.3463 - val_loss: 1.6453; rmse: 0.5533 - rmse_val: 1.2827;  r2: 0.9805 - r2_val: 0.8739                                                                                                    \n",
      "epoch: 0294, loss: 0.3615 - val_loss: 1.6446; rmse: 0.5699 - rmse_val: 1.2824;  r2: 0.9808 - r2_val: 0.8746                                                                                                    \n",
      "epoch: 0295, loss: 0.2995 - val_loss: 1.6096; rmse: 0.5565 - rmse_val: 1.2687;  r2: 0.9810 - r2_val: 0.8768                                                                                                    \n",
      "epoch: 0296, loss: 0.4360 - val_loss: 1.6432; rmse: 0.6388 - rmse_val: 1.2819;  r2: 0.9804 - r2_val: 0.8781                                                                                                    \n",
      "epoch: 0297, loss: 0.3466 - val_loss: 1.5877; rmse: 0.5677 - rmse_val: 1.2601;  r2: 0.9806 - r2_val: 0.8827                                                                                                    \n",
      "epoch: 0298, loss: 0.3107 - val_loss: 1.5789; rmse: 0.5653 - rmse_val: 1.2565;  r2: 0.9813 - r2_val: 0.8793                                                                                                    \n",
      "epoch: 0299, loss: 0.3262 - val_loss: 1.5861; rmse: 0.5444 - rmse_val: 1.2594;  r2: 0.9817 - r2_val: 0.8795                                                                                                    \n",
      "epoch: 0300, loss: 0.2980 - val_loss: 1.6367; rmse: 0.5668 - rmse_val: 1.2793;  r2: 0.9821 - r2_val: 0.8805                                                                                                    \n",
      "epoch: 0301, loss: 0.3369 - val_loss: 1.6279; rmse: 0.5827 - rmse_val: 1.2759;  r2: 0.9817 - r2_val: 0.8771                                                                                                    \n",
      "epoch: 0302, loss: 0.4784 - val_loss: 1.5998; rmse: 0.5212 - rmse_val: 1.2648;  r2: 0.9823 - r2_val: 0.8773                                                                                                    \n",
      "epoch: 0303, loss: 0.3421 - val_loss: 1.6625; rmse: 0.5619 - rmse_val: 1.2894;  r2: 0.9828 - r2_val: 0.8797                                                                                                    \n",
      "epoch: 0304, loss: 0.2888 - val_loss: 1.5889; rmse: 0.5268 - rmse_val: 1.2605;  r2: 0.9828 - r2_val: 0.8780                                                                                                    \n",
      "epoch: 0305, loss: 0.2770 - val_loss: 1.5744; rmse: 0.5171 - rmse_val: 1.2547;  r2: 0.9828 - r2_val: 0.8812                                                                                                    \n",
      "epoch: 0306, loss: 0.2914 - val_loss: 1.6204; rmse: 0.5726 - rmse_val: 1.2730;  r2: 0.9822 - r2_val: 0.8780                                                                                                    \n",
      "epoch: 0307, loss: 0.3019 - val_loss: 1.5836; rmse: 0.5180 - rmse_val: 1.2584;  r2: 0.9826 - r2_val: 0.8793                                                                                                    \n",
      "epoch: 0308, loss: 0.2810 - val_loss: 1.5609; rmse: 0.5081 - rmse_val: 1.2494;  r2: 0.9834 - r2_val: 0.8804                                                                                                    \n",
      "epoch: 0309, loss: 0.2778 - val_loss: 1.5730; rmse: 0.5124 - rmse_val: 1.2542;  r2: 0.9839 - r2_val: 0.8806                                                                                                    \n",
      "epoch: 0310, loss: 0.2723 - val_loss: 1.5853; rmse: 0.5107 - rmse_val: 1.2591;  r2: 0.9839 - r2_val: 0.8783                                                                                                    \n",
      "epoch: 0311, loss: 0.2577 - val_loss: 1.5933; rmse: 0.5010 - rmse_val: 1.2623;  r2: 0.9840 - r2_val: 0.8786                                                                                                    \n",
      "epoch: 0312, loss: 0.2572 - val_loss: 1.5778; rmse: 0.4970 - rmse_val: 1.2561;  r2: 0.9842 - r2_val: 0.8788                                                                                                    \n",
      "epoch: 0313, loss: 0.2631 - val_loss: 1.5878; rmse: 0.4978 - rmse_val: 1.2601;  r2: 0.9843 - r2_val: 0.8797                                                                                                    \n",
      "epoch: 0314, loss: 0.2527 - val_loss: 1.5878; rmse: 0.4962 - rmse_val: 1.2601;  r2: 0.9841 - r2_val: 0.8781                                                                                                    \n",
      "epoch: 0315, loss: 0.2486 - val_loss: 1.6461; rmse: 0.5279 - rmse_val: 1.2830;  r2: 0.9842 - r2_val: 0.8797                                                                                                    \n",
      "epoch: 0316, loss: 0.2718 - val_loss: 1.6097; rmse: 0.5045 - rmse_val: 1.2687;  r2: 0.9841 - r2_val: 0.8774                                                                                                    \n",
      "epoch: 0317, loss: 0.2513 - val_loss: 1.5975; rmse: 0.4863 - rmse_val: 1.2639;  r2: 0.9846 - r2_val: 0.8791                                                                                                    \n",
      "epoch: 0318, loss: 0.2371 - val_loss: 1.5875; rmse: 0.4928 - rmse_val: 1.2600;  r2: 0.9852 - r2_val: 0.8814                                                                                                    \n",
      "epoch: 0319, loss: 0.2488 - val_loss: 1.5345; rmse: 0.4817 - rmse_val: 1.2387;  r2: 0.9856 - r2_val: 0.8837                                                                                                    \n",
      "epoch: 0320, loss: 0.2325 - val_loss: 1.5075; rmse: 0.4790 - rmse_val: 1.2278;  r2: 0.9856 - r2_val: 0.8853                                                                                                    \n",
      "epoch: 0321, loss: 0.2303 - val_loss: 1.5075; rmse: 0.4776 - rmse_val: 1.2278;  r2: 0.9856 - r2_val: 0.8842                                                                                                    \n",
      "epoch: 0322, loss: 0.2415 - val_loss: 1.5228; rmse: 0.4684 - rmse_val: 1.2340;  r2: 0.9857 - r2_val: 0.8833                                                                                                    \n",
      "epoch: 0323, loss: 0.2192 - val_loss: 1.5359; rmse: 0.4676 - rmse_val: 1.2393;  r2: 0.9857 - r2_val: 0.8836                                                                                                    \n",
      "epoch: 0324, loss: 0.2187 - val_loss: 1.5361; rmse: 0.4649 - rmse_val: 1.2394;  r2: 0.9859 - r2_val: 0.8836                                                                                                    \n",
      "epoch: 0325, loss: 0.2182 - val_loss: 1.5445; rmse: 0.4637 - rmse_val: 1.2428;  r2: 0.9861 - r2_val: 0.8834                                                                                                    \n",
      "epoch: 0326, loss: 0.2132 - val_loss: 1.5366; rmse: 0.4585 - rmse_val: 1.2396;  r2: 0.9863 - r2_val: 0.8825                                                                                                    \n",
      "epoch: 0327, loss: 0.2100 - val_loss: 1.5383; rmse: 0.4655 - rmse_val: 1.2403;  r2: 0.9864 - r2_val: 0.8820                                                                                                    \n",
      "epoch: 0328, loss: 0.2296 - val_loss: 1.5412; rmse: 0.4586 - rmse_val: 1.2415;  r2: 0.9862 - r2_val: 0.8822                                                                                                    \n",
      "epoch: 0329, loss: 0.2131 - val_loss: 1.5492; rmse: 0.4759 - rmse_val: 1.2447;  r2: 0.9859 - r2_val: 0.8810                                                                                                    \n",
      "epoch: 0330, loss: 0.2425 - val_loss: 1.5635; rmse: 0.4830 - rmse_val: 1.2504;  r2: 0.9865 - r2_val: 0.8833                                                                                                    \n",
      "epoch: 0331, loss: 0.2769 - val_loss: 1.5390; rmse: 0.4663 - rmse_val: 1.2406;  r2: 0.9865 - r2_val: 0.8818                                                                                                    \n",
      "epoch: 0332, loss: 0.2356 - val_loss: 1.5465; rmse: 0.4845 - rmse_val: 1.2436;  r2: 0.9868 - r2_val: 0.8818                                                                                                    \n",
      "epoch: 0333, loss: 0.2226 - val_loss: 1.5643; rmse: 0.4641 - rmse_val: 1.2507;  r2: 0.9872 - r2_val: 0.8838                                                                                                    \n",
      "epoch: 0334, loss: 0.2202 - val_loss: 1.5377; rmse: 0.4497 - rmse_val: 1.2400;  r2: 0.9871 - r2_val: 0.8821                                                                                                    \n",
      "epoch: 0335, loss: 0.2011 - val_loss: 1.5505; rmse: 0.4647 - rmse_val: 1.2452;  r2: 0.9871 - r2_val: 0.8814                                                                                                    \n",
      "epoch: 0336, loss: 0.2344 - val_loss: 1.5856; rmse: 0.4680 - rmse_val: 1.2592;  r2: 0.9870 - r2_val: 0.8828                                                                                                    \n",
      "epoch: 0337, loss: 0.2496 - val_loss: 1.5676; rmse: 0.4602 - rmse_val: 1.2520;  r2: 0.9865 - r2_val: 0.8805                                                                                                    \n",
      "epoch: 0338, loss: 0.2386 - val_loss: 1.5490; rmse: 0.4441 - rmse_val: 1.2446;  r2: 0.9870 - r2_val: 0.8818                                                                                                    \n",
      "epoch: 0339, loss: 0.2038 - val_loss: 1.5522; rmse: 0.4496 - rmse_val: 1.2459;  r2: 0.9877 - r2_val: 0.8841                                                                                                    \n",
      "epoch: 0340, loss: 0.1985 - val_loss: 1.5315; rmse: 0.4404 - rmse_val: 1.2375;  r2: 0.9877 - r2_val: 0.8825                                                                                                    \n",
      "epoch: 0341, loss: 0.1989 - val_loss: 1.5648; rmse: 0.4555 - rmse_val: 1.2509;  r2: 0.9880 - r2_val: 0.8848                                                                                                    \n",
      "epoch: 0342, loss: 0.2212 - val_loss: 1.5375; rmse: 0.4370 - rmse_val: 1.2399;  r2: 0.9881 - r2_val: 0.8845                                                                                                    \n",
      "epoch: 0343, loss: 0.1914 - val_loss: 1.5789; rmse: 0.4997 - rmse_val: 1.2565;  r2: 0.9877 - r2_val: 0.8805                                                                                                    \n",
      "epoch: 0344, loss: 0.3148 - val_loss: 1.5366; rmse: 0.4297 - rmse_val: 1.2396;  r2: 0.9883 - r2_val: 0.8824                                                                                                    \n",
      "epoch: 0345, loss: 0.1879 - val_loss: 1.5498; rmse: 0.4556 - rmse_val: 1.2449;  r2: 0.9885 - r2_val: 0.8847                                                                                                    \n",
      "epoch: 0346, loss: 0.2181 - val_loss: 1.5261; rmse: 0.4290 - rmse_val: 1.2353;  r2: 0.9882 - r2_val: 0.8832                                                                                                    \n",
      "epoch: 0347, loss: 0.1850 - val_loss: 1.6217; rmse: 0.5087 - rmse_val: 1.2735;  r2: 0.9884 - r2_val: 0.8859                                                                                                    \n",
      "epoch: 0348, loss: 0.3115 - val_loss: 1.5103; rmse: 0.4699 - rmse_val: 1.2289;  r2: 0.9880 - r2_val: 0.8846                                                                                                    \n",
      "epoch: 0349, loss: 0.2606 - val_loss: 1.4876; rmse: 0.4478 - rmse_val: 1.2197;  r2: 0.9881 - r2_val: 0.8885                                                                                                    \n",
      "epoch: 0350, loss: 0.2187 - val_loss: 1.5164; rmse: 0.4672 - rmse_val: 1.2314;  r2: 0.9881 - r2_val: 0.8894                                                                                                    \n",
      "epoch: 0351, loss: 0.2106 - val_loss: 1.5770; rmse: 0.5501 - rmse_val: 1.2558;  r2: 0.9873 - r2_val: 0.8828                                                                                                    \n",
      "epoch: 0352, loss: 0.3573 - val_loss: 1.5386; rmse: 0.4578 - rmse_val: 1.2404;  r2: 0.9865 - r2_val: 0.8822                                                                                                    \n",
      "epoch: 0353, loss: 0.2221 - val_loss: 1.6170; rmse: 0.4857 - rmse_val: 1.2716;  r2: 0.9853 - r2_val: 0.8785                                                                                                    \n",
      "epoch: 0354, loss: 0.2404 - val_loss: 1.6162; rmse: 0.4840 - rmse_val: 1.2713;  r2: 0.9861 - r2_val: 0.8793                                                                                                    \n",
      "epoch: 0355, loss: 0.2341 - val_loss: 1.5398; rmse: 0.4408 - rmse_val: 1.2409;  r2: 0.9877 - r2_val: 0.8817                                                                                                    \n",
      "epoch: 0356, loss: 0.1949 - val_loss: 1.5038; rmse: 0.4287 - rmse_val: 1.2263;  r2: 0.9882 - r2_val: 0.8852                                                                                                    \n",
      "epoch: 0357, loss: 0.1852 - val_loss: 1.4812; rmse: 0.4265 - rmse_val: 1.2171;  r2: 0.9881 - r2_val: 0.8867                                                                                                    \n",
      "epoch: 0358, loss: 0.1811 - val_loss: 1.4740; rmse: 0.4220 - rmse_val: 1.2141;  r2: 0.9883 - r2_val: 0.8872                                                                                                    \n",
      "epoch: 0359, loss: 0.1786 - val_loss: 1.4736; rmse: 0.4149 - rmse_val: 1.2139;  r2: 0.9887 - r2_val: 0.8875                                                                                                    \n",
      "epoch: 0360, loss: 0.1707 - val_loss: 1.4696; rmse: 0.4062 - rmse_val: 1.2123;  r2: 0.9892 - r2_val: 0.8878                                                                                                    \n",
      "epoch: 0361, loss: 0.1648 - val_loss: 1.4639; rmse: 0.4079 - rmse_val: 1.2099;  r2: 0.9895 - r2_val: 0.8875                                                                                                    \n",
      "epoch: 0362, loss: 0.1710 - val_loss: 1.4854; rmse: 0.4436 - rmse_val: 1.2188;  r2: 0.9896 - r2_val: 0.8869                                                                                                    \n",
      "epoch: 0363, loss: 0.2199 - val_loss: 1.5068; rmse: 0.4305 - rmse_val: 1.2275;  r2: 0.9895 - r2_val: 0.8887                                                                                                    \n",
      "epoch: 0364, loss: 0.2060 - val_loss: 1.4971; rmse: 0.4289 - rmse_val: 1.2236;  r2: 0.9890 - r2_val: 0.8857                                                                                                    \n",
      "epoch: 0365, loss: 0.2036 - val_loss: 1.5711; rmse: 0.5075 - rmse_val: 1.2534;  r2: 0.9897 - r2_val: 0.8911                                                                                                    \n",
      "epoch: 0366, loss: 0.2977 - val_loss: 1.4404; rmse: 0.4441 - rmse_val: 1.2002;  r2: 0.9896 - r2_val: 0.8904                                                                                                    \n",
      "epoch: 0367, loss: 0.2540 - val_loss: 1.4345; rmse: 0.4360 - rmse_val: 1.1977;  r2: 0.9899 - r2_val: 0.8947                                                                                                    \n",
      "epoch: 0368, loss: 0.2151 - val_loss: 1.4049; rmse: 0.4086 - rmse_val: 1.1853;  r2: 0.9899 - r2_val: 0.8930                                                                                                    \n",
      "epoch: 0369, loss: 0.1806 - val_loss: 1.4525; rmse: 0.4337 - rmse_val: 1.2052;  r2: 0.9902 - r2_val: 0.8944                                                                                                    \n",
      "epoch: 0370, loss: 0.2218 - val_loss: 1.4790; rmse: 0.5003 - rmse_val: 1.2162;  r2: 0.9898 - r2_val: 0.8898                                                                                                    \n",
      "epoch: 0371, loss: 0.3515 - val_loss: 1.4820; rmse: 0.4298 - rmse_val: 1.2174;  r2: 0.9904 - r2_val: 0.8924                                                                                                    \n",
      "epoch: 0372, loss: 0.2526 - val_loss: 1.4457; rmse: 0.3938 - rmse_val: 1.2024;  r2: 0.9902 - r2_val: 0.8889                                                                                                    \n",
      "epoch: 0373, loss: 0.1778 - val_loss: 1.4638; rmse: 0.4069 - rmse_val: 1.2099;  r2: 0.9901 - r2_val: 0.8877                                                                                                    \n",
      "epoch: 0374, loss: 0.1626 - val_loss: 1.4863; rmse: 0.3943 - rmse_val: 1.2191;  r2: 0.9900 - r2_val: 0.8878                                                                                                    \n",
      "epoch: 0375, loss: 0.1553 - val_loss: 1.4834; rmse: 0.4043 - rmse_val: 1.2179;  r2: 0.9900 - r2_val: 0.8864                                                                                                    \n",
      "epoch: 0376, loss: 0.1632 - val_loss: 1.4550; rmse: 0.3811 - rmse_val: 1.2062;  r2: 0.9905 - r2_val: 0.8888                                                                                                    \n",
      "epoch: 0377, loss: 0.1492 - val_loss: 1.4332; rmse: 0.3837 - rmse_val: 1.1971;  r2: 0.9907 - r2_val: 0.8899                                                                                                    \n",
      "epoch: 0378, loss: 0.1462 - val_loss: 1.4398; rmse: 0.3927 - rmse_val: 1.1999;  r2: 0.9909 - r2_val: 0.8924                                                                                                    \n",
      "epoch: 0379, loss: 0.1535 - val_loss: 1.4220; rmse: 0.3722 - rmse_val: 1.1925;  r2: 0.9910 - r2_val: 0.8910                                                                                                    \n",
      "epoch: 0380, loss: 0.1401 - val_loss: 1.4733; rmse: 0.4276 - rmse_val: 1.2138;  r2: 0.9908 - r2_val: 0.8879                                                                                                    \n",
      "epoch: 0381, loss: 0.2093 - val_loss: 1.4811; rmse: 0.3856 - rmse_val: 1.2170;  r2: 0.9907 - r2_val: 0.8874                                                                                                    \n",
      "epoch: 0382, loss: 0.1561 - val_loss: 1.4780; rmse: 0.4050 - rmse_val: 1.2157;  r2: 0.9906 - r2_val: 0.8871                                                                                                    \n",
      "epoch: 0383, loss: 0.1686 - val_loss: 1.4581; rmse: 0.4198 - rmse_val: 1.2075;  r2: 0.9912 - r2_val: 0.8894                                                                                                    \n",
      "epoch: 0384, loss: 0.1910 - val_loss: 1.3873; rmse: 0.3780 - rmse_val: 1.1778;  r2: 0.9913 - r2_val: 0.8960                                                                                                    \n",
      "epoch: 0385, loss: 0.1510 - val_loss: 1.3515; rmse: 0.3735 - rmse_val: 1.1625;  r2: 0.9911 - r2_val: 0.8963                                                                                                    \n",
      "epoch: 0386, loss: 0.1439 - val_loss: 1.3613; rmse: 0.3742 - rmse_val: 1.1668;  r2: 0.9911 - r2_val: 0.8969                                                                                                    \n",
      "epoch: 0387, loss: 0.1402 - val_loss: 1.3566; rmse: 0.3616 - rmse_val: 1.1647;  r2: 0.9914 - r2_val: 0.8963                                                                                                    \n",
      "epoch: 0388, loss: 0.1325 - val_loss: 1.3627; rmse: 0.3611 - rmse_val: 1.1673;  r2: 0.9916 - r2_val: 0.8961                                                                                                    \n",
      "epoch: 0389, loss: 0.1300 - val_loss: 1.3739; rmse: 0.3591 - rmse_val: 1.1722;  r2: 0.9918 - r2_val: 0.8945                                                                                                    \n",
      "epoch: 0390, loss: 0.1288 - val_loss: 1.3851; rmse: 0.3563 - rmse_val: 1.1769;  r2: 0.9919 - r2_val: 0.8936                                                                                                    \n",
      "epoch: 0391, loss: 0.1273 - val_loss: 1.3842; rmse: 0.3518 - rmse_val: 1.1765;  r2: 0.9921 - r2_val: 0.8939                                                                                                    \n",
      "epoch: 0392, loss: 0.1231 - val_loss: 1.3835; rmse: 0.3490 - rmse_val: 1.1762;  r2: 0.9922 - r2_val: 0.8944                                                                                                    \n",
      "epoch: 0393, loss: 0.1214 - val_loss: 1.3810; rmse: 0.3438 - rmse_val: 1.1751;  r2: 0.9923 - r2_val: 0.8945                                                                                                    \n",
      "epoch: 0394, loss: 0.1198 - val_loss: 1.3923; rmse: 0.3507 - rmse_val: 1.1800;  r2: 0.9922 - r2_val: 0.8931                                                                                                    \n",
      "epoch: 0395, loss: 0.1237 - val_loss: 1.4481; rmse: 0.3968 - rmse_val: 1.2034;  r2: 0.9924 - r2_val: 0.8946                                                                                                    \n",
      "epoch: 0396, loss: 0.1700 - val_loss: 1.4513; rmse: 0.3992 - rmse_val: 1.2047;  r2: 0.9920 - r2_val: 0.8899                                                                                                    \n",
      "epoch: 0397, loss: 0.1571 - val_loss: 1.4972; rmse: 0.4311 - rmse_val: 1.2236;  r2: 0.9926 - r2_val: 0.8935                                                                                                    \n",
      "epoch: 0398, loss: 0.1691 - val_loss: 1.4760; rmse: 0.4328 - rmse_val: 1.2149;  r2: 0.9923 - r2_val: 0.8896                                                                                                    \n",
      "epoch: 0399, loss: 0.1720 - val_loss: 1.4526; rmse: 0.3967 - rmse_val: 1.2052;  r2: 0.9929 - r2_val: 0.8945                                                                                                    \n",
      "epoch: 0400, loss: 0.1356 - val_loss: 1.4174; rmse: 0.3690 - rmse_val: 1.1905;  r2: 0.9928 - r2_val: 0.8917                                                                                                    \n",
      "epoch: 0401, loss: 0.1214 - val_loss: 1.4221; rmse: 0.3627 - rmse_val: 1.1925;  r2: 0.9930 - r2_val: 0.8943                                                                                                    \n",
      "epoch: 0402, loss: 0.1192 - val_loss: 1.4206; rmse: 0.3823 - rmse_val: 1.1919;  r2: 0.9929 - r2_val: 0.8920                                                                                                    \n",
      "epoch: 0403, loss: 0.1312 - val_loss: 1.3762; rmse: 0.3263 - rmse_val: 1.1731;  r2: 0.9930 - r2_val: 0.8946                                                                                                    \n",
      "epoch: 0404, loss: 0.1202 - val_loss: 1.4035; rmse: 0.3984 - rmse_val: 1.1847;  r2: 0.9927 - r2_val: 0.8938                                                                                                    \n",
      "epoch: 0405, loss: 0.1585 - val_loss: 1.4381; rmse: 0.3841 - rmse_val: 1.1992;  r2: 0.9923 - r2_val: 0.8945                                                                                                    \n",
      "epoch: 0406, loss: 0.1349 - val_loss: 1.4347; rmse: 0.3633 - rmse_val: 1.1978;  r2: 0.9921 - r2_val: 0.8906                                                                                                    \n",
      "epoch: 0407, loss: 0.1258 - val_loss: 1.4304; rmse: 0.3527 - rmse_val: 1.1960;  r2: 0.9922 - r2_val: 0.8916                                                                                                    \n",
      "epoch: 0408, loss: 0.1242 - val_loss: 1.4099; rmse: 0.3481 - rmse_val: 1.1874;  r2: 0.9924 - r2_val: 0.8933                                                                                                    \n",
      "epoch: 0409, loss: 0.1303 - val_loss: 1.3686; rmse: 0.3515 - rmse_val: 1.1699;  r2: 0.9927 - r2_val: 0.8949                                                                                                    \n",
      "epoch: 0410, loss: 0.1325 - val_loss: 1.3715; rmse: 0.3615 - rmse_val: 1.1711;  r2: 0.9926 - r2_val: 0.8982                                                                                                    \n",
      "epoch: 0411, loss: 0.1338 - val_loss: 1.3480; rmse: 0.3271 - rmse_val: 1.1611;  r2: 0.9930 - r2_val: 0.8971                                                                                                    \n",
      "epoch: 0412, loss: 0.1098 - val_loss: 1.3795; rmse: 0.3406 - rmse_val: 1.1745;  r2: 0.9933 - r2_val: 0.8942                                                                                                    \n",
      "epoch: 0413, loss: 0.1311 - val_loss: 1.4178; rmse: 0.3656 - rmse_val: 1.1907;  r2: 0.9931 - r2_val: 0.8916                                                                                                    \n",
      "epoch: 0414, loss: 0.1595 - val_loss: 1.4936; rmse: 0.3797 - rmse_val: 1.2221;  r2: 0.9930 - r2_val: 0.8912                                                                                                    \n",
      "epoch: 0415, loss: 0.1433 - val_loss: 1.5541; rmse: 0.4719 - rmse_val: 1.2466;  r2: 0.9922 - r2_val: 0.8861                                                                                                    \n",
      "epoch: 0416, loss: 0.2174 - val_loss: 1.4534; rmse: 0.3441 - rmse_val: 1.2056;  r2: 0.9926 - r2_val: 0.8906                                                                                                    \n",
      "epoch: 0417, loss: 0.1249 - val_loss: 1.4345; rmse: 0.3573 - rmse_val: 1.1977;  r2: 0.9920 - r2_val: 0.8920                                                                                                    \n",
      "epoch: 0418, loss: 0.1562 - val_loss: 1.4837; rmse: 0.4316 - rmse_val: 1.2181;  r2: 0.9921 - r2_val: 0.8885                                                                                                    \n",
      "epoch: 0419, loss: 0.2194 - val_loss: 1.5951; rmse: 0.4805 - rmse_val: 1.2630;  r2: 0.9928 - r2_val: 0.8921                                                                                                    \n",
      "epoch: 0420, loss: 0.2274 - val_loss: 1.5208; rmse: 0.4282 - rmse_val: 1.2332;  r2: 0.9924 - r2_val: 0.8859                                                                                                    \n",
      "epoch: 0421, loss: 0.1462 - val_loss: 1.5518; rmse: 0.4479 - rmse_val: 1.2457;  r2: 0.9932 - r2_val: 0.8920                                                                                                    \n",
      "epoch: 0422, loss: 0.1572 - val_loss: 1.5140; rmse: 0.4468 - rmse_val: 1.2305;  r2: 0.9929 - r2_val: 0.8876                                                                                                    \n",
      "epoch: 0423, loss: 0.1496 - val_loss: 1.4966; rmse: 0.4111 - rmse_val: 1.2234;  r2: 0.9935 - r2_val: 0.8933                                                                                                    \n",
      "epoch: 0424, loss: 0.1355 - val_loss: 1.6213; rmse: 0.5585 - rmse_val: 1.2733;  r2: 0.9924 - r2_val: 0.8863                                                                                                    \n",
      "epoch: 0425, loss: 0.2504 - val_loss: 1.4833; rmse: 0.3640 - rmse_val: 1.2179;  r2: 0.9928 - r2_val: 0.8894                                                                                                    \n",
      "epoch: 0426, loss: 0.1391 - val_loss: 1.5653; rmse: 0.4376 - rmse_val: 1.2511;  r2: 0.9929 - r2_val: 0.8900                                                                                                    \n",
      "epoch: 0427, loss: 0.3134 - val_loss: 1.5642; rmse: 0.5005 - rmse_val: 1.2507;  r2: 0.9918 - r2_val: 0.8861                                                                                                    \n",
      "epoch: 0428, loss: 0.2722 - val_loss: 1.4601; rmse: 0.3768 - rmse_val: 1.2083;  r2: 0.9916 - r2_val: 0.8905                                                                                                    \n",
      "epoch: 0429, loss: 0.1359 - val_loss: 1.5819; rmse: 0.4767 - rmse_val: 1.2577;  r2: 0.9910 - r2_val: 0.8828                                                                                                    \n",
      "epoch: 0430, loss: 0.2153 - val_loss: 1.5026; rmse: 0.3742 - rmse_val: 1.2258;  r2: 0.9913 - r2_val: 0.8859                                                                                                    \n",
      "epoch: 0431, loss: 0.1389 - val_loss: 1.4820; rmse: 0.3923 - rmse_val: 1.2174;  r2: 0.9917 - r2_val: 0.8901                                                                                                    \n",
      "epoch: 0432, loss: 0.2072 - val_loss: 1.4068; rmse: 0.3749 - rmse_val: 1.1861;  r2: 0.9918 - r2_val: 0.8924                                                                                                    \n",
      "epoch: 0433, loss: 0.1425 - val_loss: 1.4057; rmse: 0.3892 - rmse_val: 1.1856;  r2: 0.9917 - r2_val: 0.8964                                                                                                    \n",
      "epoch: 0434, loss: 0.1489 - val_loss: 1.6372; rmse: 0.6311 - rmse_val: 1.2795;  r2: 0.9919 - r2_val: 0.8899                                                                                                    \n",
      "epoch: 0435, loss: 0.4321 - val_loss: 2.2644; rmse: 0.9307 - rmse_val: 1.5048;  r2: 0.9898 - r2_val: 0.8924                                                                                                    \n",
      "epoch: 0436, loss: 0.7689 - val_loss: 2.2950; rmse: 0.9547 - rmse_val: 1.5149;  r2: 0.9878 - r2_val: 0.8746                                                                                                    \n",
      "epoch: 0437, loss: 0.6208 - val_loss: 1.8708; rmse: 0.6697 - rmse_val: 1.3678;  r2: 0.9912 - r2_val: 0.8863                                                                                                    \n",
      "epoch: 0438, loss: 0.2752 - val_loss: 1.6080; rmse: 0.5176 - rmse_val: 1.2681;  r2: 0.9916 - r2_val: 0.8827                                                                                                    \n",
      "epoch: 0439, loss: 0.2230 - val_loss: 1.6500; rmse: 0.5878 - rmse_val: 1.2845;  r2: 0.9914 - r2_val: 0.8906                                                                                                    \n",
      "epoch: 0440, loss: 0.2674 - val_loss: 1.5633; rmse: 0.5054 - rmse_val: 1.2503;  r2: 0.9918 - r2_val: 0.8853                                                                                                    \n",
      "epoch: 0441, loss: 0.2173 - val_loss: 1.4998; rmse: 0.3935 - rmse_val: 1.2247;  r2: 0.9923 - r2_val: 0.8893                                                                                                    \n",
      "epoch: 0442, loss: 0.1350 - val_loss: 1.4966; rmse: 0.3867 - rmse_val: 1.2233;  r2: 0.9921 - r2_val: 0.8860                                                                                                    \n",
      "epoch: 0443, loss: 0.1415 - val_loss: 1.6847; rmse: 0.5454 - rmse_val: 1.2980;  r2: 0.9926 - r2_val: 0.8912                                                                                                    \n",
      "epoch: 0444, loss: 0.3008 - val_loss: 1.5459; rmse: 0.4683 - rmse_val: 1.2434;  r2: 0.9924 - r2_val: 0.8862                                                                                                    \n",
      "epoch: 0445, loss: 0.2226 - val_loss: 1.4700; rmse: 0.3546 - rmse_val: 1.2124;  r2: 0.9925 - r2_val: 0.8900                                                                                                    \n",
      "epoch: 0446, loss: 0.1337 - val_loss: 1.4973; rmse: 0.4214 - rmse_val: 1.2236;  r2: 0.9917 - r2_val: 0.8876                                                                                                    \n",
      "epoch: 0447, loss: 0.1750 - val_loss: 1.4936; rmse: 0.3868 - rmse_val: 1.2221;  r2: 0.9919 - r2_val: 0.8897                                                                                                    \n",
      "epoch: 0448, loss: 0.1414 - val_loss: 1.4655; rmse: 0.3570 - rmse_val: 1.2106;  r2: 0.9923 - r2_val: 0.8879                                                                                                    \n",
      "epoch: 0449, loss: 0.1193 - val_loss: 1.5118; rmse: 0.4006 - rmse_val: 1.2295;  r2: 0.9927 - r2_val: 0.8902                                                                                                    \n",
      "epoch: 0450, loss: 0.1507 - val_loss: 1.5220; rmse: 0.4111 - rmse_val: 1.2337;  r2: 0.9927 - r2_val: 0.8854                                                                                                    \n",
      "epoch: 0451, loss: 0.1557 - val_loss: 1.4903; rmse: 0.3670 - rmse_val: 1.2208;  r2: 0.9935 - r2_val: 0.8905                                                                                                    \n",
      "epoch: 0452, loss: 0.1168 - val_loss: 1.4214; rmse: 0.3224 - rmse_val: 1.1922;  r2: 0.9939 - r2_val: 0.8908                                                                                                    \n",
      "epoch: 0453, loss: 0.0943 - val_loss: 1.4837; rmse: 0.3918 - rmse_val: 1.2181;  r2: 0.9942 - r2_val: 0.8946                                                                                                    \n",
      "epoch: 0454, loss: 0.1406 - val_loss: 1.4170; rmse: 0.3138 - rmse_val: 1.1904;  r2: 0.9943 - r2_val: 0.8913                                                                                                    \n",
      "epoch: 0455, loss: 0.0956 - val_loss: 1.4407; rmse: 0.3447 - rmse_val: 1.2003;  r2: 0.9938 - r2_val: 0.8942                                                                                                    \n",
      "epoch: 0456, loss: 0.1108 - val_loss: 1.3939; rmse: 0.3217 - rmse_val: 1.1806;  r2: 0.9938 - r2_val: 0.8929                                                                                                    \n",
      "epoch: 0457, loss: 0.0982 - val_loss: 1.3920; rmse: 0.3110 - rmse_val: 1.1798;  r2: 0.9942 - r2_val: 0.8930                                                                                                    \n",
      "epoch: 0458, loss: 0.1106 - val_loss: 1.4388; rmse: 0.3564 - rmse_val: 1.1995;  r2: 0.9942 - r2_val: 0.8905                                                                                                    \n",
      "epoch: 0459, loss: 0.1474 - val_loss: 1.4598; rmse: 0.4294 - rmse_val: 1.2082;  r2: 0.9931 - r2_val: 0.8907                                                                                                    \n",
      "epoch: 0460, loss: 0.2584 - val_loss: 1.5547; rmse: 0.5285 - rmse_val: 1.2469;  r2: 0.9924 - r2_val: 0.8998                                                                                                    \n",
      "epoch: 0461, loss: 0.2729 - val_loss: 1.4599; rmse: 0.5597 - rmse_val: 1.2083;  r2: 0.9927 - r2_val: 0.8960                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00461: early stopping\n",
      "513 64 65\n",
      "Train on 513 samples, validate on 64 samples\n",
      "Epoch 1/411\n",
      "513/513 [==============================] - 1s 2ms/sample - loss: 28.5087 - val_loss: 25.8998\n",
      "Epoch 2/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 26.4198 - val_loss: 23.9926\n",
      "Epoch 3/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 24.2550 - val_loss: 21.6741\n",
      "Epoch 4/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 21.5144 - val_loss: 18.4661\n",
      "Epoch 5/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 17.6203 - val_loss: 14.6470\n",
      "Epoch 6/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 13.4779 - val_loss: 12.8291\n",
      "Epoch 7/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 12.2346 - val_loss: 13.6130\n",
      "Epoch 8/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 12.2858 - val_loss: 12.6757\n",
      "Epoch 9/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 11.3290 - val_loss: 11.8456\n",
      "Epoch 10/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 10.8084 - val_loss: 11.5618\n",
      "Epoch 11/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 10.6391 - val_loss: 11.8611\n",
      "Epoch 12/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 10.3363 - val_loss: 10.8414\n",
      "Epoch 13/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 9.9558 - val_loss: 10.6888\n",
      "Epoch 14/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 9.6664 - val_loss: 10.5345\n",
      "Epoch 15/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 9.5806 - val_loss: 10.4357\n",
      "Epoch 16/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 9.0556 - val_loss: 9.9126\n",
      "Epoch 17/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 9.0912 - val_loss: 9.9835\n",
      "Epoch 18/411\n",
      "513/513 [==============================] - 0s 298us/sample - loss: 9.1401 - val_loss: 9.5079\n",
      "Epoch 19/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 8.4591 - val_loss: 9.3590\n",
      "Epoch 20/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 8.2700 - val_loss: 9.2419\n",
      "Epoch 21/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 8.5980 - val_loss: 9.0682\n",
      "Epoch 22/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 7.6805 - val_loss: 8.4919\n",
      "Epoch 23/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 7.8604 - val_loss: 8.3005\n",
      "Epoch 24/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 7.3378 - val_loss: 7.7810\n",
      "Epoch 25/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 6.9785 - val_loss: 7.4842\n",
      "Epoch 26/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 6.7285 - val_loss: 7.2560\n",
      "Epoch 27/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 6.5463 - val_loss: 7.0208\n",
      "Epoch 28/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 6.8648 - val_loss: 7.3731\n",
      "Epoch 29/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 6.5093 - val_loss: 6.9909\n",
      "Epoch 30/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 6.4193 - val_loss: 6.8870\n",
      "Epoch 31/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 6.0384 - val_loss: 6.7004\n",
      "Epoch 32/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 6.4885 - val_loss: 6.8636\n",
      "Epoch 33/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 5.8119 - val_loss: 7.0236\n",
      "Epoch 34/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 6.9550 - val_loss: 7.8104\n",
      "Epoch 35/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 6.3652 - val_loss: 5.9672\n",
      "Epoch 36/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 5.4021 - val_loss: 6.0143\n",
      "Epoch 37/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 5.3645 - val_loss: 5.9332\n",
      "Epoch 38/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 5.4136 - val_loss: 6.2000\n",
      "Epoch 39/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 5.1786 - val_loss: 5.8603\n",
      "Epoch 40/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 5.0150 - val_loss: 5.8175\n",
      "Epoch 41/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 5.3072 - val_loss: 6.6530\n",
      "Epoch 42/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 5.2754 - val_loss: 5.4744\n",
      "Epoch 43/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 5.2819 - val_loss: 5.6403\n",
      "Epoch 44/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 4.8081 - val_loss: 5.7879\n",
      "Epoch 45/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 4.7512 - val_loss: 5.3408\n",
      "Epoch 46/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 4.5742 - val_loss: 5.5521\n",
      "Epoch 47/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 4.9268 - val_loss: 5.3738\n",
      "Epoch 48/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 4.7353 - val_loss: 6.1542\n",
      "Epoch 49/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 4.6955 - val_loss: 5.3040\n",
      "Epoch 50/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 4.3039 - val_loss: 5.3279\n",
      "Epoch 51/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 4.2574 - val_loss: 5.2598\n",
      "Epoch 52/411\n",
      "513/513 [==============================] - 0s 293us/sample - loss: 4.0999 - val_loss: 5.2613\n",
      "Epoch 53/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 4.0157 - val_loss: 5.2009\n",
      "Epoch 54/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 3.9710 - val_loss: 5.2329\n",
      "Epoch 55/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 4.0202 - val_loss: 5.6759\n",
      "Epoch 56/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 4.0284 - val_loss: 5.1897\n",
      "Epoch 57/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 3.7634 - val_loss: 5.1628\n",
      "Epoch 58/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 4.3515 - val_loss: 5.4511\n",
      "Epoch 59/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 3.8578 - val_loss: 5.8192\n",
      "Epoch 60/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 3.8967 - val_loss: 5.2270\n",
      "Epoch 61/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 3.6280 - val_loss: 5.1656\n",
      "Epoch 62/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 3.5180 - val_loss: 5.4422\n",
      "Epoch 63/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 4.2654 - val_loss: 5.7715\n",
      "Epoch 64/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 3.5639 - val_loss: 5.2025\n",
      "Epoch 65/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 3.8152 - val_loss: 4.9704\n",
      "Epoch 66/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 3.4740 - val_loss: 5.6326\n",
      "Epoch 67/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 3.5222 - val_loss: 4.9069\n",
      "Epoch 68/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 3.6948 - val_loss: 5.1702\n",
      "Epoch 69/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 3.5771 - val_loss: 5.9090\n",
      "Epoch 70/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 4.0939 - val_loss: 5.4934\n",
      "Epoch 71/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 3.4561 - val_loss: 5.1154\n",
      "Epoch 72/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 3.5105 - val_loss: 4.9647\n",
      "Epoch 73/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 3.1919 - val_loss: 5.3852\n",
      "Epoch 74/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 3.3849 - val_loss: 5.0970\n",
      "Epoch 75/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 3.0088 - val_loss: 4.7797\n",
      "Epoch 76/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 2.8807 - val_loss: 4.7161\n",
      "Epoch 77/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 2.8395 - val_loss: 4.6524\n",
      "Epoch 78/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 2.8814 - val_loss: 4.6117\n",
      "Epoch 79/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 2.7908 - val_loss: 4.5955\n",
      "Epoch 80/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 2.7518 - val_loss: 4.5922\n",
      "Epoch 81/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 2.6826 - val_loss: 4.8455\n",
      "Epoch 82/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 2.6357 - val_loss: 4.4691\n",
      "Epoch 83/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 2.5145 - val_loss: 4.5243\n",
      "Epoch 84/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 2.4905 - val_loss: 4.3532\n",
      "Epoch 85/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 2.5799 - val_loss: 4.3574\n",
      "Epoch 86/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 2.3894 - val_loss: 4.8166\n",
      "Epoch 87/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 2.7270 - val_loss: 4.2819\n",
      "Epoch 88/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 2.5850 - val_loss: 4.2284\n",
      "Epoch 89/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 2.4464 - val_loss: 5.0422\n",
      "Epoch 90/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 2.5323 - val_loss: 4.1659\n",
      "Epoch 91/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 2.3884 - val_loss: 4.2059\n",
      "Epoch 92/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 2.3567 - val_loss: 4.0515\n",
      "Epoch 93/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 2.5071 - val_loss: 3.9688\n",
      "Epoch 94/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 2.2557 - val_loss: 4.2185\n",
      "Epoch 95/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 2.2448 - val_loss: 3.8710\n",
      "Epoch 96/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 2.1275 - val_loss: 3.9466\n",
      "Epoch 97/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 2.2255 - val_loss: 3.8773\n",
      "Epoch 98/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 2.1631 - val_loss: 3.7560\n",
      "Epoch 99/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 2.0266 - val_loss: 4.1619\n",
      "Epoch 100/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 2.1664 - val_loss: 3.7973\n",
      "Epoch 101/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.9440 - val_loss: 3.7217\n",
      "Epoch 102/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 1.9226 - val_loss: 3.8879\n",
      "Epoch 103/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.9166 - val_loss: 3.7093\n",
      "Epoch 104/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.8146 - val_loss: 4.0274\n",
      "Epoch 105/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 3.4867 - val_loss: 4.0411\n",
      "Epoch 106/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 1.9881 - val_loss: 4.8917\n",
      "Epoch 107/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 2.3589 - val_loss: 3.7913\n",
      "Epoch 108/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 2.3212 - val_loss: 3.8073\n",
      "Epoch 109/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 1.8495 - val_loss: 4.5724\n",
      "Epoch 110/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 2.3408 - val_loss: 3.7215\n",
      "Epoch 111/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 1.7453 - val_loss: 3.5845\n",
      "Epoch 112/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 1.7308 - val_loss: 3.7534\n",
      "Epoch 113/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 1.8009 - val_loss: 3.5430\n",
      "Epoch 114/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 1.7687 - val_loss: 3.8739\n",
      "Epoch 115/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 2.0764 - val_loss: 3.5113\n",
      "Epoch 116/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 1.6236 - val_loss: 3.7526\n",
      "Epoch 117/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.5722 - val_loss: 3.4946\n",
      "Epoch 118/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.7631 - val_loss: 3.4125\n",
      "Epoch 119/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.5592 - val_loss: 3.4136\n",
      "Epoch 120/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 1.5870 - val_loss: 3.4611\n",
      "Epoch 121/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 1.5500 - val_loss: 3.9312\n",
      "Epoch 122/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 1.9591 - val_loss: 3.3294\n",
      "Epoch 123/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 1.4593 - val_loss: 3.1961\n",
      "Epoch 124/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 1.5586 - val_loss: 3.4676\n",
      "Epoch 125/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 1.5012 - val_loss: 3.1870\n",
      "Epoch 126/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.4787 - val_loss: 3.4448\n",
      "Epoch 127/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 1.5841 - val_loss: 3.1686\n",
      "Epoch 128/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.3299 - val_loss: 3.1703\n",
      "Epoch 129/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 1.4737 - val_loss: 3.2076\n",
      "Epoch 130/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 1.4369 - val_loss: 3.1576\n",
      "Epoch 131/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 1.5685 - val_loss: 3.1966\n",
      "Epoch 132/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.2692 - val_loss: 3.3491\n",
      "Epoch 133/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 1.2518 - val_loss: 3.3770\n",
      "Epoch 134/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 1.8109 - val_loss: 3.0871\n",
      "Epoch 135/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 1.3795 - val_loss: 3.1782\n",
      "Epoch 136/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 1.2419 - val_loss: 3.0943\n",
      "Epoch 137/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 1.2956 - val_loss: 3.1757\n",
      "Epoch 138/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.4810 - val_loss: 3.1164\n",
      "Epoch 139/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 1.1740 - val_loss: 2.8458\n",
      "Epoch 140/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 1.1547 - val_loss: 2.8215\n",
      "Epoch 141/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 1.0737 - val_loss: 2.8309\n",
      "Epoch 142/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 1.0515 - val_loss: 2.8180\n",
      "Epoch 143/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 1.0401 - val_loss: 2.7284\n",
      "Epoch 144/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 1.0188 - val_loss: 2.7021\n",
      "Epoch 145/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.9865 - val_loss: 2.7728\n",
      "Epoch 146/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.9978 - val_loss: 2.6684\n",
      "Epoch 147/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 1.1146 - val_loss: 2.6357\n",
      "Epoch 148/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.9674 - val_loss: 2.8145\n",
      "Epoch 149/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.0200 - val_loss: 2.8085\n",
      "Epoch 150/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 1.0872 - val_loss: 2.5595\n",
      "Epoch 151/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.9424 - val_loss: 2.5264\n",
      "Epoch 152/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.9414 - val_loss: 3.0490\n",
      "Epoch 153/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 1.3092 - val_loss: 2.5583\n",
      "Epoch 154/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 1.1780 - val_loss: 2.5855\n",
      "Epoch 155/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.9878 - val_loss: 2.9257\n",
      "Epoch 156/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.0541 - val_loss: 2.5050\n",
      "Epoch 157/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 0.9926 - val_loss: 2.6122\n",
      "Epoch 158/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 1.1561 - val_loss: 2.3872\n",
      "Epoch 159/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 1.1298 - val_loss: 2.3621\n",
      "Epoch 160/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.8919 - val_loss: 2.7864\n",
      "Epoch 161/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.9122 - val_loss: 2.4070\n",
      "Epoch 162/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 0.9709 - val_loss: 2.5207\n",
      "Epoch 163/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.8886 - val_loss: 2.3438\n",
      "Epoch 164/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 1.0164 - val_loss: 2.4222\n",
      "Epoch 165/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 1.1157 - val_loss: 2.3573\n",
      "Epoch 166/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 1.1690 - val_loss: 2.3422\n",
      "Epoch 167/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 1.0762 - val_loss: 2.7550\n",
      "Epoch 168/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 1.0752 - val_loss: 2.3213\n",
      "Epoch 169/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.9238 - val_loss: 2.8709\n",
      "Epoch 170/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.9492 - val_loss: 2.3172\n",
      "Epoch 171/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.8681 - val_loss: 2.5843\n",
      "Epoch 172/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 1.0156 - val_loss: 2.3093\n",
      "Epoch 173/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.8517 - val_loss: 2.2645\n",
      "Epoch 174/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.7571 - val_loss: 2.4500\n",
      "Epoch 175/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.7407 - val_loss: 2.2433\n",
      "Epoch 176/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.6789 - val_loss: 2.2133\n",
      "Epoch 177/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.9430 - val_loss: 2.1893\n",
      "Epoch 178/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.6918 - val_loss: 2.3130\n",
      "Epoch 179/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.6654 - val_loss: 2.1972\n",
      "Epoch 180/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.6569 - val_loss: 2.2586\n",
      "Epoch 181/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.6424 - val_loss: 2.2475\n",
      "Epoch 182/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.6679 - val_loss: 2.2646\n",
      "Epoch 183/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.6303 - val_loss: 2.1467\n",
      "Epoch 184/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.6247 - val_loss: 2.1336\n",
      "Epoch 185/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.6253 - val_loss: 2.1290\n",
      "Epoch 186/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.5742 - val_loss: 2.1598\n",
      "Epoch 187/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.5678 - val_loss: 2.1067\n",
      "Epoch 188/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.5763 - val_loss: 2.1824\n",
      "Epoch 189/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.5736 - val_loss: 2.0568\n",
      "Epoch 190/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.5503 - val_loss: 2.0057\n",
      "Epoch 191/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.5645 - val_loss: 2.0051\n",
      "Epoch 192/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.5478 - val_loss: 2.0578\n",
      "Epoch 193/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.5431 - val_loss: 1.9685\n",
      "Epoch 194/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.5318 - val_loss: 2.0074\n",
      "Epoch 195/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.5029 - val_loss: 1.9408\n",
      "Epoch 196/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.5738 - val_loss: 1.9746\n",
      "Epoch 197/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.4877 - val_loss: 1.9460\n",
      "Epoch 198/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.4868 - val_loss: 1.9777\n",
      "Epoch 199/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.4718 - val_loss: 2.2011\n",
      "Epoch 200/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.6881 - val_loss: 2.6676\n",
      "Epoch 201/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 2.5543 - val_loss: 2.2780\n",
      "Epoch 202/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 1.1643 - val_loss: 1.8469\n",
      "Epoch 203/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.9487 - val_loss: 2.3406\n",
      "Epoch 204/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 1.6317 - val_loss: 1.9130\n",
      "Epoch 205/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 1.0414 - val_loss: 2.0456\n",
      "Epoch 206/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.6872 - val_loss: 2.6092\n",
      "Epoch 207/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.8715 - val_loss: 2.2978\n",
      "Epoch 208/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 1.4644 - val_loss: 2.0013\n",
      "Epoch 209/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.1676 - val_loss: 2.0957\n",
      "Epoch 210/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.7801 - val_loss: 2.1211\n",
      "Epoch 211/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.6786 - val_loss: 2.6300\n",
      "Epoch 212/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.7393 - val_loss: 2.4850\n",
      "Epoch 213/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 2.1562 - val_loss: 1.9366\n",
      "Epoch 214/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 1.0620 - val_loss: 2.4534\n",
      "Epoch 215/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.7067 - val_loss: 2.3256\n",
      "Epoch 216/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.8405 - val_loss: 2.3667\n",
      "Epoch 217/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.8177 - val_loss: 1.8928\n",
      "Epoch 218/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.5920 - val_loss: 1.8408\n",
      "Epoch 219/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.5411 - val_loss: 1.8572\n",
      "Epoch 220/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.5780 - val_loss: 1.7364\n",
      "Epoch 221/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.7010 - val_loss: 1.9027\n",
      "Epoch 222/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.6680 - val_loss: 1.7064\n",
      "Epoch 223/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.5477 - val_loss: 1.8526\n",
      "Epoch 224/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.5384 - val_loss: 1.7417\n",
      "Epoch 225/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.4673 - val_loss: 2.0241\n",
      "Epoch 226/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.4879 - val_loss: 1.8186\n",
      "Epoch 227/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.4455 - val_loss: 2.1301\n",
      "Epoch 228/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.7868 - val_loss: 1.8266\n",
      "Epoch 229/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 1.1432 - val_loss: 1.7128\n",
      "Epoch 230/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.8624 - val_loss: 2.5772\n",
      "Epoch 231/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.6829 - val_loss: 1.9133\n",
      "Epoch 232/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.7734 - val_loss: 1.9619\n",
      "Epoch 233/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 0.8223 - val_loss: 1.8747\n",
      "Epoch 234/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.4662 - val_loss: 1.7482\n",
      "Epoch 235/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.5692 - val_loss: 1.7296\n",
      "Epoch 236/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.4516 - val_loss: 1.7206\n",
      "Epoch 237/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.4166 - val_loss: 1.6494\n",
      "Epoch 238/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.4007 - val_loss: 1.7003\n",
      "Epoch 239/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.4119 - val_loss: 1.6600\n",
      "Epoch 240/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.5336 - val_loss: 1.6359\n",
      "Epoch 241/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.3844 - val_loss: 1.6526\n",
      "Epoch 242/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3890 - val_loss: 1.6345\n",
      "Epoch 243/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3866 - val_loss: 1.6493\n",
      "Epoch 244/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.3460 - val_loss: 1.6875\n",
      "Epoch 245/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.8090 - val_loss: 1.7186\n",
      "Epoch 246/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.4231 - val_loss: 2.0645\n",
      "Epoch 247/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.4376 - val_loss: 1.8121\n",
      "Epoch 248/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3731 - val_loss: 1.7871\n",
      "Epoch 249/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.4529 - val_loss: 1.7519\n",
      "Epoch 250/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.4203 - val_loss: 2.6704\n",
      "Epoch 251/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.4678 - val_loss: 1.8401\n",
      "Epoch 252/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.8641 - val_loss: 2.1974\n",
      "Epoch 253/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.6016 - val_loss: 2.2392\n",
      "Epoch 254/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.4618 - val_loss: 1.9071\n",
      "Epoch 255/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.3893 - val_loss: 2.0634\n",
      "Epoch 256/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.4032 - val_loss: 1.7522\n",
      "Epoch 257/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.4496 - val_loss: 1.9332\n",
      "Epoch 258/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.6001 - val_loss: 1.7504\n",
      "Epoch 259/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.6161 - val_loss: 1.7634\n",
      "Epoch 260/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.4046 - val_loss: 1.8997\n",
      "Epoch 261/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.4302 - val_loss: 2.0274\n",
      "Epoch 262/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.8984 - val_loss: 1.9356\n",
      "Epoch 263/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.7684 - val_loss: 1.6973\n",
      "Epoch 264/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.7124 - val_loss: 1.8797\n",
      "Epoch 265/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.4839 - val_loss: 1.9864\n",
      "Epoch 266/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.4166 - val_loss: 1.6263\n",
      "Epoch 267/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.4333 - val_loss: 1.7122\n",
      "Epoch 268/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3904 - val_loss: 1.8436\n",
      "Epoch 269/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.3217 - val_loss: 1.6442\n",
      "Epoch 270/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.3140 - val_loss: 1.7420\n",
      "Epoch 271/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.2961 - val_loss: 1.7254\n",
      "Epoch 272/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 0.2784 - val_loss: 1.6783\n",
      "Epoch 273/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 0.2722 - val_loss: 1.8138\n",
      "Epoch 274/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.4113 - val_loss: 1.6571\n",
      "Epoch 275/411\n",
      "513/513 [==============================] - 0s 249us/sample - loss: 0.3889 - val_loss: 1.6372\n",
      "Epoch 276/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.3046 - val_loss: 1.9470\n",
      "Epoch 277/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.3846 - val_loss: 1.6204\n",
      "Epoch 278/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.3416 - val_loss: 1.6483\n",
      "Epoch 279/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2815 - val_loss: 1.7107\n",
      "Epoch 280/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2583 - val_loss: 1.6246\n",
      "Epoch 281/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2915 - val_loss: 1.7398\n",
      "Epoch 282/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2780 - val_loss: 1.6896\n",
      "Epoch 283/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.2354 - val_loss: 1.6509\n",
      "Epoch 284/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2448 - val_loss: 1.6361\n",
      "Epoch 285/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 0.2561 - val_loss: 2.0092\n",
      "Epoch 286/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 1.0646 - val_loss: 1.6019\n",
      "Epoch 287/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.5293 - val_loss: 1.5844\n",
      "Epoch 288/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.3758 - val_loss: 1.9032\n",
      "Epoch 289/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.3153 - val_loss: 1.6652\n",
      "Epoch 290/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.4509 - val_loss: 1.6854\n",
      "Epoch 291/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.3040 - val_loss: 1.5917\n",
      "Epoch 292/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.2669 - val_loss: 1.5825\n",
      "Epoch 293/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.2501 - val_loss: 1.6295\n",
      "Epoch 294/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.2351 - val_loss: 1.5333\n",
      "Epoch 295/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2297 - val_loss: 1.5700\n",
      "Epoch 296/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2270 - val_loss: 1.7866\n",
      "Epoch 297/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.5427 - val_loss: 1.7691\n",
      "Epoch 298/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.4034 - val_loss: 1.7583\n",
      "Epoch 299/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.4102 - val_loss: 1.7283\n",
      "Epoch 300/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.4635 - val_loss: 1.6334\n",
      "Epoch 301/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.3223 - val_loss: 1.7647\n",
      "Epoch 302/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2690 - val_loss: 1.5755\n",
      "Epoch 303/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.3752 - val_loss: 1.8630\n",
      "Epoch 304/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.2523 - val_loss: 1.7794\n",
      "Epoch 305/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.3135 - val_loss: 2.0305\n",
      "Epoch 306/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.3266 - val_loss: 1.7923\n",
      "Epoch 307/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.5788 - val_loss: 1.7784\n",
      "Epoch 308/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.3195 - val_loss: 2.0501\n",
      "Epoch 309/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.2486 - val_loss: 1.7540\n",
      "Epoch 310/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2509 - val_loss: 1.8663\n",
      "Epoch 311/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.2695 - val_loss: 1.8220\n",
      "Epoch 312/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.2888 - val_loss: 1.8770\n",
      "Epoch 313/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.2677 - val_loss: 1.7252\n",
      "Epoch 314/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.2489 - val_loss: 1.9289\n",
      "Epoch 315/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.2370 - val_loss: 1.6457\n",
      "Epoch 316/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.2127 - val_loss: 1.6928\n",
      "Epoch 317/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2002 - val_loss: 1.5839\n",
      "Epoch 318/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.4109 - val_loss: 1.9383\n",
      "Epoch 319/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.9418 - val_loss: 1.5531\n",
      "Epoch 320/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.6304 - val_loss: 1.5643\n",
      "Epoch 321/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 0.3808 - val_loss: 2.1337\n",
      "Epoch 322/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.3483 - val_loss: 1.6650\n",
      "Epoch 323/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.3908 - val_loss: 1.7158\n",
      "Epoch 324/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2682 - val_loss: 1.5608\n",
      "Epoch 325/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.2835 - val_loss: 1.6569\n",
      "Epoch 326/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.2895 - val_loss: 1.5708\n",
      "Epoch 327/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3639 - val_loss: 1.6073\n",
      "Epoch 328/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.2630 - val_loss: 1.7423\n",
      "Epoch 329/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.2367 - val_loss: 1.5876\n",
      "Epoch 330/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.2842 - val_loss: 1.7488\n",
      "Epoch 331/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.3883 - val_loss: 1.5025\n",
      "Epoch 332/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.3183 - val_loss: 1.4668\n",
      "Epoch 333/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.2294 - val_loss: 1.6442\n",
      "Epoch 334/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.2130 - val_loss: 1.4630\n",
      "Epoch 335/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.2281 - val_loss: 1.5483\n",
      "Epoch 336/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1757 - val_loss: 1.4897\n",
      "Epoch 337/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1720 - val_loss: 1.5405\n",
      "Epoch 338/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1737 - val_loss: 1.4990\n",
      "Epoch 339/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.1646 - val_loss: 1.4310\n",
      "Epoch 340/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2314 - val_loss: 1.5024\n",
      "Epoch 341/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.2104 - val_loss: 1.4767\n",
      "Epoch 342/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3201 - val_loss: 1.5036\n",
      "Epoch 343/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2061 - val_loss: 1.6340\n",
      "Epoch 344/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.1801 - val_loss: 1.5441\n",
      "Epoch 345/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.2120 - val_loss: 1.7908\n",
      "Epoch 346/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3022 - val_loss: 1.5007\n",
      "Epoch 347/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.2687 - val_loss: 1.5432\n",
      "Epoch 348/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.2232 - val_loss: 1.6310\n",
      "Epoch 349/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1717 - val_loss: 1.5499\n",
      "Epoch 350/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.1950 - val_loss: 1.6718\n",
      "Epoch 351/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.1809 - val_loss: 1.5898\n",
      "Epoch 352/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1757 - val_loss: 1.7601\n",
      "Epoch 353/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.1880 - val_loss: 1.5708\n",
      "Epoch 354/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.3429 - val_loss: 1.6002\n",
      "Epoch 355/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1926 - val_loss: 1.5919\n",
      "Epoch 356/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1720 - val_loss: 1.5375\n",
      "Epoch 357/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.1509 - val_loss: 1.6052\n",
      "Epoch 358/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1450 - val_loss: 1.5490\n",
      "Epoch 359/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1406 - val_loss: 1.5798\n",
      "Epoch 360/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1360 - val_loss: 1.4568\n",
      "Epoch 361/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1961 - val_loss: 1.3790\n",
      "Epoch 362/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.1640 - val_loss: 1.2894\n",
      "Epoch 363/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1469 - val_loss: 1.2267\n",
      "Epoch 364/411\n",
      "513/513 [==============================] - 0s 285us/sample - loss: 0.1521 - val_loss: 1.3282\n",
      "Epoch 365/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 0.1472 - val_loss: 1.3170\n",
      "Epoch 366/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.1229 - val_loss: 1.3865\n",
      "Epoch 367/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.1709 - val_loss: 1.2887\n",
      "Epoch 368/411\n",
      "513/513 [==============================] - 0s 298us/sample - loss: 0.1678 - val_loss: 1.4202\n",
      "Epoch 369/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.2213 - val_loss: 1.2991\n",
      "Epoch 370/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 0.1888 - val_loss: 1.3833\n",
      "Epoch 371/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 0.1602 - val_loss: 1.4072\n",
      "Epoch 372/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1291 - val_loss: 1.3767\n",
      "Epoch 373/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 0.1179 - val_loss: 1.4661\n",
      "Epoch 374/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1197 - val_loss: 1.3718\n",
      "Epoch 375/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.1781 - val_loss: 1.5062\n",
      "Epoch 376/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1700 - val_loss: 1.3953\n",
      "Epoch 377/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1231 - val_loss: 1.4122\n",
      "Epoch 378/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.1180 - val_loss: 1.4354\n",
      "Epoch 379/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1060 - val_loss: 1.4751\n",
      "Epoch 380/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.1668 - val_loss: 1.3651\n",
      "Epoch 381/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2338 - val_loss: 1.5903\n",
      "Epoch 382/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3081 - val_loss: 1.4265\n",
      "Epoch 383/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.2612 - val_loss: 1.5308\n",
      "Epoch 384/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1896 - val_loss: 1.4611\n",
      "Epoch 385/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.2752 - val_loss: 1.5003\n",
      "Epoch 386/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1892 - val_loss: 1.4558\n",
      "Epoch 387/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1642 - val_loss: 1.4503\n",
      "Epoch 388/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1719 - val_loss: 1.4331\n",
      "Epoch 389/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.2133 - val_loss: 1.4663\n",
      "Epoch 390/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.1477 - val_loss: 1.5886\n",
      "Epoch 391/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1117 - val_loss: 1.4590\n",
      "Epoch 392/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.1159 - val_loss: 1.5898\n",
      "Epoch 393/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.1093 - val_loss: 1.4561\n",
      "Epoch 394/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1095 - val_loss: 1.5878\n",
      "Epoch 395/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1374 - val_loss: 1.5113\n",
      "Epoch 396/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1072 - val_loss: 1.4725\n",
      "Epoch 397/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 0.1030 - val_loss: 1.5089\n",
      "Epoch 398/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 0.1013 - val_loss: 1.4826\n",
      "Epoch 399/411\n",
      "513/513 [==============================] - 0s 249us/sample - loss: 0.0983 - val_loss: 1.4881\n",
      "Epoch 400/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.0937 - val_loss: 1.5271\n",
      "Epoch 401/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.0979 - val_loss: 1.4478\n",
      "Epoch 402/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1516 - val_loss: 1.5605\n",
      "Epoch 403/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1144 - val_loss: 1.4738\n",
      "Epoch 404/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.1494 - val_loss: 1.5985\n",
      "Epoch 405/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.1342 - val_loss: 1.4664\n",
      "Epoch 406/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.1146 - val_loss: 1.5750\n",
      "Epoch 407/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.1379 - val_loss: 1.4447\n",
      "Epoch 408/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.1146 - val_loss: 1.4712\n",
      "Epoch 409/411\n",
      "513/513 [==============================] - 0s 252us/sample - loss: 0.0849 - val_loss: 1.5690\n",
      "Epoch 410/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1083 - val_loss: 1.4910\n",
      "Epoch 411/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.0868 - val_loss: 1.5205\n",
      "513 64 65\n",
      "Train on 513 samples, validate on 64 samples\n",
      "Epoch 1/411\n",
      "513/513 [==============================] - 1s 2ms/sample - loss: 30.2616 - val_loss: 21.5831\n",
      "Epoch 2/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 26.9306 - val_loss: 18.1900\n",
      "Epoch 3/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 23.3852 - val_loss: 14.7608\n",
      "Epoch 4/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 19.8146 - val_loss: 11.2163\n",
      "Epoch 5/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 16.0113 - val_loss: 8.4580\n",
      "Epoch 6/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 13.4150 - val_loss: 8.0293\n",
      "Epoch 7/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 12.7260 - val_loss: 8.3795\n",
      "Epoch 8/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 12.4665 - val_loss: 7.7814\n",
      "Epoch 9/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 11.9315 - val_loss: 7.3916\n",
      "Epoch 10/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 12.2094 - val_loss: 7.5750\n",
      "Epoch 11/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 12.5180 - val_loss: 7.4946\n",
      "Epoch 12/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 12.1214 - val_loss: 7.0285\n",
      "Epoch 13/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 11.2378 - val_loss: 6.9363\n",
      "Epoch 14/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 10.6471 - val_loss: 7.3571\n",
      "Epoch 15/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 10.3246 - val_loss: 6.9150\n",
      "Epoch 16/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 9.9595 - val_loss: 7.8553\n",
      "Epoch 17/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 10.0252 - val_loss: 8.3993\n",
      "Epoch 18/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 10.1146 - val_loss: 8.3287\n",
      "Epoch 19/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 9.4299 - val_loss: 6.7022\n",
      "Epoch 20/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 8.7757 - val_loss: 6.1971\n",
      "Epoch 21/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 8.6316 - val_loss: 6.0063\n",
      "Epoch 22/411\n",
      "513/513 [==============================] - 0s 293us/sample - loss: 8.3530 - val_loss: 6.2974\n",
      "Epoch 23/411\n",
      "513/513 [==============================] - 0s 295us/sample - loss: 8.2022 - val_loss: 7.4423\n",
      "Epoch 24/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 8.5277 - val_loss: 6.6018\n",
      "Epoch 25/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 7.8091 - val_loss: 5.5206\n",
      "Epoch 26/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 7.4532 - val_loss: 5.5652\n",
      "Epoch 27/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 7.2745 - val_loss: 5.6019\n",
      "Epoch 28/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 7.4198 - val_loss: 6.8050\n",
      "Epoch 29/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 7.5316 - val_loss: 5.1607\n",
      "Epoch 30/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 6.7533 - val_loss: 4.7258\n",
      "Epoch 31/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 6.6964 - val_loss: 4.8751\n",
      "Epoch 32/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 6.7742 - val_loss: 6.4770\n",
      "Epoch 33/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 6.6144 - val_loss: 4.4763\n",
      "Epoch 34/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 6.0991 - val_loss: 4.3652\n",
      "Epoch 35/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 5.9684 - val_loss: 4.2671\n",
      "Epoch 36/411\n",
      "513/513 [==============================] - 0s 285us/sample - loss: 5.6665 - val_loss: 4.3611\n",
      "Epoch 37/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 5.7190 - val_loss: 4.5672\n",
      "Epoch 38/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 5.3321 - val_loss: 4.3060\n",
      "Epoch 39/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 5.8642 - val_loss: 4.0338\n",
      "Epoch 40/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 5.3407 - val_loss: 4.7078\n",
      "Epoch 41/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 5.2602 - val_loss: 3.8689\n",
      "Epoch 42/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 4.9225 - val_loss: 3.8622\n",
      "Epoch 43/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 4.9971 - val_loss: 4.0028\n",
      "Epoch 44/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 4.8439 - val_loss: 3.5951\n",
      "Epoch 45/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 4.6893 - val_loss: 3.6095\n",
      "Epoch 46/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 4.6143 - val_loss: 3.9017\n",
      "Epoch 47/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 5.1546 - val_loss: 3.7482\n",
      "Epoch 48/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 4.4633 - val_loss: 3.7328\n",
      "Epoch 49/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 4.4176 - val_loss: 3.5592\n",
      "Epoch 50/411\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 4.2409 - val_loss: 3.6936\n",
      "Epoch 51/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 4.3959 - val_loss: 3.2423\n",
      "Epoch 52/411\n",
      "513/513 [==============================] - 0s 300us/sample - loss: 4.3248 - val_loss: 3.3316\n",
      "Epoch 53/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 4.1984 - val_loss: 3.8705\n",
      "Epoch 54/411\n",
      "513/513 [==============================] - 0s 285us/sample - loss: 4.5931 - val_loss: 3.2099\n",
      "Epoch 55/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 4.0335 - val_loss: 3.0244\n",
      "Epoch 56/411\n",
      "513/513 [==============================] - 0s 293us/sample - loss: 3.9435 - val_loss: 2.9766\n",
      "Epoch 57/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 3.9370 - val_loss: 3.0515\n",
      "Epoch 58/411\n",
      "513/513 [==============================] - 0s 305us/sample - loss: 3.7541 - val_loss: 3.0380\n",
      "Epoch 59/411\n",
      "513/513 [==============================] - 0s 305us/sample - loss: 3.6079 - val_loss: 3.0453\n",
      "Epoch 60/411\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 3.5957 - val_loss: 3.0513\n",
      "Epoch 61/411\n",
      "513/513 [==============================] - 0s 319us/sample - loss: 3.4916 - val_loss: 3.0835\n",
      "Epoch 62/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 3.5465 - val_loss: 3.1035\n",
      "Epoch 63/411\n",
      "513/513 [==============================] - 0s 323us/sample - loss: 3.2969 - val_loss: 2.8826\n",
      "Epoch 64/411\n",
      "513/513 [==============================] - 0s 313us/sample - loss: 3.3023 - val_loss: 2.8218\n",
      "Epoch 65/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 3.1881 - val_loss: 2.8117\n",
      "Epoch 66/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 3.1313 - val_loss: 2.8647\n",
      "Epoch 67/411\n",
      "513/513 [==============================] - 0s 296us/sample - loss: 3.6532 - val_loss: 3.2918\n",
      "Epoch 68/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 3.3561 - val_loss: 3.0481\n",
      "Epoch 69/411\n",
      "513/513 [==============================] - 0s 313us/sample - loss: 3.6354 - val_loss: 2.9844\n",
      "Epoch 70/411\n",
      "513/513 [==============================] - 0s 294us/sample - loss: 2.9968 - val_loss: 3.2417\n",
      "Epoch 71/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 3.6403 - val_loss: 2.6568\n",
      "Epoch 72/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 3.0338 - val_loss: 3.3609\n",
      "Epoch 73/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 3.2054 - val_loss: 2.5660\n",
      "Epoch 74/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 2.8726 - val_loss: 2.5816\n",
      "Epoch 75/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 2.7379 - val_loss: 2.4927\n",
      "Epoch 76/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 2.6828 - val_loss: 2.4872\n",
      "Epoch 77/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 2.7612 - val_loss: 2.3183\n",
      "Epoch 78/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 2.5963 - val_loss: 2.2925\n",
      "Epoch 79/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 2.5171 - val_loss: 2.2862\n",
      "Epoch 80/411\n",
      "513/513 [==============================] - 0s 344us/sample - loss: 2.5216 - val_loss: 2.6007\n",
      "Epoch 81/411\n",
      "513/513 [==============================] - 0s 323us/sample - loss: 3.0599 - val_loss: 2.5653\n",
      "Epoch 82/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 2.6251 - val_loss: 2.3613\n",
      "Epoch 83/411\n",
      "513/513 [==============================] - 0s 285us/sample - loss: 2.4955 - val_loss: 2.2877\n",
      "Epoch 84/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 2.5285 - val_loss: 2.4036\n",
      "Epoch 85/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 2.4538 - val_loss: 2.7122\n",
      "Epoch 86/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 2.3632 - val_loss: 2.7335\n",
      "Epoch 87/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 2.6646 - val_loss: 2.3465\n",
      "Epoch 88/411\n",
      "513/513 [==============================] - 0s 295us/sample - loss: 2.3281 - val_loss: 2.7508\n",
      "Epoch 89/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 2.3064 - val_loss: 2.2052\n",
      "Epoch 90/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 2.1055 - val_loss: 2.1769\n",
      "Epoch 91/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 2.0438 - val_loss: 2.1501\n",
      "Epoch 92/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 1.9590 - val_loss: 2.2384\n",
      "Epoch 93/411\n",
      "513/513 [==============================] - 0s 298us/sample - loss: 2.0956 - val_loss: 2.1808\n",
      "Epoch 94/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 2.5015 - val_loss: 2.8175\n",
      "Epoch 95/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 2.1420 - val_loss: 2.4579\n",
      "Epoch 96/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 2.0479 - val_loss: 2.1511\n",
      "Epoch 97/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 2.0384 - val_loss: 2.0480\n",
      "Epoch 98/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 1.8779 - val_loss: 1.9230\n",
      "Epoch 99/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 2.3272 - val_loss: 2.8968\n",
      "Epoch 100/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 2.4743 - val_loss: 2.0180\n",
      "Epoch 101/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 2.3034 - val_loss: 1.9330\n",
      "Epoch 102/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 1.7838 - val_loss: 2.1678\n",
      "Epoch 103/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 1.8691 - val_loss: 1.8682\n",
      "Epoch 104/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 1.6577 - val_loss: 1.8987\n",
      "Epoch 105/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.6355 - val_loss: 1.9586\n",
      "Epoch 106/411\n",
      "513/513 [==============================] - 0s 301us/sample - loss: 1.6837 - val_loss: 1.8772\n",
      "Epoch 107/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 1.6537 - val_loss: 1.9006\n",
      "Epoch 108/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.7467 - val_loss: 2.1047\n",
      "Epoch 109/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 1.5691 - val_loss: 2.2132\n",
      "Epoch 110/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.6719 - val_loss: 1.9532\n",
      "Epoch 111/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 1.4628 - val_loss: 1.9483\n",
      "Epoch 112/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.4506 - val_loss: 1.9440\n",
      "Epoch 113/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.3961 - val_loss: 1.9203\n",
      "Epoch 114/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 1.3607 - val_loss: 1.8627\n",
      "Epoch 115/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 1.3327 - val_loss: 1.9067\n",
      "Epoch 116/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.8045 - val_loss: 1.7840\n",
      "Epoch 117/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 1.5835 - val_loss: 1.7505\n",
      "Epoch 118/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 2.4387 - val_loss: 3.2056\n",
      "Epoch 119/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 1.8186 - val_loss: 3.1490\n",
      "Epoch 120/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 2.9627 - val_loss: 1.7760\n",
      "Epoch 121/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 2.4336 - val_loss: 2.8541\n",
      "Epoch 122/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.6486 - val_loss: 2.2175\n",
      "Epoch 123/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 1.5903 - val_loss: 1.9887\n",
      "Epoch 124/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 2.0385 - val_loss: 2.2970\n",
      "Epoch 125/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 1.3929 - val_loss: 2.5456\n",
      "Epoch 126/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 2.1890 - val_loss: 1.8377\n",
      "Epoch 127/411\n",
      "513/513 [==============================] - 0s 285us/sample - loss: 1.4069 - val_loss: 2.3557\n",
      "Epoch 128/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 1.4426 - val_loss: 1.9982\n",
      "Epoch 129/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.8102 - val_loss: 1.9986\n",
      "Epoch 130/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 1.2337 - val_loss: 2.1656\n",
      "Epoch 131/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 1.4916 - val_loss: 1.7917\n",
      "Epoch 132/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 1.1294 - val_loss: 1.7330\n",
      "Epoch 133/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.1087 - val_loss: 1.8407\n",
      "Epoch 134/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.3821 - val_loss: 1.7302\n",
      "Epoch 135/411\n",
      "513/513 [==============================] - 0s 256us/sample - loss: 1.2885 - val_loss: 2.2633\n",
      "Epoch 136/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 1.2599 - val_loss: 1.8557\n",
      "Epoch 137/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 1.3686 - val_loss: 1.7792\n",
      "Epoch 138/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 1.0777 - val_loss: 1.7238\n",
      "Epoch 139/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.9996 - val_loss: 1.7185\n",
      "Epoch 140/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 1.0104 - val_loss: 1.7618\n",
      "Epoch 141/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.9738 - val_loss: 1.7205\n",
      "Epoch 142/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.9448 - val_loss: 1.6933\n",
      "Epoch 143/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.9765 - val_loss: 1.6674\n",
      "Epoch 144/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.9693 - val_loss: 1.6788\n",
      "Epoch 145/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.9229 - val_loss: 1.6352\n",
      "Epoch 146/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.9254 - val_loss: 1.7358\n",
      "Epoch 147/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 1.0753 - val_loss: 1.6019\n",
      "Epoch 148/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.9591 - val_loss: 1.5996\n",
      "Epoch 149/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 1.0143 - val_loss: 1.6393\n",
      "Epoch 150/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.9586 - val_loss: 1.9121\n",
      "Epoch 151/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.9881 - val_loss: 1.8517\n",
      "Epoch 152/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 1.8756 - val_loss: 1.7992\n",
      "Epoch 153/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 1.2945 - val_loss: 2.7346\n",
      "Epoch 154/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.2877 - val_loss: 2.2714\n",
      "Epoch 155/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 1.3611 - val_loss: 1.6385\n",
      "Epoch 156/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.8728 - val_loss: 1.5872\n",
      "Epoch 157/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.8612 - val_loss: 1.6678\n",
      "Epoch 158/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.9037 - val_loss: 1.5735\n",
      "Epoch 159/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.8409 - val_loss: 1.6172\n",
      "Epoch 160/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 0.8093 - val_loss: 1.6658\n",
      "Epoch 161/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.7880 - val_loss: 1.7016\n",
      "Epoch 162/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.7726 - val_loss: 1.7461\n",
      "Epoch 163/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.8456 - val_loss: 1.7604\n",
      "Epoch 164/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.8132 - val_loss: 1.7095\n",
      "Epoch 165/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.8419 - val_loss: 1.7400\n",
      "Epoch 166/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 0.7785 - val_loss: 1.5964\n",
      "Epoch 167/411\n",
      "513/513 [==============================] - 0s 290us/sample - loss: 0.6929 - val_loss: 1.6030\n",
      "Epoch 168/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.7097 - val_loss: 1.5904\n",
      "Epoch 169/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.6814 - val_loss: 1.5804\n",
      "Epoch 170/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.6602 - val_loss: 1.5810\n",
      "Epoch 171/411\n",
      "513/513 [==============================] - 0s 249us/sample - loss: 0.6606 - val_loss: 1.6272\n",
      "Epoch 172/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.6499 - val_loss: 1.7137\n",
      "Epoch 173/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 0.7155 - val_loss: 1.6421\n",
      "Epoch 174/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.8012 - val_loss: 1.5852\n",
      "Epoch 175/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.7112 - val_loss: 1.5823\n",
      "Epoch 176/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.8135 - val_loss: 1.7505\n",
      "Epoch 177/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.6989 - val_loss: 1.8170\n",
      "Epoch 178/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.7283 - val_loss: 1.6903\n",
      "Epoch 179/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.7950 - val_loss: 1.5881\n",
      "Epoch 180/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.6052 - val_loss: 1.6672\n",
      "Epoch 181/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 0.6510 - val_loss: 1.5792\n",
      "Epoch 182/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.6154 - val_loss: 1.5597\n",
      "Epoch 183/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.5707 - val_loss: 1.5488\n",
      "Epoch 184/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.5755 - val_loss: 1.5536\n",
      "Epoch 185/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.5489 - val_loss: 1.5408\n",
      "Epoch 186/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.5991 - val_loss: 1.6084\n",
      "Epoch 187/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.5629 - val_loss: 1.6499\n",
      "Epoch 188/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.5716 - val_loss: 1.6708\n",
      "Epoch 189/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.8116 - val_loss: 1.5536\n",
      "Epoch 190/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.5497 - val_loss: 1.6647\n",
      "Epoch 191/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.6586 - val_loss: 1.5790\n",
      "Epoch 192/411\n",
      "513/513 [==============================] - 0s 247us/sample - loss: 0.8016 - val_loss: 1.5077\n",
      "Epoch 193/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.8594 - val_loss: 1.6759\n",
      "Epoch 194/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.7477 - val_loss: 1.4862\n",
      "Epoch 195/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.6680 - val_loss: 1.5061\n",
      "Epoch 196/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.6282 - val_loss: 1.5639\n",
      "Epoch 197/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.5490 - val_loss: 1.6578\n",
      "Epoch 198/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.5883 - val_loss: 1.8168\n",
      "Epoch 199/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.9002 - val_loss: 1.8893\n",
      "Epoch 200/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 1.8365 - val_loss: 1.7832\n",
      "Epoch 201/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.8327 - val_loss: 1.7891\n",
      "Epoch 202/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 1.5835 - val_loss: 2.3125\n",
      "Epoch 203/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.8698 - val_loss: 2.2383\n",
      "Epoch 204/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.9492 - val_loss: 1.8194\n",
      "Epoch 205/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.1122 - val_loss: 1.5700\n",
      "Epoch 206/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.5987 - val_loss: 1.5680\n",
      "Epoch 207/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.6118 - val_loss: 1.5307\n",
      "Epoch 208/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.5899 - val_loss: 1.4616\n",
      "Epoch 209/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.5229 - val_loss: 1.4523\n",
      "Epoch 210/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 0.4990 - val_loss: 1.5168\n",
      "Epoch 211/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.5386 - val_loss: 1.5287\n",
      "Epoch 212/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.5423 - val_loss: 1.5984\n",
      "Epoch 213/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.4792 - val_loss: 1.6097\n",
      "Epoch 214/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.7106 - val_loss: 1.5257\n",
      "Epoch 215/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 0.5709 - val_loss: 1.6091\n",
      "Epoch 216/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.4878 - val_loss: 1.4988\n",
      "Epoch 217/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.4875 - val_loss: 1.4700\n",
      "Epoch 218/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.4618 - val_loss: 1.4623\n",
      "Epoch 219/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 0.4542 - val_loss: 1.4980\n",
      "Epoch 220/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.4816 - val_loss: 1.4687\n",
      "Epoch 221/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.4469 - val_loss: 1.4404\n",
      "Epoch 222/411\n",
      "513/513 [==============================] - 0s 298us/sample - loss: 0.4077 - val_loss: 1.4650\n",
      "Epoch 223/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.4114 - val_loss: 1.4670\n",
      "Epoch 224/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.4216 - val_loss: 1.4623\n",
      "Epoch 225/411\n",
      "513/513 [==============================] - 0s 301us/sample - loss: 0.4235 - val_loss: 1.5088\n",
      "Epoch 226/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.4224 - val_loss: 1.4714\n",
      "Epoch 227/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.3852 - val_loss: 1.4616\n",
      "Epoch 228/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.3666 - val_loss: 1.7853\n",
      "Epoch 229/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 1.0151 - val_loss: 1.4483\n",
      "Epoch 230/411\n",
      "513/513 [==============================] - 0s 301us/sample - loss: 0.4468 - val_loss: 1.4554\n",
      "Epoch 231/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.6525 - val_loss: 1.4693\n",
      "Epoch 232/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.4662 - val_loss: 1.5115\n",
      "Epoch 233/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.4035 - val_loss: 1.5162\n",
      "Epoch 234/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.4107 - val_loss: 1.4994\n",
      "Epoch 235/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.4749 - val_loss: 1.3904\n",
      "Epoch 236/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.3749 - val_loss: 1.3624\n",
      "Epoch 237/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.3417 - val_loss: 1.3547\n",
      "Epoch 238/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.3399 - val_loss: 1.3982\n",
      "Epoch 239/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.3542 - val_loss: 1.3652\n",
      "Epoch 240/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3313 - val_loss: 1.3745\n",
      "Epoch 241/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 0.3165 - val_loss: 1.3864\n",
      "Epoch 242/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3264 - val_loss: 1.3939\n",
      "Epoch 243/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.3052 - val_loss: 1.3966\n",
      "Epoch 244/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.3153 - val_loss: 1.4146\n",
      "Epoch 245/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.3414 - val_loss: 1.4180\n",
      "Epoch 246/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.3034 - val_loss: 1.4099\n",
      "Epoch 247/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.3375 - val_loss: 1.3800\n",
      "Epoch 248/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.3228 - val_loss: 1.3713\n",
      "Epoch 249/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.3299 - val_loss: 1.3825\n",
      "Epoch 250/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.2989 - val_loss: 1.3707\n",
      "Epoch 251/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.2942 - val_loss: 1.3874\n",
      "Epoch 252/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.2914 - val_loss: 1.3970\n",
      "Epoch 253/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.3078 - val_loss: 1.4554\n",
      "Epoch 254/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.3188 - val_loss: 1.4613\n",
      "Epoch 255/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.3022 - val_loss: 1.4221\n",
      "Epoch 256/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2837 - val_loss: 1.3841\n",
      "Epoch 257/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.2922 - val_loss: 1.3945\n",
      "Epoch 258/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.3977 - val_loss: 1.3504\n",
      "Epoch 259/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2872 - val_loss: 1.3604\n",
      "Epoch 260/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.2878 - val_loss: 1.3965\n",
      "Epoch 261/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.2917 - val_loss: 1.5669\n",
      "Epoch 262/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.5503 - val_loss: 1.5557\n",
      "Epoch 263/411\n",
      "513/513 [==============================] - 0s 293us/sample - loss: 0.6637 - val_loss: 1.2574\n",
      "Epoch 264/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.3381 - val_loss: 1.2285\n",
      "Epoch 265/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2791 - val_loss: 1.3890\n",
      "Epoch 266/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.7710 - val_loss: 1.2560\n",
      "Epoch 267/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.5504 - val_loss: 1.2285\n",
      "Epoch 268/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.3547 - val_loss: 1.2216\n",
      "Epoch 269/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.5552 - val_loss: 1.1322\n",
      "Epoch 270/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.3804 - val_loss: 1.1781\n",
      "Epoch 271/411\n",
      "513/513 [==============================] - 0s 244us/sample - loss: 0.3402 - val_loss: 1.1394\n",
      "Epoch 272/411\n",
      "513/513 [==============================] - 0s 254us/sample - loss: 0.3120 - val_loss: 1.1365\n",
      "Epoch 273/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.2989 - val_loss: 1.1564\n",
      "Epoch 274/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.3115 - val_loss: 1.2872\n",
      "Epoch 275/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.3171 - val_loss: 1.2248\n",
      "Epoch 276/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.2743 - val_loss: 1.2064\n",
      "Epoch 277/411\n",
      "513/513 [==============================] - 0s 280us/sample - loss: 0.2408 - val_loss: 1.2085\n",
      "Epoch 278/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.2416 - val_loss: 1.2233\n",
      "Epoch 279/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.2665 - val_loss: 1.2156\n",
      "Epoch 280/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.2243 - val_loss: 1.2322\n",
      "Epoch 281/411\n",
      "513/513 [==============================] - 0s 245us/sample - loss: 0.2152 - val_loss: 1.2464\n",
      "Epoch 282/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 0.2379 - val_loss: 1.2574\n",
      "Epoch 283/411\n",
      "513/513 [==============================] - 0s 247us/sample - loss: 0.2199 - val_loss: 1.2958\n",
      "Epoch 284/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.2865 - val_loss: 1.2411\n",
      "Epoch 285/411\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 0.2289 - val_loss: 1.2341\n",
      "Epoch 286/411\n",
      "513/513 [==============================] - 0s 283us/sample - loss: 0.2195 - val_loss: 1.2282\n",
      "Epoch 287/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.2093 - val_loss: 1.2277\n",
      "Epoch 288/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.2080 - val_loss: 1.2329\n",
      "Epoch 289/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.2185 - val_loss: 1.2508\n",
      "Epoch 290/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.2095 - val_loss: 1.2411\n",
      "Epoch 291/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.1893 - val_loss: 1.3119\n",
      "Epoch 292/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.2918 - val_loss: 1.2512\n",
      "Epoch 293/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.1992 - val_loss: 1.2495\n",
      "Epoch 294/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.1861 - val_loss: 1.2412\n",
      "Epoch 295/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.1830 - val_loss: 1.2452\n",
      "Epoch 296/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.2022 - val_loss: 1.2523\n",
      "Epoch 297/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.2375 - val_loss: 1.2503\n",
      "Epoch 298/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.2016 - val_loss: 1.2985\n",
      "Epoch 299/411\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 0.2561 - val_loss: 1.2930\n",
      "Epoch 300/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.2042 - val_loss: 1.2745\n",
      "Epoch 301/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1717 - val_loss: 1.2866\n",
      "Epoch 302/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1861 - val_loss: 1.2883\n",
      "Epoch 303/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.1931 - val_loss: 1.2669\n",
      "Epoch 304/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.1750 - val_loss: 1.2855\n",
      "Epoch 305/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1976 - val_loss: 1.2512\n",
      "Epoch 306/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1652 - val_loss: 1.2653\n",
      "Epoch 307/411\n",
      "513/513 [==============================] - 0s 291us/sample - loss: 0.1819 - val_loss: 1.3355\n",
      "Epoch 308/411\n",
      "513/513 [==============================] - 0s 279us/sample - loss: 0.2558 - val_loss: 1.2931\n",
      "Epoch 309/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.2027 - val_loss: 1.4528\n",
      "Epoch 310/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.3000 - val_loss: 1.3095\n",
      "Epoch 311/411\n",
      "513/513 [==============================] - 0s 251us/sample - loss: 0.1910 - val_loss: 1.2697\n",
      "Epoch 312/411\n",
      "513/513 [==============================] - 0s 265us/sample - loss: 0.1536 - val_loss: 1.2501\n",
      "Epoch 313/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1572 - val_loss: 1.2464\n",
      "Epoch 314/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.1560 - val_loss: 1.2417\n",
      "Epoch 315/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1497 - val_loss: 1.2538\n",
      "Epoch 316/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.1517 - val_loss: 1.2471\n",
      "Epoch 317/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.1491 - val_loss: 1.2502\n",
      "Epoch 318/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1806 - val_loss: 1.3334\n",
      "Epoch 319/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.2931 - val_loss: 1.2905\n",
      "Epoch 320/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.1947 - val_loss: 1.3530\n",
      "Epoch 321/411\n",
      "513/513 [==============================] - 0s 277us/sample - loss: 0.2418 - val_loss: 1.2878\n",
      "Epoch 322/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.1672 - val_loss: 1.5081\n",
      "Epoch 323/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.3458 - val_loss: 1.4090\n",
      "Epoch 324/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.3135 - val_loss: 1.2753\n",
      "Epoch 325/411\n",
      "513/513 [==============================] - 0s 269us/sample - loss: 0.1659 - val_loss: 1.2548\n",
      "Epoch 326/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1634 - val_loss: 1.2434\n",
      "Epoch 327/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.1898 - val_loss: 1.4463\n",
      "Epoch 328/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.4421 - val_loss: 1.2810\n",
      "Epoch 329/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1666 - val_loss: 1.3252\n",
      "Epoch 330/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.1821 - val_loss: 1.3287\n",
      "Epoch 331/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.1797 - val_loss: 1.3645\n",
      "Epoch 332/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.2446 - val_loss: 1.3203\n",
      "Epoch 333/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.1740 - val_loss: 1.3405\n",
      "Epoch 334/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.2106 - val_loss: 1.3369\n",
      "Epoch 335/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.1955 - val_loss: 1.2873\n",
      "Epoch 336/411\n",
      "513/513 [==============================] - 0s 252us/sample - loss: 0.1527 - val_loss: 1.2925\n",
      "Epoch 337/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.2075 - val_loss: 1.2573\n",
      "Epoch 338/411\n",
      "513/513 [==============================] - 0s 274us/sample - loss: 0.1488 - val_loss: 1.2778\n",
      "Epoch 339/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1512 - val_loss: 1.2619\n",
      "Epoch 340/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.1424 - val_loss: 1.2545\n",
      "Epoch 341/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.1460 - val_loss: 1.2719\n",
      "Epoch 342/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.1474 - val_loss: 1.2596\n",
      "Epoch 343/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1318 - val_loss: 1.2805\n",
      "Epoch 344/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.1244 - val_loss: 1.2904\n",
      "Epoch 345/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1220 - val_loss: 1.2974\n",
      "Epoch 346/411\n",
      "513/513 [==============================] - 0s 286us/sample - loss: 0.1259 - val_loss: 1.2946\n",
      "Epoch 347/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1355 - val_loss: 1.2688\n",
      "Epoch 348/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.1134 - val_loss: 1.2533\n",
      "Epoch 349/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.1192 - val_loss: 1.2818\n",
      "Epoch 350/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1296 - val_loss: 1.2465\n",
      "Epoch 351/411\n",
      "513/513 [==============================] - 0s 302us/sample - loss: 0.1226 - val_loss: 1.2336\n",
      "Epoch 352/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.1198 - val_loss: 1.2871\n",
      "Epoch 353/411\n",
      "513/513 [==============================] - 0s 263us/sample - loss: 0.1617 - val_loss: 1.2488\n",
      "Epoch 354/411\n",
      "513/513 [==============================] - 0s 252us/sample - loss: 0.1160 - val_loss: 1.2947\n",
      "Epoch 355/411\n",
      "513/513 [==============================] - 0s 258us/sample - loss: 0.1368 - val_loss: 1.2543\n",
      "Epoch 356/411\n",
      "513/513 [==============================] - 0s 245us/sample - loss: 0.1127 - val_loss: 1.2368\n",
      "Epoch 357/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.1012 - val_loss: 1.2310\n",
      "Epoch 358/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1112 - val_loss: 1.2584\n",
      "Epoch 359/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.1174 - val_loss: 1.2385\n",
      "Epoch 360/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.1176 - val_loss: 1.2729\n",
      "Epoch 361/411\n",
      "513/513 [==============================] - 0s 288us/sample - loss: 0.1102 - val_loss: 1.2620\n",
      "Epoch 362/411\n",
      "513/513 [==============================] - 0s 276us/sample - loss: 0.1275 - val_loss: 1.2474\n",
      "Epoch 363/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1005 - val_loss: 1.2995\n",
      "Epoch 364/411\n",
      "513/513 [==============================] - 0s 289us/sample - loss: 0.1127 - val_loss: 1.4067\n",
      "Epoch 365/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1608 - val_loss: 1.2878\n",
      "Epoch 366/411\n",
      "513/513 [==============================] - 0s 287us/sample - loss: 0.1153 - val_loss: 1.2737\n",
      "Epoch 367/411\n",
      "513/513 [==============================] - 0s 300us/sample - loss: 0.1003 - val_loss: 1.2905\n",
      "Epoch 368/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 0.1424 - val_loss: 1.2588\n",
      "Epoch 369/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1037 - val_loss: 1.2585\n",
      "Epoch 370/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 0.1011 - val_loss: 1.2648\n",
      "Epoch 371/411\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 0.0932 - val_loss: 1.2625\n",
      "Epoch 372/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.0930 - val_loss: 1.2635\n",
      "Epoch 373/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.0928 - val_loss: 1.6155\n",
      "Epoch 374/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.5106 - val_loss: 1.7354\n",
      "Epoch 375/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.4424 - val_loss: 1.2909\n",
      "Epoch 376/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.1567 - val_loss: 1.3008\n",
      "Epoch 377/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1546 - val_loss: 1.4002\n",
      "Epoch 378/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.2509 - val_loss: 1.4588\n",
      "Epoch 379/411\n",
      "513/513 [==============================] - 0s 281us/sample - loss: 0.2038 - val_loss: 1.3092\n",
      "Epoch 380/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.1842 - val_loss: 1.3533\n",
      "Epoch 381/411\n",
      "513/513 [==============================] - 0s 264us/sample - loss: 0.1573 - val_loss: 1.2217\n",
      "Epoch 382/411\n",
      "513/513 [==============================] - 0s 257us/sample - loss: 0.2884 - val_loss: 1.1941\n",
      "Epoch 383/411\n",
      "513/513 [==============================] - 0s 254us/sample - loss: 0.3080 - val_loss: 1.1670\n",
      "Epoch 384/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.3224 - val_loss: 1.1630\n",
      "Epoch 385/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.1828 - val_loss: 1.1975\n",
      "Epoch 386/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.1472 - val_loss: 1.2453\n",
      "Epoch 387/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.1336 - val_loss: 1.2759\n",
      "Epoch 388/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.1523 - val_loss: 1.2919\n",
      "Epoch 389/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.1374 - val_loss: 1.2725\n",
      "Epoch 390/411\n",
      "513/513 [==============================] - 0s 259us/sample - loss: 0.1460 - val_loss: 1.3193\n",
      "Epoch 391/411\n",
      "513/513 [==============================] - 0s 253us/sample - loss: 0.1498 - val_loss: 1.2214\n",
      "Epoch 392/411\n",
      "513/513 [==============================] - 0s 262us/sample - loss: 0.0947 - val_loss: 1.2127\n",
      "Epoch 393/411\n",
      "513/513 [==============================] - 0s 250us/sample - loss: 0.1193 - val_loss: 1.2146\n",
      "Epoch 394/411\n",
      "513/513 [==============================] - 0s 275us/sample - loss: 0.0893 - val_loss: 1.2255\n",
      "Epoch 395/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.1069 - val_loss: 1.3011\n",
      "Epoch 396/411\n",
      "513/513 [==============================] - 0s 282us/sample - loss: 0.1524 - val_loss: 1.3059\n",
      "Epoch 397/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.1382 - val_loss: 1.2976\n",
      "Epoch 398/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.1073 - val_loss: 1.2257\n",
      "Epoch 399/411\n",
      "513/513 [==============================] - 0s 268us/sample - loss: 0.0887 - val_loss: 1.2133\n",
      "Epoch 400/411\n",
      "513/513 [==============================] - 0s 273us/sample - loss: 0.0842 - val_loss: 1.2021\n",
      "Epoch 401/411\n",
      "513/513 [==============================] - 0s 270us/sample - loss: 0.0804 - val_loss: 1.1954\n",
      "Epoch 402/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.0782 - val_loss: 1.2003\n",
      "Epoch 403/411\n",
      "513/513 [==============================] - 0s 272us/sample - loss: 0.1085 - val_loss: 1.2227\n",
      "Epoch 404/411\n",
      "513/513 [==============================] - 0s 284us/sample - loss: 0.1277 - val_loss: 1.1989\n",
      "Epoch 405/411\n",
      "513/513 [==============================] - 0s 255us/sample - loss: 0.0954 - val_loss: 1.2379\n",
      "Epoch 406/411\n",
      "513/513 [==============================] - 0s 261us/sample - loss: 0.1182 - val_loss: 1.2174\n",
      "Epoch 407/411\n",
      "513/513 [==============================] - 0s 278us/sample - loss: 0.0916 - val_loss: 1.2690\n",
      "Epoch 408/411\n",
      "513/513 [==============================] - 0s 266us/sample - loss: 0.1063 - val_loss: 1.2744\n",
      "Epoch 409/411\n",
      "513/513 [==============================] - 0s 260us/sample - loss: 0.1160 - val_loss: 1.2561\n",
      "Epoch 410/411\n",
      "513/513 [==============================] - 0s 271us/sample - loss: 0.0926 - val_loss: 1.5014\n",
      "Epoch 411/411\n",
      "513/513 [==============================] - 0s 267us/sample - loss: 0.3110 - val_loss: 1.6808\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    \n",
    "    train_idx = [i for i in train_idx if i < len(df)]\n",
    "    valid_idx = [i for i in valid_idx if i < len(df)]    \n",
    "    test_idx = [i for i in test_idx if i < len(df)]\n",
    "    \n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    testX = (X1[test_idx], X2[test_idx])\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "    \n",
    "\n",
    "    if i == 0:\n",
    "        performance = molmodel.cbks.Reg_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                   (validX, validY), \n",
    "                                                                   patience = patience, \n",
    "                                                                   criteria = monitor)\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs=epochs, verbose= 0, shuffle = True, \n",
    "              validation_data = (validX, validY), \n",
    "              callbacks=[performance]) \n",
    "    else:\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs = performance.best_epoch + 1, verbose = 1, shuffle = True, \n",
    "              validation_data = (validX, validY)) \n",
    "            \n",
    "    performance.model.set_weights(model.get_weights())\n",
    "    \n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "\n",
    "    train_rmses, train_r2s = performance.evaluate(trainX, trainY)            \n",
    "    valid_rmses, valid_r2s = performance.evaluate(validX, validY)            \n",
    "    test_rmses, test_r2s = performance.evaluate(testX, testY)\n",
    "\n",
    "\n",
    "    final_res = {\n",
    "                 'task_name':task_name,            \n",
    "                 'train_rmse':np.nanmean(train_rmses), \n",
    "                 'valid_rmse':np.nanmean(valid_rmses),                      \n",
    "                 'test_rmse':np.nanmean(test_rmses), \n",
    "\n",
    "                 'train_r2':np.nanmean(train_r2s), \n",
    "                 'valid_r2':np.nanmean(valid_r2s),                      \n",
    "                 'test_r2':np.nanmean(test_r2s), \n",
    "\n",
    "                 '# trainable params': trainable_params,\n",
    "                 'best_epoch': best_epoch,\n",
    "                 'batch_size':batch_size,\n",
    "                 'lr': lr,\n",
    "                 'weight_decay':weight_decay\n",
    "                }\n",
    "    results.append(final_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff58ee07518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(performance.history)[['rmse', 'val_rmse']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1548276516989255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2099641544673566"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_rmse.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./results/%s.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>valid_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>valid_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FreeSolv</td>\n",
       "      <td>0.327072</td>\n",
       "      <td>1.161050</td>\n",
       "      <td>0.961887</td>\n",
       "      <td>0.993030</td>\n",
       "      <td>0.897130</td>\n",
       "      <td>0.935676</td>\n",
       "      <td>803681</td>\n",
       "      <td>410</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FreeSolv</td>\n",
       "      <td>0.287582</td>\n",
       "      <td>1.233097</td>\n",
       "      <td>1.124155</td>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.916107</td>\n",
       "      <td>0.920250</td>\n",
       "      <td>803681</td>\n",
       "      <td>410</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FreeSolv</td>\n",
       "      <td>0.675379</td>\n",
       "      <td>1.296443</td>\n",
       "      <td>1.378441</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>0.868722</td>\n",
       "      <td>0.918209</td>\n",
       "      <td>803681</td>\n",
       "      <td>410</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  train_rmse  valid_rmse  test_rmse  train_r2  valid_r2   test_r2  \\\n",
       "0  FreeSolv    0.327072    1.161050   0.961887  0.993030  0.897130  0.935676   \n",
       "1  FreeSolv    0.287582    1.233097   1.124155  0.994611  0.916107  0.920250   \n",
       "2  FreeSolv    0.675379    1.296443   1.378441  0.993143  0.868722  0.918209   \n",
       "\n",
       "   # trainable params  best_epoch  batch_size      lr  weight_decay  \n",
       "0              803681         410         128  0.0001             0  \n",
       "1              803681         410         128  0.0001             0  \n",
       "2              803681         410         128  0.0001             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
