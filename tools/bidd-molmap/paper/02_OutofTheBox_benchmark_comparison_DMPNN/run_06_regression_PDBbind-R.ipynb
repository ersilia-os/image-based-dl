{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "np.random.seed(123)\n",
    "tf.compat.v1.set_random_seed(123)\n",
    "\n",
    "\n",
    "tmp_feature_dir = './tmpignore'\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: PDBbind-refined number of split times: 1\n"
     ]
    }
   ],
   "source": [
    "task_name = 'PDBbind-refined'\n",
    "\n",
    "from chembench import load_data\n",
    "\n",
    "df, induces = load_data(task_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "induces = induces*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 3040/3040 [12:01<00:00,  3.61it/s]\n",
      "100%|##########| 3040/3040 [01:07<00:00, 45.14it/s]\n"
     ]
    }
   ],
   "source": [
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').values\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 800\n",
    "patience = 50 #early stopping\n",
    "\n",
    "dense_layers = [256, 128, 32]\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "loss = 'mse'\n",
    "monitor = 'val_loss'\n",
    "dense_avf = 'relu'\n",
    "last_avf = 'linear'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2432 304 304\n",
      "WARNING:tensorflow:From /home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "epoch: 0001, loss: 0.9188 - val_loss: 0.8743; rmse: 0.9147 - rmse_val: 0.9351;  r2: 0.2211 - r2_val: 0.3798                                                                                                    \n",
      "epoch: 0002, loss: 0.8030 - val_loss: 0.7799; rmse: 0.8763 - rmse_val: 0.8831;  r2: 0.2549 - r2_val: 0.3826                                                                                                    \n",
      "epoch: 0003, loss: 0.7527 - val_loss: 0.7422; rmse: 0.8450 - rmse_val: 0.8615;  r2: 0.2957 - r2_val: 0.3834                                                                                                    \n",
      "epoch: 0004, loss: 0.7083 - val_loss: 0.7151; rmse: 0.8250 - rmse_val: 0.8456;  r2: 0.3281 - r2_val: 0.3932                                                                                                    \n",
      "epoch: 0005, loss: 0.6776 - val_loss: 0.7204; rmse: 0.8136 - rmse_val: 0.8488;  r2: 0.3537 - r2_val: 0.4018                                                                                                    \n",
      "epoch: 0006, loss: 0.6491 - val_loss: 0.7056; rmse: 0.7954 - rmse_val: 0.8400;  r2: 0.3821 - r2_val: 0.4093                                                                                                    \n",
      "epoch: 0007, loss: 0.6277 - val_loss: 0.6648; rmse: 0.7719 - rmse_val: 0.8153;  r2: 0.4143 - r2_val: 0.4244                                                                                                    \n",
      "epoch: 0008, loss: 0.6289 - val_loss: 0.6638; rmse: 0.7784 - rmse_val: 0.8147;  r2: 0.4403 - r2_val: 0.4393                                                                                                    \n",
      "epoch: 0009, loss: 0.6018 - val_loss: 0.6556; rmse: 0.7479 - rmse_val: 0.8097;  r2: 0.4541 - r2_val: 0.4441                                                                                                    \n",
      "epoch: 0010, loss: 0.5547 - val_loss: 0.7919; rmse: 0.8042 - rmse_val: 0.8899;  r2: 0.4714 - r2_val: 0.4493                                                                                                    \n",
      "epoch: 0011, loss: 0.5905 - val_loss: 0.6443; rmse: 0.7438 - rmse_val: 0.8027;  r2: 0.5007 - r2_val: 0.4545                                                                                                    \n",
      "epoch: 0012, loss: 0.5492 - val_loss: 0.6925; rmse: 0.7375 - rmse_val: 0.8321;  r2: 0.5141 - r2_val: 0.4647                                                                                                    \n",
      "epoch: 0013, loss: 0.5222 - val_loss: 0.6266; rmse: 0.6950 - rmse_val: 0.7916;  r2: 0.5349 - r2_val: 0.4661                                                                                                    \n",
      "epoch: 0014, loss: 0.4982 - val_loss: 0.6066; rmse: 0.6810 - rmse_val: 0.7789;  r2: 0.5476 - r2_val: 0.4750                                                                                                    \n",
      "epoch: 0015, loss: 0.4651 - val_loss: 0.6357; rmse: 0.6764 - rmse_val: 0.7973;  r2: 0.5675 - r2_val: 0.4723                                                                                                    \n",
      "epoch: 0016, loss: 0.4474 - val_loss: 0.5919; rmse: 0.6558 - rmse_val: 0.7693;  r2: 0.5953 - r2_val: 0.4794                                                                                                    \n",
      "epoch: 0017, loss: 0.4291 - val_loss: 0.5961; rmse: 0.6342 - rmse_val: 0.7721;  r2: 0.6083 - r2_val: 0.4772                                                                                                    \n",
      "epoch: 0018, loss: 0.4082 - val_loss: 0.5868; rmse: 0.6193 - rmse_val: 0.7660;  r2: 0.6283 - r2_val: 0.4886                                                                                                    \n",
      "epoch: 0019, loss: 0.3826 - val_loss: 0.5881; rmse: 0.6011 - rmse_val: 0.7669;  r2: 0.6483 - r2_val: 0.4808                                                                                                    \n",
      "epoch: 0020, loss: 0.3642 - val_loss: 0.6744; rmse: 0.6304 - rmse_val: 0.8212;  r2: 0.6687 - r2_val: 0.4871                                                                                                    \n",
      "epoch: 0021, loss: 0.3688 - val_loss: 0.6243; rmse: 0.5875 - rmse_val: 0.7902;  r2: 0.6867 - r2_val: 0.4878                                                                                                    \n",
      "epoch: 0022, loss: 0.3698 - val_loss: 0.5889; rmse: 0.5590 - rmse_val: 0.7674;  r2: 0.7056 - r2_val: 0.4766                                                                                                    \n",
      "epoch: 0023, loss: 0.3462 - val_loss: 0.5984; rmse: 0.5561 - rmse_val: 0.7736;  r2: 0.7120 - r2_val: 0.4942                                                                                                    \n",
      "epoch: 0024, loss: 0.3048 - val_loss: 0.5972; rmse: 0.5348 - rmse_val: 0.7728;  r2: 0.7329 - r2_val: 0.4884                                                                                                    \n",
      "epoch: 0025, loss: 0.3065 - val_loss: 0.5718; rmse: 0.5253 - rmse_val: 0.7562;  r2: 0.7459 - r2_val: 0.4874                                                                                                    \n",
      "epoch: 0026, loss: 0.2780 - val_loss: 0.5998; rmse: 0.5146 - rmse_val: 0.7745;  r2: 0.7487 - r2_val: 0.4920                                                                                                    \n",
      "epoch: 0027, loss: 0.2915 - val_loss: 0.5868; rmse: 0.4943 - rmse_val: 0.7660;  r2: 0.7655 - r2_val: 0.4767                                                                                                    \n",
      "epoch: 0028, loss: 0.2556 - val_loss: 0.6004; rmse: 0.4871 - rmse_val: 0.7749;  r2: 0.7735 - r2_val: 0.4860                                                                                                    \n",
      "epoch: 0029, loss: 0.2476 - val_loss: 0.5985; rmse: 0.4728 - rmse_val: 0.7736;  r2: 0.7897 - r2_val: 0.4858                                                                                                    \n",
      "epoch: 0030, loss: 0.2447 - val_loss: 0.6166; rmse: 0.4730 - rmse_val: 0.7852;  r2: 0.7922 - r2_val: 0.4840                                                                                                    \n",
      "epoch: 0031, loss: 0.2300 - val_loss: 0.5779; rmse: 0.4693 - rmse_val: 0.7602;  r2: 0.8046 - r2_val: 0.4849                                                                                                    \n",
      "epoch: 0032, loss: 0.2214 - val_loss: 0.5850; rmse: 0.4427 - rmse_val: 0.7649;  r2: 0.8151 - r2_val: 0.4762                                                                                                    \n",
      "epoch: 0033, loss: 0.1992 - val_loss: 0.6263; rmse: 0.4369 - rmse_val: 0.7914;  r2: 0.8255 - r2_val: 0.4736                                                                                                    \n",
      "epoch: 0034, loss: 0.2055 - val_loss: 0.6159; rmse: 0.4258 - rmse_val: 0.7848;  r2: 0.8273 - r2_val: 0.4778                                                                                                    \n",
      "epoch: 0035, loss: 0.1967 - val_loss: 0.6025; rmse: 0.4095 - rmse_val: 0.7762;  r2: 0.8392 - r2_val: 0.4680                                                                                                    \n",
      "epoch: 0036, loss: 0.1772 - val_loss: 0.6098; rmse: 0.4042 - rmse_val: 0.7809;  r2: 0.8452 - r2_val: 0.4774                                                                                                    \n",
      "epoch: 0037, loss: 0.1723 - val_loss: 0.6193; rmse: 0.4040 - rmse_val: 0.7869;  r2: 0.8455 - r2_val: 0.4790                                                                                                    \n",
      "epoch: 0038, loss: 0.1619 - val_loss: 0.6328; rmse: 0.3960 - rmse_val: 0.7955;  r2: 0.8531 - r2_val: 0.4727                                                                                                    \n",
      "epoch: 0039, loss: 0.1599 - val_loss: 0.6159; rmse: 0.3772 - rmse_val: 0.7848;  r2: 0.8633 - r2_val: 0.4610                                                                                                    \n",
      "epoch: 0040, loss: 0.1508 - val_loss: 0.6189; rmse: 0.3854 - rmse_val: 0.7867;  r2: 0.8666 - r2_val: 0.4479                                                                                                    \n",
      "epoch: 0041, loss: 0.1690 - val_loss: 0.6092; rmse: 0.3735 - rmse_val: 0.7805;  r2: 0.8715 - r2_val: 0.4630                                                                                                    \n",
      "epoch: 0042, loss: 0.1516 - val_loss: 0.6463; rmse: 0.3836 - rmse_val: 0.8039;  r2: 0.8686 - r2_val: 0.4746                                                                                                    \n",
      "epoch: 0043, loss: 0.1622 - val_loss: 0.6029; rmse: 0.3595 - rmse_val: 0.7765;  r2: 0.8744 - r2_val: 0.4668                                                                                                    \n",
      "epoch: 0044, loss: 0.1496 - val_loss: 0.6012; rmse: 0.3732 - rmse_val: 0.7754;  r2: 0.8788 - r2_val: 0.4673                                                                                                    \n",
      "epoch: 0045, loss: 0.1376 - val_loss: 0.6328; rmse: 0.3572 - rmse_val: 0.7955;  r2: 0.8800 - r2_val: 0.4651                                                                                                    \n",
      "epoch: 0046, loss: 0.1391 - val_loss: 0.6209; rmse: 0.3580 - rmse_val: 0.7880;  r2: 0.8818 - r2_val: 0.4549                                                                                                    \n",
      "epoch: 0047, loss: 0.1453 - val_loss: 0.6043; rmse: 0.3440 - rmse_val: 0.7774;  r2: 0.8879 - r2_val: 0.4657                                                                                                    \n",
      "epoch: 0048, loss: 0.1510 - val_loss: 0.6277; rmse: 0.3401 - rmse_val: 0.7923;  r2: 0.8868 - r2_val: 0.4576                                                                                                    \n",
      "epoch: 0049, loss: 0.1284 - val_loss: 0.6246; rmse: 0.3358 - rmse_val: 0.7903;  r2: 0.8884 - r2_val: 0.4668                                                                                                    \n",
      "epoch: 0050, loss: 0.1383 - val_loss: 0.6532; rmse: 0.3434 - rmse_val: 0.8082;  r2: 0.8892 - r2_val: 0.4598                                                                                                    \n",
      "epoch: 0051, loss: 0.1287 - val_loss: 0.6599; rmse: 0.3496 - rmse_val: 0.8123;  r2: 0.8908 - r2_val: 0.4607                                                                                                    \n",
      "epoch: 0052, loss: 0.1239 - val_loss: 0.6489; rmse: 0.3315 - rmse_val: 0.8056;  r2: 0.8964 - r2_val: 0.4519                                                                                                    \n",
      "epoch: 0053, loss: 0.1220 - val_loss: 0.7309; rmse: 0.4010 - rmse_val: 0.8549;  r2: 0.8954 - r2_val: 0.4576                                                                                                    \n",
      "epoch: 0054, loss: 0.1399 - val_loss: 0.6173; rmse: 0.3474 - rmse_val: 0.7857;  r2: 0.8950 - r2_val: 0.4595                                                                                                    \n",
      "epoch: 0055, loss: 0.1308 - val_loss: 0.6472; rmse: 0.3387 - rmse_val: 0.8045;  r2: 0.8934 - r2_val: 0.4689                                                                                                    \n",
      "epoch: 0056, loss: 0.1248 - val_loss: 0.6209; rmse: 0.3431 - rmse_val: 0.7879;  r2: 0.8999 - r2_val: 0.4530                                                                                                    \n",
      "epoch: 0057, loss: 0.1159 - val_loss: 0.6344; rmse: 0.3194 - rmse_val: 0.7965;  r2: 0.9003 - r2_val: 0.4565                                                                                                    \n",
      "epoch: 0058, loss: 0.1214 - val_loss: 0.7718; rmse: 0.4118 - rmse_val: 0.8785;  r2: 0.8991 - r2_val: 0.4440                                                                                                    \n",
      "epoch: 0059, loss: 0.1258 - val_loss: 0.6368; rmse: 0.3250 - rmse_val: 0.7980;  r2: 0.9025 - r2_val: 0.4412                                                                                                    \n",
      "epoch: 0060, loss: 0.1196 - val_loss: 0.6359; rmse: 0.3586 - rmse_val: 0.7974;  r2: 0.9019 - r2_val: 0.4391                                                                                                    \n",
      "epoch: 0061, loss: 0.1289 - val_loss: 0.7015; rmse: 0.3609 - rmse_val: 0.8375;  r2: 0.9033 - r2_val: 0.4502                                                                                                    \n",
      "epoch: 0062, loss: 0.1137 - val_loss: 0.6326; rmse: 0.3091 - rmse_val: 0.7953;  r2: 0.9060 - r2_val: 0.4518                                                                                                    \n",
      "epoch: 0063, loss: 0.1039 - val_loss: 0.6660; rmse: 0.3226 - rmse_val: 0.8161;  r2: 0.9069 - r2_val: 0.4533                                                                                                    \n",
      "epoch: 0064, loss: 0.1220 - val_loss: 0.6395; rmse: 0.3428 - rmse_val: 0.7997;  r2: 0.9039 - r2_val: 0.4379                                                                                                    \n",
      "epoch: 0065, loss: 0.1239 - val_loss: 0.6438; rmse: 0.3144 - rmse_val: 0.8024;  r2: 0.9062 - r2_val: 0.4572                                                                                                    \n",
      "epoch: 0066, loss: 0.1037 - val_loss: 0.6408; rmse: 0.3061 - rmse_val: 0.8005;  r2: 0.9064 - r2_val: 0.4535                                                                                                    \n",
      "epoch: 0067, loss: 0.1011 - val_loss: 0.6572; rmse: 0.3060 - rmse_val: 0.8107;  r2: 0.9088 - r2_val: 0.4443                                                                                                    \n",
      "epoch: 0068, loss: 0.1189 - val_loss: 0.6745; rmse: 0.3245 - rmse_val: 0.8213;  r2: 0.9086 - r2_val: 0.4529                                                                                                    \n",
      "epoch: 0069, loss: 0.1272 - val_loss: 0.6415; rmse: 0.3320 - rmse_val: 0.8009;  r2: 0.9067 - r2_val: 0.4403                                                                                                    \n",
      "epoch: 0070, loss: 0.1126 - val_loss: 0.6318; rmse: 0.3182 - rmse_val: 0.7948;  r2: 0.9083 - r2_val: 0.4449                                                                                                    \n",
      "epoch: 0071, loss: 0.1057 - val_loss: 0.6739; rmse: 0.3254 - rmse_val: 0.8209;  r2: 0.9103 - r2_val: 0.4555                                                                                                    \n",
      "epoch: 0072, loss: 0.1110 - val_loss: 0.6514; rmse: 0.3034 - rmse_val: 0.8071;  r2: 0.9110 - r2_val: 0.4510                                                                                                    \n",
      "epoch: 0073, loss: 0.1024 - val_loss: 0.6447; rmse: 0.3017 - rmse_val: 0.8029;  r2: 0.9115 - r2_val: 0.4386                                                                                                    \n",
      "epoch: 0074, loss: 0.1009 - val_loss: 0.6374; rmse: 0.3040 - rmse_val: 0.7983;  r2: 0.9108 - r2_val: 0.4417                                                                                                    \n",
      "epoch: 0075, loss: 0.0997 - val_loss: 0.6598; rmse: 0.2989 - rmse_val: 0.8123;  r2: 0.9112 - r2_val: 0.4460                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00075: early stopping\n",
      "2432 304 304\n",
      "Train on 2432 samples, validate on 304 samples\n",
      "Epoch 1/25\n",
      "2432/2432 [==============================] - 2s 751us/sample - loss: 0.9555 - val_loss: 0.9896\n",
      "Epoch 2/25\n",
      "2432/2432 [==============================] - 1s 233us/sample - loss: 0.8457 - val_loss: 0.8027\n",
      "Epoch 3/25\n",
      "2432/2432 [==============================] - 1s 225us/sample - loss: 0.7748 - val_loss: 0.7392\n",
      "Epoch 4/25\n",
      "2432/2432 [==============================] - 1s 242us/sample - loss: 0.7744 - val_loss: 0.7748\n",
      "Epoch 5/25\n",
      "2432/2432 [==============================] - 1s 264us/sample - loss: 0.7062 - val_loss: 0.7072\n",
      "Epoch 6/25\n",
      "2432/2432 [==============================] - 1s 292us/sample - loss: 0.6590 - val_loss: 0.6886\n",
      "Epoch 7/25\n",
      "2432/2432 [==============================] - 1s 273us/sample - loss: 0.6381 - val_loss: 0.6798\n",
      "Epoch 8/25\n",
      "2432/2432 [==============================] - 1s 266us/sample - loss: 0.6120 - val_loss: 0.6652\n",
      "Epoch 9/25\n",
      "2432/2432 [==============================] - 1s 265us/sample - loss: 0.5825 - val_loss: 0.6445\n",
      "Epoch 10/25\n",
      "2432/2432 [==============================] - 1s 256us/sample - loss: 0.5561 - val_loss: 0.6379\n",
      "Epoch 11/25\n",
      "2432/2432 [==============================] - 1s 250us/sample - loss: 0.5340 - val_loss: 0.6347\n",
      "Epoch 12/25\n",
      "2432/2432 [==============================] - 1s 237us/sample - loss: 0.5087 - val_loss: 0.6967\n",
      "Epoch 13/25\n",
      "2432/2432 [==============================] - 1s 256us/sample - loss: 0.5077 - val_loss: 0.6290\n",
      "Epoch 14/25\n",
      "2432/2432 [==============================] - 1s 265us/sample - loss: 0.5196 - val_loss: 0.6275\n",
      "Epoch 15/25\n",
      "2432/2432 [==============================] - 1s 253us/sample - loss: 0.5470 - val_loss: 0.6472\n",
      "Epoch 16/25\n",
      "2432/2432 [==============================] - 1s 252us/sample - loss: 0.4628 - val_loss: 0.5982\n",
      "Epoch 17/25\n",
      "2432/2432 [==============================] - 1s 259us/sample - loss: 0.4312 - val_loss: 0.6275\n",
      "Epoch 18/25\n",
      "2432/2432 [==============================] - 1s 245us/sample - loss: 0.4198 - val_loss: 0.5939\n",
      "Epoch 19/25\n",
      "2432/2432 [==============================] - 1s 251us/sample - loss: 0.4021 - val_loss: 0.5923\n",
      "Epoch 20/25\n",
      "2432/2432 [==============================] - 1s 243us/sample - loss: 0.3768 - val_loss: 0.6181\n",
      "Epoch 21/25\n",
      "2432/2432 [==============================] - 1s 242us/sample - loss: 0.3642 - val_loss: 0.6021\n",
      "Epoch 22/25\n",
      "2432/2432 [==============================] - 1s 241us/sample - loss: 0.3517 - val_loss: 0.5996\n",
      "Epoch 23/25\n",
      "2432/2432 [==============================] - 1s 238us/sample - loss: 0.3798 - val_loss: 0.6196\n",
      "Epoch 24/25\n",
      "2432/2432 [==============================] - 1s 236us/sample - loss: 0.3790 - val_loss: 0.6356\n",
      "Epoch 25/25\n",
      "2432/2432 [==============================] - 1s 236us/sample - loss: 0.3165 - val_loss: 0.5998\n",
      "2432 304 304\n",
      "Train on 2432 samples, validate on 304 samples\n",
      "Epoch 1/25\n",
      "2432/2432 [==============================] - 2s 745us/sample - loss: 0.9676 - val_loss: 0.9885\n",
      "Epoch 2/25\n",
      "2432/2432 [==============================] - 1s 324us/sample - loss: 0.8494 - val_loss: 0.8020\n",
      "Epoch 3/25\n",
      "2432/2432 [==============================] - 1s 300us/sample - loss: 0.7700 - val_loss: 0.7495\n",
      "Epoch 4/25\n",
      "2432/2432 [==============================] - 1s 293us/sample - loss: 0.7227 - val_loss: 0.7252\n",
      "Epoch 5/25\n",
      "2432/2432 [==============================] - 1s 292us/sample - loss: 0.6910 - val_loss: 0.7648\n",
      "Epoch 6/25\n",
      "2432/2432 [==============================] - 1s 312us/sample - loss: 0.6557 - val_loss: 0.6774\n",
      "Epoch 7/25\n",
      "2432/2432 [==============================] - 1s 317us/sample - loss: 0.6222 - val_loss: 0.6704\n",
      "Epoch 8/25\n",
      "2432/2432 [==============================] - 1s 314us/sample - loss: 0.6171 - val_loss: 0.6570\n",
      "Epoch 9/25\n",
      "2432/2432 [==============================] - 1s 294us/sample - loss: 0.5794 - val_loss: 0.6626\n",
      "Epoch 10/25\n",
      "2432/2432 [==============================] - 1s 303us/sample - loss: 0.6106 - val_loss: 0.7351\n",
      "Epoch 11/25\n",
      "2432/2432 [==============================] - 1s 317us/sample - loss: 0.5588 - val_loss: 0.6933\n",
      "Epoch 12/25\n",
      "2432/2432 [==============================] - 1s 319us/sample - loss: 0.5323 - val_loss: 0.6429\n",
      "Epoch 13/25\n",
      "2432/2432 [==============================] - 1s 329us/sample - loss: 0.5134 - val_loss: 0.6567\n",
      "Epoch 14/25\n",
      "2432/2432 [==============================] - 1s 320us/sample - loss: 0.4815 - val_loss: 0.6107\n",
      "Epoch 15/25\n",
      "2432/2432 [==============================] - 1s 300us/sample - loss: 0.4604 - val_loss: 0.6118\n",
      "Epoch 16/25\n",
      "2432/2432 [==============================] - 1s 335us/sample - loss: 0.4387 - val_loss: 0.5989\n",
      "Epoch 17/25\n",
      "2432/2432 [==============================] - 1s 325us/sample - loss: 0.4130 - val_loss: 0.6261\n",
      "Epoch 18/25\n",
      "2432/2432 [==============================] - 1s 312us/sample - loss: 0.4109 - val_loss: 0.5862\n",
      "Epoch 19/25\n",
      "2432/2432 [==============================] - 1s 293us/sample - loss: 0.3724 - val_loss: 0.6885\n",
      "Epoch 20/25\n",
      "2432/2432 [==============================] - 1s 339us/sample - loss: 0.3662 - val_loss: 0.6113\n",
      "Epoch 21/25\n",
      "2432/2432 [==============================] - 1s 346us/sample - loss: 0.3553 - val_loss: 0.5971\n",
      "Epoch 22/25\n",
      "2432/2432 [==============================] - 1s 282us/sample - loss: 0.3307 - val_loss: 0.5982\n",
      "Epoch 23/25\n",
      "2432/2432 [==============================] - 1s 280us/sample - loss: 0.3036 - val_loss: 0.5891\n",
      "Epoch 24/25\n",
      "2432/2432 [==============================] - 1s 274us/sample - loss: 0.2875 - val_loss: 0.6304\n",
      "Epoch 25/25\n",
      "2432/2432 [==============================] - 1s 321us/sample - loss: 0.2740 - val_loss: 0.6490\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    \n",
    "    train_idx = [i for i in train_idx if i < len(df)]\n",
    "    valid_idx = [i for i in valid_idx if i < len(df)]    \n",
    "    test_idx = [i for i in test_idx if i < len(df)]\n",
    "    \n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    testX = (X1[test_idx], X2[test_idx])\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "    \n",
    "\n",
    "    if i == 0:\n",
    "        performance = molmodel.cbks.Reg_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                   (validX, validY), \n",
    "                                                                   patience = patience, \n",
    "                                                                   criteria = monitor)\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs=epochs, verbose= 0, shuffle = True, \n",
    "              validation_data = (validX, validY), \n",
    "              callbacks=[performance]) \n",
    "    else:\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs = performance.best_epoch + 1, verbose = 1, shuffle = True, \n",
    "              validation_data = (validX, validY)) \n",
    "            \n",
    "    performance.model.set_weights(model.get_weights())\n",
    "    \n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "\n",
    "    train_rmses, train_r2s = performance.evaluate(trainX, trainY)            \n",
    "    valid_rmses, valid_r2s = performance.evaluate(validX, validY)            \n",
    "    test_rmses, test_r2s = performance.evaluate(testX, testY)\n",
    "\n",
    "\n",
    "    final_res = {\n",
    "                 'task_name':task_name,            \n",
    "                 'train_rmse':np.nanmean(train_rmses), \n",
    "                 'valid_rmse':np.nanmean(valid_rmses),                      \n",
    "                 'test_rmse':np.nanmean(test_rmses), \n",
    "\n",
    "                 'train_r2':np.nanmean(train_r2s), \n",
    "                 'valid_r2':np.nanmean(valid_r2s),                      \n",
    "                 'test_r2':np.nanmean(test_r2s), \n",
    "\n",
    "                 '# trainable params': trainable_params,\n",
    "                 'best_epoch': best_epoch,\n",
    "                 'batch_size':batch_size,\n",
    "                 'lr': lr,\n",
    "                 'weight_decay':weight_decay\n",
    "                }\n",
    "    results.append(final_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b6c0930b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(performance.history)[['rmse', 'val_rmse']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8892327751942514"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025072556532979986"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_rmse.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./results/%s.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>valid_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>valid_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PDBbind-refined</td>\n",
       "      <td>0.525349</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.864778</td>\n",
       "      <td>0.745875</td>\n",
       "      <td>0.487415</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>803681</td>\n",
       "      <td>24</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PDBbind-refined</td>\n",
       "      <td>0.538194</td>\n",
       "      <td>0.774494</td>\n",
       "      <td>0.888039</td>\n",
       "      <td>0.723629</td>\n",
       "      <td>0.472371</td>\n",
       "      <td>0.338041</td>\n",
       "      <td>803681</td>\n",
       "      <td>24</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PDBbind-refined</td>\n",
       "      <td>0.536861</td>\n",
       "      <td>0.805614</td>\n",
       "      <td>0.914881</td>\n",
       "      <td>0.763745</td>\n",
       "      <td>0.478941</td>\n",
       "      <td>0.365051</td>\n",
       "      <td>803681</td>\n",
       "      <td>24</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task_name  train_rmse  valid_rmse  test_rmse  train_r2  valid_r2  \\\n",
       "0  PDBbind-refined    0.525349    0.756187   0.864778  0.745875  0.487415   \n",
       "1  PDBbind-refined    0.538194    0.774494   0.888039  0.723629  0.472371   \n",
       "2  PDBbind-refined    0.536861    0.805614   0.914881  0.763745  0.478941   \n",
       "\n",
       "    test_r2  # trainable params  best_epoch  batch_size      lr  weight_decay  \n",
       "0  0.350139              803681          24         128  0.0001             0  \n",
       "1  0.338041              803681          24         128  0.0001             0  \n",
       "2  0.365051              803681          24         128  0.0001             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
