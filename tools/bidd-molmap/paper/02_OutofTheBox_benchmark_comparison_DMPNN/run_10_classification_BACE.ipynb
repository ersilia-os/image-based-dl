{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "np.random.seed(123)\n",
    "tf.compat.v1.set_random_seed(123)\n",
    "\n",
    "\n",
    "tmp_feature_dir = './tmpignore'\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: BACE number of split times: 3\n"
     ]
    }
   ],
   "source": [
    "task_name = 'BACE'\n",
    "from chembench import load_data\n",
    "df, induces = load_data(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').values\n",
    "Y = Y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_weights(trainY):\n",
    "    \"\"\"pos_weights: neg_n / pos_n \"\"\"\n",
    "    dfY = pd.DataFrame(trainY)\n",
    "    pos = dfY == 1\n",
    "    pos_n = pos.sum(axis=0)\n",
    "    neg = dfY == 0\n",
    "    neg_n = neg.sum(axis=0)\n",
    "    pos_weights = (neg_n / pos_n).values\n",
    "    neg_weights = (pos_n / neg_n).values\n",
    "    return pos_weights, neg_weights\n",
    "\n",
    "\n",
    "prcs_metrics = ['MUV', 'PCBA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 800\n",
    "patience = 50 #early stopping\n",
    "\n",
    "dense_layers = [256, 128, 32]\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "monitor = 'val_loss'\n",
    "dense_avf = 'relu'\n",
    "last_avf = None #sigmoid in loss\n",
    "\n",
    "if task_name in prcs_metrics:\n",
    "    metric = 'PRC'\n",
    "else:\n",
    "    metric = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210 151 152\n",
      "epoch: 0001, loss: 0.7953 - val_loss: 0.8284; auc: 0.8103 - val_auc: 0.6171                                                                                                    \n",
      "epoch: 0002, loss: 0.7836 - val_loss: 0.8064; auc: 0.8318 - val_auc: 0.6382                                                                                                    \n",
      "epoch: 0003, loss: 0.7736 - val_loss: 0.8266; auc: 0.8532 - val_auc: 0.6452                                                                                                    \n",
      "epoch: 0004, loss: 0.7637 - val_loss: 0.7921; auc: 0.8576 - val_auc: 0.6546                                                                                                    \n",
      "epoch: 0005, loss: 0.7431 - val_loss: 0.7951; auc: 0.8688 - val_auc: 0.6633                                                                                                    \n",
      "epoch: 0006, loss: 0.7213 - val_loss: 0.8374; auc: 0.8775 - val_auc: 0.6702                                                                                                    \n",
      "epoch: 0007, loss: 0.6945 - val_loss: 0.8391; auc: 0.8831 - val_auc: 0.6780                                                                                                    \n",
      "epoch: 0008, loss: 0.6719 - val_loss: 0.8503; auc: 0.8854 - val_auc: 0.6798                                                                                                    \n",
      "epoch: 0009, loss: 0.6473 - val_loss: 0.8436; auc: 0.8897 - val_auc: 0.6828                                                                                                    \n",
      "epoch: 0010, loss: 0.6089 - val_loss: 0.7628; auc: 0.8938 - val_auc: 0.6869                                                                                                    \n",
      "epoch: 0011, loss: 0.5713 - val_loss: 0.7444; auc: 0.8972 - val_auc: 0.6883                                                                                                    \n",
      "epoch: 0012, loss: 0.5423 - val_loss: 0.7565; auc: 0.9023 - val_auc: 0.6935                                                                                                    \n",
      "epoch: 0013, loss: 0.5118 - val_loss: 0.7455; auc: 0.9078 - val_auc: 0.6994                                                                                                    \n",
      "epoch: 0014, loss: 0.4931 - val_loss: 0.7863; auc: 0.9115 - val_auc: 0.7036                                                                                                    \n",
      "epoch: 0015, loss: 0.4745 - val_loss: 0.7460; auc: 0.9171 - val_auc: 0.7090                                                                                                    \n",
      "epoch: 0016, loss: 0.4564 - val_loss: 0.7261; auc: 0.9213 - val_auc: 0.7150                                                                                                    \n",
      "epoch: 0017, loss: 0.4459 - val_loss: 0.8078; auc: 0.9244 - val_auc: 0.7175                                                                                                    \n",
      "epoch: 0018, loss: 0.4304 - val_loss: 0.8367; auc: 0.9284 - val_auc: 0.7217                                                                                                    \n",
      "epoch: 0019, loss: 0.4231 - val_loss: 0.7431; auc: 0.9314 - val_auc: 0.7248                                                                                                    \n",
      "epoch: 0020, loss: 0.4056 - val_loss: 0.7616; auc: 0.9346 - val_auc: 0.7267                                                                                                    \n",
      "epoch: 0021, loss: 0.3893 - val_loss: 0.7632; auc: 0.9377 - val_auc: 0.7271                                                                                                    \n",
      "epoch: 0022, loss: 0.3797 - val_loss: 0.7123; auc: 0.9394 - val_auc: 0.7312                                                                                                    \n",
      "epoch: 0023, loss: 0.4092 - val_loss: 0.8686; auc: 0.9432 - val_auc: 0.7369                                                                                                    \n",
      "epoch: 0024, loss: 0.3879 - val_loss: 0.7966; auc: 0.9454 - val_auc: 0.7393                                                                                                    \n",
      "epoch: 0025, loss: 0.3547 - val_loss: 0.7258; auc: 0.9471 - val_auc: 0.7385                                                                                                    \n",
      "epoch: 0026, loss: 0.3498 - val_loss: 0.7389; auc: 0.9498 - val_auc: 0.7395                                                                                                    \n",
      "epoch: 0027, loss: 0.3379 - val_loss: 0.7086; auc: 0.9522 - val_auc: 0.7445                                                                                                    \n",
      "epoch: 0028, loss: 0.3387 - val_loss: 0.8682; auc: 0.9551 - val_auc: 0.7448                                                                                                    \n",
      "epoch: 0029, loss: 0.3492 - val_loss: 0.7297; auc: 0.9562 - val_auc: 0.7441                                                                                                    \n",
      "epoch: 0030, loss: 0.3271 - val_loss: 0.7160; auc: 0.9577 - val_auc: 0.7448                                                                                                    \n",
      "epoch: 0031, loss: 0.3262 - val_loss: 0.7161; auc: 0.9589 - val_auc: 0.7434                                                                                                    \n",
      "epoch: 0032, loss: 0.3186 - val_loss: 0.7534; auc: 0.9616 - val_auc: 0.7482                                                                                                    \n",
      "epoch: 0033, loss: 0.3113 - val_loss: 0.7121; auc: 0.9618 - val_auc: 0.7484                                                                                                    \n",
      "epoch: 0034, loss: 0.3158 - val_loss: 0.7163; auc: 0.9638 - val_auc: 0.7488                                                                                                    \n",
      "epoch: 0035, loss: 0.3030 - val_loss: 0.7403; auc: 0.9656 - val_auc: 0.7509                                                                                                    \n",
      "epoch: 0036, loss: 0.2957 - val_loss: 0.7198; auc: 0.9675 - val_auc: 0.7527                                                                                                    \n",
      "epoch: 0037, loss: 0.2999 - val_loss: 0.8137; auc: 0.9684 - val_auc: 0.7504                                                                                                    \n",
      "epoch: 0038, loss: 0.2782 - val_loss: 0.7531; auc: 0.9699 - val_auc: 0.7518                                                                                                    \n",
      "epoch: 0039, loss: 0.2737 - val_loss: 0.7364; auc: 0.9710 - val_auc: 0.7516                                                                                                    \n",
      "epoch: 0040, loss: 0.2788 - val_loss: 0.7958; auc: 0.9723 - val_auc: 0.7536                                                                                                    \n",
      "epoch: 0041, loss: 0.2648 - val_loss: 0.8310; auc: 0.9737 - val_auc: 0.7541                                                                                                    \n",
      "epoch: 0042, loss: 0.2833 - val_loss: 0.7519; auc: 0.9734 - val_auc: 0.7553                                                                                                    \n",
      "epoch: 0043, loss: 0.2973 - val_loss: 0.8100; auc: 0.9744 - val_auc: 0.7550                                                                                                    \n",
      "epoch: 0044, loss: 0.2575 - val_loss: 0.7394; auc: 0.9752 - val_auc: 0.7546                                                                                                    \n",
      "epoch: 0045, loss: 0.2511 - val_loss: 0.7991; auc: 0.9772 - val_auc: 0.7564                                                                                                    \n",
      "epoch: 0046, loss: 0.2549 - val_loss: 0.7931; auc: 0.9773 - val_auc: 0.7559                                                                                                    \n",
      "epoch: 0047, loss: 0.2393 - val_loss: 0.7516; auc: 0.9786 - val_auc: 0.7550                                                                                                    \n",
      "epoch: 0048, loss: 0.2328 - val_loss: 0.7557; auc: 0.9799 - val_auc: 0.7541                                                                                                    \n",
      "epoch: 0049, loss: 0.2365 - val_loss: 0.7866; auc: 0.9807 - val_auc: 0.7525                                                                                                    \n",
      "epoch: 0050, loss: 0.2287 - val_loss: 0.7767; auc: 0.9816 - val_auc: 0.7550                                                                                                    \n",
      "epoch: 0051, loss: 0.2229 - val_loss: 0.8495; auc: 0.9826 - val_auc: 0.7560                                                                                                    \n",
      "epoch: 0052, loss: 0.2265 - val_loss: 0.8131; auc: 0.9841 - val_auc: 0.7559                                                                                                    \n",
      "epoch: 0053, loss: 0.2211 - val_loss: 0.7981; auc: 0.9833 - val_auc: 0.7585                                                                                                    \n",
      "epoch: 0054, loss: 0.2147 - val_loss: 0.7643; auc: 0.9852 - val_auc: 0.7555                                                                                                    \n",
      "epoch: 0055, loss: 0.2074 - val_loss: 0.8873; auc: 0.9855 - val_auc: 0.7568                                                                                                    \n",
      "epoch: 0056, loss: 0.2062 - val_loss: 0.8127; auc: 0.9869 - val_auc: 0.7541                                                                                                    \n",
      "epoch: 0057, loss: 0.1999 - val_loss: 0.8009; auc: 0.9871 - val_auc: 0.7559                                                                                                    \n",
      "epoch: 0058, loss: 0.2107 - val_loss: 1.0683; auc: 0.9880 - val_auc: 0.7552                                                                                                    \n",
      "epoch: 0059, loss: 0.2174 - val_loss: 0.7810; auc: 0.9864 - val_auc: 0.7564                                                                                                    \n",
      "epoch: 0060, loss: 0.2063 - val_loss: 0.8348; auc: 0.9881 - val_auc: 0.7536                                                                                                    \n",
      "epoch: 0061, loss: 0.2031 - val_loss: 0.8007; auc: 0.9879 - val_auc: 0.7507                                                                                                    \n",
      "epoch: 0062, loss: 0.1970 - val_loss: 0.9638; auc: 0.9895 - val_auc: 0.7566                                                                                                    \n",
      "epoch: 0063, loss: 0.2204 - val_loss: 0.8204; auc: 0.9882 - val_auc: 0.7569                                                                                                    \n",
      "epoch: 0064, loss: 0.1952 - val_loss: 1.1148; auc: 0.9890 - val_auc: 0.7580                                                                                                    \n",
      "epoch: 0065, loss: 0.2070 - val_loss: 0.8000; auc: 0.9900 - val_auc: 0.7548                                                                                                    \n",
      "epoch: 0066, loss: 0.1817 - val_loss: 0.8745; auc: 0.9904 - val_auc: 0.7555                                                                                                    \n",
      "epoch: 0067, loss: 0.1706 - val_loss: 0.8545; auc: 0.9913 - val_auc: 0.7555                                                                                                    \n",
      "epoch: 0068, loss: 0.1754 - val_loss: 0.9776; auc: 0.9923 - val_auc: 0.7566                                                                                                    \n",
      "epoch: 0069, loss: 0.1760 - val_loss: 0.8091; auc: 0.9923 - val_auc: 0.7555                                                                                                    \n",
      "epoch: 0070, loss: 0.1727 - val_loss: 0.9474; auc: 0.9924 - val_auc: 0.7550                                                                                                    \n",
      "epoch: 0071, loss: 0.2294 - val_loss: 0.8401; auc: 0.9915 - val_auc: 0.7512                                                                                                    \n",
      "epoch: 0072, loss: 0.1818 - val_loss: 0.8094; auc: 0.9922 - val_auc: 0.7534                                                                                                    \n",
      "epoch: 0073, loss: 0.1732 - val_loss: 1.0869; auc: 0.9924 - val_auc: 0.7552                                                                                                    \n",
      "epoch: 0074, loss: 0.2028 - val_loss: 0.8416; auc: 0.9917 - val_auc: 0.7546                                                                                                    \n",
      "epoch: 0075, loss: 0.1917 - val_loss: 0.9763; auc: 0.9932 - val_auc: 0.7548                                                                                                    \n",
      "epoch: 0076, loss: 0.2034 - val_loss: 1.3260; auc: 0.9931 - val_auc: 0.7587                                                                                                    \n",
      "epoch: 0077, loss: 0.1822 - val_loss: 0.8365; auc: 0.9925 - val_auc: 0.7553                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00077: early stopping\n",
      "1210 151 152\n",
      "Train on 1210 samples, validate on 151 samples\n",
      "Epoch 1/27\n",
      "1210/1210 [==============================] - 3s 2ms/sample - loss: 0.7916 - val_loss: 0.8233\n",
      "Epoch 2/27\n",
      "1210/1210 [==============================] - 0s 267us/sample - loss: 0.7725 - val_loss: 0.8204\n",
      "Epoch 3/27\n",
      "1210/1210 [==============================] - 0s 286us/sample - loss: 0.7478 - val_loss: 0.8062\n",
      "Epoch 4/27\n",
      "1210/1210 [==============================] - 0s 295us/sample - loss: 0.7160 - val_loss: 0.8027\n",
      "Epoch 5/27\n",
      "1210/1210 [==============================] - 0s 281us/sample - loss: 0.6848 - val_loss: 0.7777\n",
      "Epoch 6/27\n",
      "1210/1210 [==============================] - 0s 295us/sample - loss: 0.6423 - val_loss: 0.7549\n",
      "Epoch 7/27\n",
      "1210/1210 [==============================] - 0s 282us/sample - loss: 0.6142 - val_loss: 0.7471\n",
      "Epoch 8/27\n",
      "1210/1210 [==============================] - 0s 275us/sample - loss: 0.5884 - val_loss: 0.7481\n",
      "Epoch 9/27\n",
      "1210/1210 [==============================] - 0s 277us/sample - loss: 0.5760 - val_loss: 0.7482\n",
      "Epoch 10/27\n",
      "1210/1210 [==============================] - 0s 283us/sample - loss: 0.5458 - val_loss: 0.7460\n",
      "Epoch 11/27\n",
      "1210/1210 [==============================] - 0s 287us/sample - loss: 0.5069 - val_loss: 0.7575\n",
      "Epoch 12/27\n",
      "1210/1210 [==============================] - 0s 269us/sample - loss: 0.4833 - val_loss: 0.7742\n",
      "Epoch 13/27\n",
      "1210/1210 [==============================] - 0s 301us/sample - loss: 0.4669 - val_loss: 0.7894\n",
      "Epoch 14/27\n",
      "1210/1210 [==============================] - 0s 281us/sample - loss: 0.4454 - val_loss: 0.7430\n",
      "Epoch 15/27\n",
      "1210/1210 [==============================] - 0s 273us/sample - loss: 0.4337 - val_loss: 0.8211\n",
      "Epoch 16/27\n",
      "1210/1210 [==============================] - 0s 271us/sample - loss: 0.4255 - val_loss: 0.7401\n",
      "Epoch 17/27\n",
      "1210/1210 [==============================] - 0s 293us/sample - loss: 0.4396 - val_loss: 0.8570\n",
      "Epoch 18/27\n",
      "1210/1210 [==============================] - 0s 286us/sample - loss: 0.4318 - val_loss: 1.0255\n",
      "Epoch 19/27\n",
      "1210/1210 [==============================] - 0s 264us/sample - loss: 0.4176 - val_loss: 0.8389\n",
      "Epoch 20/27\n",
      "1210/1210 [==============================] - 0s 281us/sample - loss: 0.3808 - val_loss: 0.8072\n",
      "Epoch 21/27\n",
      "1210/1210 [==============================] - 0s 308us/sample - loss: 0.3808 - val_loss: 0.7553\n",
      "Epoch 22/27\n",
      "1210/1210 [==============================] - 0s 279us/sample - loss: 0.3598 - val_loss: 0.7586\n",
      "Epoch 23/27\n",
      "1210/1210 [==============================] - 0s 283us/sample - loss: 0.3671 - val_loss: 0.7302\n",
      "Epoch 24/27\n",
      "1210/1210 [==============================] - 0s 306us/sample - loss: 0.3709 - val_loss: 0.9284\n",
      "Epoch 25/27\n",
      "1210/1210 [==============================] - 0s 310us/sample - loss: 0.3612 - val_loss: 0.7980\n",
      "Epoch 26/27\n",
      "1210/1210 [==============================] - 0s 276us/sample - loss: 0.3391 - val_loss: 0.7208\n",
      "Epoch 27/27\n",
      "1210/1210 [==============================] - 0s 291us/sample - loss: 0.3303 - val_loss: 0.7353\n",
      "1210 151 152\n",
      "Train on 1210 samples, validate on 151 samples\n",
      "Epoch 1/27\n",
      "1210/1210 [==============================] - 3s 2ms/sample - loss: 0.7923 - val_loss: 0.8247\n",
      "Epoch 2/27\n",
      "1210/1210 [==============================] - 0s 287us/sample - loss: 0.7769 - val_loss: 0.8194\n",
      "Epoch 3/27\n",
      "1210/1210 [==============================] - 0s 272us/sample - loss: 0.7575 - val_loss: 0.8054\n",
      "Epoch 4/27\n",
      "1210/1210 [==============================] - 0s 276us/sample - loss: 0.7323 - val_loss: 0.8163\n",
      "Epoch 5/27\n",
      "1210/1210 [==============================] - 0s 287us/sample - loss: 0.7024 - val_loss: 0.7759\n",
      "Epoch 6/27\n",
      "1210/1210 [==============================] - 0s 282us/sample - loss: 0.6677 - val_loss: 0.7765\n",
      "Epoch 7/27\n",
      "1210/1210 [==============================] - 0s 262us/sample - loss: 0.6298 - val_loss: 0.7498\n",
      "Epoch 8/27\n",
      "1210/1210 [==============================] - 0s 276us/sample - loss: 0.5937 - val_loss: 0.7331\n",
      "Epoch 9/27\n",
      "1210/1210 [==============================] - 0s 280us/sample - loss: 0.5674 - val_loss: 0.7482\n",
      "Epoch 10/27\n",
      "1210/1210 [==============================] - 0s 283us/sample - loss: 0.5269 - val_loss: 0.8607\n",
      "Epoch 11/27\n",
      "1210/1210 [==============================] - 0s 262us/sample - loss: 0.5166 - val_loss: 0.7723\n",
      "Epoch 12/27\n",
      "1210/1210 [==============================] - 0s 277us/sample - loss: 0.4769 - val_loss: 0.7564\n",
      "Epoch 13/27\n",
      "1210/1210 [==============================] - 0s 279us/sample - loss: 0.4562 - val_loss: 0.7828\n",
      "Epoch 14/27\n",
      "1210/1210 [==============================] - 0s 259us/sample - loss: 0.4525 - val_loss: 0.7424\n",
      "Epoch 15/27\n",
      "1210/1210 [==============================] - 0s 273us/sample - loss: 0.4439 - val_loss: 0.7289\n",
      "Epoch 16/27\n",
      "1210/1210 [==============================] - 0s 289us/sample - loss: 0.4267 - val_loss: 0.8941\n",
      "Epoch 17/27\n",
      "1210/1210 [==============================] - 0s 270us/sample - loss: 0.4047 - val_loss: 0.8058\n",
      "Epoch 18/27\n",
      "1210/1210 [==============================] - 0s 272us/sample - loss: 0.3980 - val_loss: 0.7133\n",
      "Epoch 19/27\n",
      "1210/1210 [==============================] - 0s 279us/sample - loss: 0.3874 - val_loss: 0.7269\n",
      "Epoch 20/27\n",
      "1210/1210 [==============================] - 0s 307us/sample - loss: 0.3873 - val_loss: 0.7077\n",
      "Epoch 21/27\n",
      "1210/1210 [==============================] - 0s 312us/sample - loss: 0.3741 - val_loss: 0.7815\n",
      "Epoch 22/27\n",
      "1210/1210 [==============================] - 0s 345us/sample - loss: 0.3626 - val_loss: 0.7358\n",
      "Epoch 23/27\n",
      "1210/1210 [==============================] - 0s 345us/sample - loss: 0.3728 - val_loss: 0.7441\n",
      "Epoch 24/27\n",
      "1210/1210 [==============================] - 0s 307us/sample - loss: 0.3486 - val_loss: 0.7283\n",
      "Epoch 25/27\n",
      "1210/1210 [==============================] - 0s 313us/sample - loss: 0.3411 - val_loss: 0.7363\n",
      "Epoch 26/27\n",
      "1210/1210 [==============================] - 0s 307us/sample - loss: 0.3288 - val_loss: 0.7168\n",
      "Epoch 27/27\n",
      "1210/1210 [==============================] - 0s 295us/sample - loss: 0.3285 - val_loss: 0.6989\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    testX = (X1[test_idx], X2[test_idx])\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "    pos_weights, neg_weights = get_pos_weights(trainY)\n",
    "    loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "    \n",
    "    if i == 0:\n",
    "        performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                       (validX, validY), \n",
    "                                                                       patience = patience, \n",
    "                                                                       criteria = monitor,\n",
    "                                                                       metric = metric,\n",
    "                                                                      )\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs=epochs, verbose= 0, shuffle = True, \n",
    "              validation_data = (validX, validY), \n",
    "              callbacks=[performance]) \n",
    "\n",
    "\n",
    "    else:\n",
    "        model.fit(trainX, trainY, batch_size=batch_size, \n",
    "              epochs = performance.best_epoch + 1, verbose = 1, shuffle = True, \n",
    "              validation_data = (validX, validY)) \n",
    "            \n",
    "        performance.model.set_weights(model.get_weights())\n",
    "    \n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "    \n",
    "    train_aucs = performance.evaluate(trainX, trainY)            \n",
    "    valid_aucs = performance.evaluate(validX, validY)            \n",
    "    test_aucs = performance.evaluate(testX, testY)\n",
    "\n",
    "\n",
    "    final_res = {\n",
    "                     'task_name':task_name,            \n",
    "                     'train_auc':np.nanmean(train_aucs), \n",
    "                     'valid_auc':np.nanmean(valid_aucs),                      \n",
    "                     'test_auc':np.nanmean(test_aucs), \n",
    "                     'metric':metric,\n",
    "                     '# trainable params': trainable_params,\n",
    "                     'best_epoch': best_epoch,\n",
    "                     'batch_size':batch_size,\n",
    "                     'lr': lr,\n",
    "                     'weight_decay':weight_decay\n",
    "                    }\n",
    "    \n",
    "    results.append(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ddbab57b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2dd3hUZfbHP296J6TTewdB6SBSVER+CnbEtqhYsJd1V9ctrqur7q6uu+raULErdhQUC0iVLr0ECC0B0oH0+v7+eOcmk8lMMqkzCefzPHkmc+fe956ZTL733POec16ltUYQBEFo+fh42gBBEAShcRBBFwRBaCWIoAuCILQSRNAFQRBaCSLogiAIrQQ/T504JiZGd+3a1VOnFwRBaJFs3LgxQ2sd6+w1jwl6165d2bBhg6dOLwiC0CJRSh1y9ZqEXARBEFoJIuiCIAitBBF0QRCEVoLHYujOKCkpITk5mcLCQk+b4tUEBQXRsWNH/P39PW2KIAhehFcJenJyMuHh4XTt2hWllKfN8Uq01mRmZpKcnEy3bt08bY4gCF6EV4VcCgsLiY6OFjGvAaUU0dHRchcjCEI1vErQARFzN5DPSBAEZ3idoAuCIAiA1rD5AyjOd/sQEXQHwsLCPG2CIAgCpO+GL+fAnkVuHyKCLgiC4I3kpZvHwhNuHyKC7gKtNQ899BADBw5k0KBBfPzxxwAcO3aMc845hyFDhjBw4EBWrFhBWVkZs2bNqtj33//+t4etFwShxZOfZR6Lctw+xKvSFu3569c72Hn0VKOO2b99BH+5eIBb+37++eds3ryZLVu2kJGRwfDhwznnnHP44IMPuOCCC3j00UcpKysjPz+fzZs3k5KSwvbt2wE4ccL9K6ogCIJTCrLNY1Gu24eIh+6ClStXMnPmTHx9fYmPj2f8+PGsX7+e4cOH89Zbb/HYY4+xbds2wsPD6d69O0lJSdx999189913REREeNp8QRBaOgWtyEN315Nubs455xyWL1/OwoULmTVrFg888AA33HADW7ZsYfHixbzyyivMnz+fN99809OmCoLQkrFCLsXioTeYcePG8fHHH1NWVkZ6ejrLly9nxIgRHDp0iPj4eG655RZmz57Npk2byMjIoLy8nMsvv5wnnniCTZs2edp8QRBaOhUhF/dDz17roXuaSy+9lF9++YXBgwejlOIf//gHCQkJvP322/zzn//E39+fsLAw3nnnHVJSUrjxxhspLy8H4KmnnvKw9YIgtHgqJkXd99CV1rqJrKmZYcOGaccFLnbt2kW/fv08Yk9LQz4rQWjlvDEZjqyFjsNh9o8Vm5VSG7XWw5wdIiEXQRAEb6Qi5OL+pKgIuiAIgjdSj5CLCLogCIK3obV46IIgCK2CwpOgy8A/BIpzjMC7gQi6IAiCt2EVFUV2Bl0OJe51XBRBFwRB8DbybeGWyM7m0c04ugi6IAiCt1HhoXcxj27G0UXQG0BNvdMPHjzIwIEDm9EaQRBaDQUOHnqxCLogCELLxEpZbFs3D917S/+/fRiOb2vcMRMGwYVPu3z54YcfplOnTtx5550APPbYY/j5+bF06VKys7MpKSnhiSeeYPr06XU6bWFhIXPmzGHDhg34+fnx3HPPMXHiRHbs2MGNN95IcXEx5eXlfPbZZ7Rv356rrrqK5ORkysrK+NOf/sSMGTMa9LYFQWhhFGQBCiI6muduxtBrFXSl1JvARUCa1rpaDEEpdS3we3N2coA5Wust7trtTcyYMYP77ruvQtDnz5/P4sWLueeee4iIiCAjI4NRo0Yxbdq0Oi3U/NJLL6GUYtu2bezevZvJkyeTmJjIK6+8wr333su1115LcXExZWVlLFq0iPbt27Nw4UIATp482STvVRAELyY/C4IjIaiNed6IHvo84EXgHRevHwDGa62zlVIXAq8BI906e03U4Ek3FWeeeSZpaWkcPXqU9PR02rZtS0JCAvfffz/Lly/Hx8eHlJQUUlNTSUhIcHvclStXcvfddwPQt29funTpQmJiIqNHj+bJJ58kOTmZyy67jF69ejFo0CAefPBBfv/733PRRRcxbty4pnq7giB4KwVZENwWAsPN88aKoWutlwNZNby+Wmtti+CzBujo1pm9lCuvvJJPP/2Ujz/+mBkzZvD++++Tnp7Oxo0b2bx5M/Hx8RQWFjbKua655hoWLFhAcHAwU6dOZcmSJfTu3ZtNmzYxaNAg/vjHP/L44483yrkEQWhB5GdBcBQE2hIvPBRDvxn41tWLSqlbgVsBOnfu3MinbhxmzJjBLbfcQkZGBsuWLWP+/PnExcXh7+/P0qVLOXToUJ3HHDduHO+//z6TJk0iMTGRw4cP06dPH5KSkujevTv33HMPhw8fZuvWrfTt25eoqCiuu+46IiMjmTt3bhO8S0EQvJqCbAiLM5WiyqfxYujuopSaiBH0s13to7V+DROSYdiwYZ7p21sLAwYMICcnhw4dOtCuXTuuvfZaLr74YgYNGsSwYcPo27dvnce84447mDNnDoMGDcLPz4958+YRGBjI/Pnzeffdd/H39ychIYE//OEPrF+/noceeggfHx/8/f15+eWXm+BdCoLg1RRkQWxfUAoCwt1etcitfuhKqa7AN84mRW2vnwF8AVyotU5058TSD71hyGclCK2Yv3eEs66HKU/BcwOg+3i45H9AE/dDV0p1Bj4HrndXzAVBEAQXlBabSdDgKPM8MKzxYuhKqQ+BCUCMUioZ+AvgD6C1fgX4MxAN/M+Wylfq6urRGtm2bRvXX399lW2BgYGsXbvWQxYJgtCisapEgyPNY0AjCrrWemYtr88GZrt1NjfQWtcpx9vTDBo0iM2bNzfrOT21bKAgCM2A1cclxPLQ3Y+he1Xpf1BQEJmZmSJYNaC1JjMzk6CgIE+bIghCU2CV/TdFyKU56dixI8nJyaSnp3vaFK8mKCiIjh1bdLq/IAiusEIuFR56RPOnLTYG/v7+dOvWzdNmCIIgeI4CBw+9DjF0rwq5CIIgnPbkO4uhu7cMnQi6IAiCN1GQBb4BpkoUTAzdzWXoRNAFQRC8CauPi5XtZzXociOOLoIuCILgTRRkV4ZbwJT+g1txdBF0QRBaB0d/dXvy0KuxPHSLOrTQFUEXBKHlU1IAb0yGda972pKGU5ANIW0rn9ehha4IuiAILZ+8dCgrhlNHPW1Jwylw4aFLDF0QhNOCXFsxYn6GZ+1oKFrbQi52HroVQ3ej/F8EXRCElk+eTdDzWrigF+dCeUnVSdEKD/1UrYeLoAuC0PKxBD3f5WqZniU/C1b9t/biIMc+LmAXQxcPXRCE04G8NPPorSGXHV/AD3+C9N017+fYaRHslqGTSVFBEE4HrFBLfqZbJfLNTq7tglPbpG1FL3Q7Qa/DMnQi6IIgNB2Fp+DA8qY/jyWY5aVQeKLpz1dXclPNY86xmvdz7ONi4WYLXRF0QRCajo3z4J3pUNDEIptn13I7L7Npz1UfKjz0WgTdmYcOZmJUBF0QBI9yKsU0lrIEranIy6hsZuWNcXQrxp9TS8ilYlI0sup2N1voiqALgtB05Bw3j3lNLehpENvH9rsXCroVcqnVQ88yC1r4+lfd7uYydCLogiA0HZaQNaWHXl5mJkNj+5nn3uaha135/t2JodsXFVlIDF0QBI9jCXpeEy4rWZBtwjpxfW3n8jJBLzoFpYXm99oEvSCr+oQouL0MnQi6IAhNR04zeOjW2G06gX+o8da9CastQdtuxtayEtf7FmRXnxAFiaELguBhinKgJM/83pQxdMv7D42F0Gjv89Ctu5T2QwBd+dwZ+a48dPeWoRNBFwShabD3ynObMORiCXpYHITEeF8M3RLwdoPNY00TowU1xNDdWIZOBF0QhKbBynDxDWhGDz3GCz1023tvN8Q8ukpdLCuFwpPOQy5uttCtVdCVUm8qpdKUUttdvK6UUv9VSu1TSm1VSp1V25iCIJwG5NoEPbZv03voyheCIm0eupfF0PPSwMcP4gea5648dKvC1VnIxc0Wuu546POAKTW8fiHQy/ZzK/CyG2MKgtDasTzThDOMqDVVj5XcNOOd+/hUxtC9qZ9Lbmrl3YNvgGsP3VmnRQs3W+jWKuha6+VATT0ppwPvaMMaIFIp1a62cQVBaOXkHAcff4jpZdL2mmq9z7wMI5hgPPSyIijOa5pz1YfcNBPfVwrCEypDUY5YZf8hLmLo0PCQixt0AI7YPU+2bauGUupWpdQGpdSG9PQmvAUTBMHz5KZCWLz5gabLRc9LgzCboIfGmEdvmhi1PgeA8PauOy4W1OChB7i3rmizTopqrV/TWg/TWg+LjY1tzlMLgtDc5KZCeHyl2DaZoKdX9dDBuxp05aYbDx1sHrqLGHpFyMWZhx5hHhshhl4bKUAnu+cdbdsEQTidyUmFsAQItYlZUxUX2YdcvM1DLy83dxDWZxDR3kyKOovxO1vcwqIi5NLAGLobLABusGW7jAJOaq1rqW8VBKHVk5tqPFPLO22K1MWiXJObXeGhR9vOVU9BT94Ab/0flBQ0jn0F2aZHe0XIpZ0ptnImzPlZJhvG8sbtcTNt0a82e5RSHwITgBilVDLwF8AfQGv9CrAImArsA/KBG2sbUxCEVk5ZifGSwxNsYRDVNKmL9jno0HAPfccXcGglpO2EDkMbbp9VVBRm56GD8dKD2lTdN/ugeV2p6uO4uQxdrYKutZ5Zy+sauLO2cQRBOI2wwith8eDrZ8IIDfHQ9y8xseX2Z1bdbl8lCmby0Dew/h56ykbzmLG3cQQ9z+5zAOOhg0ldtJqJWRzfalI8neHmMnRSKSoIQuNT4ZnahCw0rmEx9K/uhh/+Un17hYdu88yVMr/Xp7iorBSObTG/Z+ytn52O5DoIeoRN0B2Li4pyIXN/ZXsAZ7jRQrdWD10QBKHOWIIebhOysNj6Z7kU5cCpZCgtMJOJ9iEJx5ALmDh6fTz09N2VvVIyG0vQrQubzb4KD91B0FO3A9q1hw5uLUMnHrogCI2PVTwTlmAeG+KhW95yfmb1MXKdCHpoPRt0Hd1kHqN7QsY+1/vtXwLL/+nemLmp4BdUOdHpH2xCR46CfmyreWxXg6C70UJXBF0QhMbHEl5LaMPi6u+h24c/Uh1aSuWlQ2Ab8Aus3BZSzwZdKRvNRGXvKZC136QcOmPd67DkSdNIqzasHHT7u4rwdtVDLse3GLvDayiyd2MZOhF0QRAan9zjJvThF2Ceh8YaMSquuf2rUzL2mAwPgNQdVV/LS68MZ1jUN4aesslMulqtCk4ecb7f8W2AhiPrah/TvkrUIrxd9X4ux7Ya79xZhouFGzF0EXRBEBqfHAchszz1+mS6ZCRCVA8jhM4EPdRB0EOizMWjpND9c5QUmLE7DIXoXmabszh6QXal0B9aVfu4uXZFRRYRDh56aTGk7YKEQTWP5cYydCLogiA0Po6eqZVWWJ9c9Iy9ENMb4ge4EPSYqttC6pGLfnwb6DIj6DG9Ks9bbT9byMc3AA79Uvu4VnGVPeHtzYWtrNQ8T98N5SU1T4iCiaEXi4cuCEJzk5tqioos6uuhl5WadL6YXkbQ03dXXZPTmQdsCXxd4uhW/nn7s4ytgW2cC7oVwx94uTmmporSslIT+nEMuUS0M6sPWRkwx60J0RpSFkGyXARB8ABaV/dMw+rZzyX7oPFeY/uYBSLKSyqFtqzU9D+pFnKxPPQ6xNFTNhnPOaKdiWPH9HQecjm+zVxA+l9ibLEuBM7IzwC0cw8dKjNdjm01i1tH9ajZRmsZuhoQQRcEoXEpyIay4sqURbDz0OsYcsnYYx6tkAtUhl0swXY2KWr/ujukbIQOdoutxfR2nrp4fCskDITOIwEFh1a7HtOx7N8iwiEX3RrTpxY5tlro1oAIuiAIjYtjURGYtMKgNvUQ9ETzGNPLTFb6+EOaTdDzHFIjLeraoKsg26Qp2gt6dE+TiWI/CVlaDOl7zORlcFtzgalR0B2qRC3C7fq5lJcbr7+2+Dk4b9rlgAi6IAiNS0VRkYOQ1ae4KGOv8fSD2pgUyNg+lR66sypRMGuLKl/3J0WP/moe7Xu3WBOjmXZeekaiufOwxLfLGJO6aE1uOlIh6A4eeki0uTDlHIXsAyYjp6aCIotA8dAFQWgsMvaa9rK1USFkCVW316e4KH1PpbhC1UyXiipRB8H08alb+b8VB283pHJbtBNBP77NZoNtsefOo00r3ONbnI9r3ak4sy88wXjoVu8Ytzz08Fp3EUEXBME9vv09vH+FCT3URK7NQw939NBj6+aha20uIrF9KrfFD4BTKaZ3uGNjrirnqkNxUcqvRsCDIyu3RXUHVPUqVb8gE44B46GD67BLbprpkBgQUv01q7jo+FbTAz2uX+12SgxdEIRGQWtI2WDizUk/17xvTqrp3+0oQGFxdUtbzE2FopNmgtLCmhhN22kE3Tegel9xcO2hZzop6XecEAXwD4LIzpUxfDDiG9fftAMG42VHdXedj+4sB93CKi46thVi+1VtXeAKiaELLinKaZolwUqLm251d8FzZCVV9i7Z/mnN+1pFRY5l7KFxZozSIvfOWTEhai/otnBH6o7KKlFn5fLOGnQdXAUvnAUfzqhcv/PUUXNH4az3eUyvytRFrW2TlwOr7tN5DBxe7bzvS1569XkEi/D2Jsvl+Fb34ucgMXShBr57BF6fBOVljTvuT3+F189t3DEFz5Ni60TYYSjsXlhzQY1jUZFFXReLdiboYfHG+07d7rxK1MJZg66tH5nFL/YvhdfGw9HNlfFzZ4Ie3avSoz911NydOMa6u4wx2630Sntq89CLc817cCd+DhJDF2rg6GbTk+LA8sYdN3m9+XJ706rrQsNJ2WjCKBP/YIQocbHrfXOOOxeyui4WnZ5owjbWsm1gvHFrYtRZlWjFuWKg8ERlVWlpMexcAP2nw03fGUfmjcmw6j8mhh0/sPoYMT1Nf/Sco5UToo79VrqMNo/O+ro4a8xlEW73ntz10K1l6Grg9BP0spLGWwC2pVJeVun9bJ3feONqbbISAFK3Nd64gudJ2WhK07tPNCK6/TPX++amVc9wAbvFouvgocf0qh5SiR9omlnlplZPWbSwctGt0ErSUiPwAy+HjsPgtuVGjJPXm/H8g6qPEW3X08X6PlsxfIu23cwEp2McvaTQhJcci54sIuza5Dq7mDjDWoauBk4fQT91FH76GzzbB57qBG9eCD8/bWaoa5u1b21kH4SyIjOZtOvr+rU0dUZumvmngcomRoLnObYFnhtQc5l6TZSVmFhvh6Hg4wsDLoW930Ohk5XrSwrMRKZjhgtUiq+7HnpGYtVwi0X8AJvnfMx1yMVxsehtn5r89B6TKl+/7nO44CmY+KjzMaxzZ+4zHnrbbtXDHkqZ9MVDq41DY1Gx1qkrD90m6FHdIaj2yc4Kaomjt05BLy8zV+asJEhaBp/eBM8PghXPQqdRMGqOWc7q56fhrQvh3/3hZLKnrW4+LC967H2me1vit40zrn0c8bh46F7DxnlmCbfPbqm1/apT0naa/uDWAs0DLzfP9yyqvq/jWqL21KVBV1GOSU90JegWrmLUIXYNuorzja39p1X2ZwdzcRp9B/Se7HyM8AQT8snYa5sQddHetssYE5Y5cahym6sq0YqxbYLubvzcopY4eutaU/TX9+H7R6HgBGB3tQyMgBG3wYhbIKpb5faCbNj3E3x2s7mFHHtvs5tcK2tfNZ7Q+Icab8z03eZx2E2wfq4Juwy8vBHGtQl6/MDqK8sInqG0GHZ8AfGDzN9k8SMw7YW6jWE/IQrQaQS06Wz+ZwZfXXXfHEvQnYRcAmypjI4tdLOSTNzdyuuGyoIeZ4Ie29fEknW565CLvYe+d7GJ+9f1O66UyTk/+itkHYDB1zjfr/sE8/jT3+DyueY4V31cLAJCYOAVMPCyutlUSy665zz0guyaX9fa9RJQzjiZAt/+ztwWjf+duZW65GWY+TE8sBOm/L2qmIPpxzDoChMb3PVN3d9DU7P+DfOelj0DxXmNN276bojoYAopBl0B+35snEnM9D0mxtfrfHMOd9PTWhopG+G9K2yOg5ezf4n5Xzv3T3D2fbDpHRNmqwspGyE4Ctp2Nc+VgoGXmrGtGLWFq6Iii9DYqh56eTl8dC3MuwgOr6ncnu4kw8XCP7iyuMdlDN3y0DPNhSc0DrqOc/kWXRLTC5LXYRZwdhHrjukF5/7ZpHNaa426qhK154o3oO//1c2eTiNqfNlzgp590IQ87ONOFpn74ZVxMO//3I9vL/4DlJfClW+ZmfjRd8CQa6DPlNrTffpebP5ojuv8eZLdC2HRb83ETHkJHFzZeGOn766svht0lfncdnze8HEz9kBsb3MbWV5aeSfQmig4AfNnwb4f6i6MnmDbfCPGPSbBhD+Y8vYFd9ftu56yyRTe2E9ODrzc/I13flV139pCDWEO/VwSvzMhHb8g+OTGylTDjETTjyWqu/NxrLCLK0EPbmsesw9A4vcm7u/j6/o9uiLaru1ATSsKnf0AnHE1LH3S3BG56jPTUKY8VePLnhP0kCj4+Sn44raqntyeb+G1CSYedXi1yWuujX0/ws4v4ZzfVnoRdaHfxbZzL6z7sU3B4bUm7t/+LLj5e/Nl37+kccYuLzfeT2xf8zxhIMQNgG2fNHzs9ESI6VMZF2xtE6Naw9f3mHhpcFR1MfM2inJh9yIjZr7+Jn58+Vzz//blHPfugIvzIH1X9TzthDOM2Dlmu+QcN0Ic4mqyMrZS7LSGFf+CyC7wm69NeOTzW41dGXvMHbV9zNseKzPE1YXD18+I+taPTQLAoCtqf6/OiLHdCQS3NXe1rlAKpv0XOo2EL+aY/9fgKNf2NxFuCbpSaopSao9Sap9S6mEnr3dWSi1VSv2qlNqqlJpa66CRXWDiH80H/s4lJq625An48Grzh5yzCkbcCr+8aL6UrigphEUPmVuwMfe483aqE9vHHO8NHld6oqlki2gP13xsLnxdxjaeoJ88bCaE7ftjnHElHFlr4oT1peCEud2O7WP+fv4h3jcxqjV8ejPs+LJ+x2+cZ0R80h/N3V/Sz67DLqVFnr/j273Q/K3PuKpyW0wvuODvJo3vu4drD+Ud22Ji1e0dSuOVMl76wZUmXGldHHJtOeiuenvbe+gHlplwztn3QcehMOVp2P8TrHzOtuxcH+djAAy/Ga54y3VoB8xFJT/TxPs7Dq/5fbrC8tDjB9a8gDOY8v0Z75uL1uFfXF9smpBaBV0p5Qu8BFwI9AdmKqX6O+z2R2C+1vpM4Grgf26dffxDcPkb5o/6/CATfxpyHdy02PRRmPyEiW9/OQdOHHY+xqr/mEmVqf9yrx+C8zdpvPSDK6vHBJuTkkLT/MjHD677rHJip+e55hb0hItVyOuCNXEZa9cMaNCV5nFbLSXdNWHltcf2Mbe28QO8b2I0Y6+Jc/7017rNzwCk7jQC2H0ijLm3csUaVwU23/8RXhrh2TYI2z6xiZlD3HXoLBh2M6x7FV4cbv7uzkKfYDchelb11866Adp2gY+vhf+NhE3vmmwxVxOBYGLKBVmm5ezyf5nJU2uycdhN5iKx9EmboPdyPU5w29onFK3/n4GX1S7Grojuae44alseziIsFq75qHpBVDPhjoc+AtintU7SWhcDHwHTHfbRgJVM2QY46rYFg66A3ywwtzYX/Rumv2gmPcAI9JXzjIfw6U1V1xIEI+QrnjVfgh4T3T6lU/pebGKCNVXANTVJP5tQ08X/rRo7tHJnG8NLt+LasXaTTW06Qpezzd2Sq3/sWse1W1kGjEdzfGv9x2sKrM8vK8l4gu5SnG++f4HhcOmrxvvsMNRU++1aUH3//CwjbkWnTHWiK7IPmr95U4h+brp5v4OuqO4tKwUXPWccp9AYk+X11lTTKMqRlI3QppNzkW7TAe7aaJwyv0BYcJd5P84yXCysQpvEb+HgChhzd2VRj1Jw8X/Md1+XOZ8QrQtWcVFDMrgCQuD6L+Ds+90/Jn4AzP4Rpv6z/uetJ+4IegfA3jVMtm2z5zHgOqVUMrAIuNvZQEqpW5VSG5RSG/Yey2Z7iq3ZT+dRcPtKc4V2vJJGdTexqeT1xkPa8y2sex1++DN8fL3ptjb5STfeRi20P9PEyDwZdtn9jUmx7Hle1e2xfY141EWEXJG+x/zDWZNGFmdcZRoRWc3+6zzubtMnw5rDSBhkKuVONsJdRWOxf4mxLyzepIO6y4+PmTjypa9W3uL7+Ji7un0/Vs/t3vCmCXWExJj+Ic7QGj64Gt6ZDk93hlfPgUW/gz3fNc5FcOeXRhStuy9ndB4Ftyw1IpqxB+aeW+mRWzjrRGiPr5+5aNy2wghfn/+DAZe43t/K+vj+T+Y7OHRW1dcDw+Gqd8xdRbd6ZKXY03m0uaOqaTLTHbqPd13A5Iq4fhBdyxqhTUBjTYrOBOZprTsCU4F3laredEBr/ZrWepjWelix9uWiF1ZyzetrWLonDV3Tl3jApTB8tsmZ/vBqk/2x5mWTW3rx81XLaOuLjw/0vciIZmOlCFrd6dyhvMxcrHqdX30iRSnjpSf93PBmWmm7qsbPLfpPN4K89eP6jWuVaVuZBNY/kbdMjJYWGY+w5/kw9EaTpZK5v/bjctNh41smvNDToelY/+mmwGbv93bnKTYOR49zTd3DgRXOi9aSfjYXibH3wbjfmgv5r++a+ZMtLi4Crsg+WD1FdOt8c5cU7xgddcDH14jqHWuN2H7ym8qU4rxMc8foGD93hvUdnfmBmV9wheXpZx+AUXc4r3yMHwCzfzBh14Yw5i644cv6h1taIO4IegrQye55R9s2e24G5gNorX8BgoAaL2l924Xzh6l9SUrP48a31jPl+RW8+8tBThaUOD9gyjNww1cwewk8mAiPpsK9W+o/e+2MfheZf9B9PzZ8rC0fwTPdzMSUOxxZa2b5+17k/PWek8wFor4eNFT2WrEyXOwJjjQpnts+rR7acof0PVVvkeP6A8p7JkaPrDXl4j0mwbAbzTzFutdrP27jPLPs2GgnN52dR5kJMPuwy47PzcTg6Dtsk5Haeb+cta8aD37CIzDpUZj1DTx82Him3z/q/lzO7oXwnyHwbPKlv8gAACAASURBVF/49mHTtCrrgEnDrcv/RlisCW+eOgZf3mG+K0cdCooaAyuNLyDcXPCERsUdQV8P9FJKdVNKBWAmPR0Dg4eBcwGUUv0wgl5jBx5fpbj1nB4s/91Enr1yML4+ij99tYMRT/7IfR/9yup9GZSX23ntvn6mIqvjUHPbW9sK2fWh8xiTatTQIqO8DBMe0mWw8EH3PPVd35jwkWO4xaLbBECZytb6cjLZLJkV50TQweTR5mfUPVZfnG8mre0vFIFh5pbzuJO4rCfYv8SIeLdxpqS7/yWw+f2aS+FLi81dYY9zq845WPj4mgtw4vemh4nWJisrtq85Jqq7aTXhODeRlWTyr4fdVLUplK+/mUcqOGFCirVxfJsp5293BnQ7x9j68hjTRRBMJWJd6DQcJv/NlMmvfsEWflHQfkith7pNeAL4BcPIW6uH/YQGU6sqaq1LgbuAxcAuTDbLDqXU40qpabbdHgRuUUptAT4EZukaYyiVBPj5cPnQjiy852y+uftsrhrWiZ92p3HN3LWM/9dSXvhpL8dONlN3RF8/6DPVTIw2pGHX4keNUEz/n6kY+7GWXHqtYffX5oLlqlFPaLT5x2rIxGhFhosLQe95nrmg1fWWP3MvoKuLnje1ANi/xOQIW0VmI28zk5ZbPnR9zM6vjLc9ao7rffpPNxfJfT+ZLKnj20wowbrNHzzDzC9Ya0eCuTPw8TWC7kjCQBh9pwm/1LSifE6qicEHtYFr5sNVb8ODe0zqX1g8DLgMIju5Pt4VI2+HftPMvMHWj014zo0+3G4TEAp3rXPdEEtoEG65uVrrRVrr3lrrHlrrJ23b/qy1XmD7fafWeqzWerDWeojW+vuaR6yOUoqBHdrwt0sGsv7R83h+xhA6tQ3h2R8SGfv0Ema9tY7FO47XHGtvDPpdbLrFHaxnn/D9S8xE2Nn3wZnXmn+QDW9ULWt2JHW78XBdhVssepxrJoedefxaG0/51DFI2w3Zh6rvU5Hh4kLQ/QJMRsDuhXWL/1eUaTvE5hMGmfius658zUluuhFU+0yojsNN1eS6111PQq592aSt9ahhwY6uZxtPc9cC+OUlE0axz/secKm587IukkU58Ot7ZruruZ8JD5vMkm/ud+5YlBSaVMH8TJj5YeViEqHR5uIzZ6WpmK4PSplMs7ZdIGt/44ZbLCI7169qU6gVr+y2GOTvyyVnduCDW0ax7KEJ3DGhJ7uOneK2dzdy/8ebKShu5FV27Ok+wcT3Fv/RTCC6wlkec0kBfPMARPUwE11gPJE2nU25taveJru+ART0ubBm23pMMmEc+0Up0hNh7vnwtxj4ezt4rq/JCX5haPVJv/TdJoYZEuX6HIOvNpV1damCzNhjcnUdZ/WtiVFrlXZPYa2BaaV/ghGukbcZ2w8sq37MkfUmw2PEbTWH93z9TWbHrq9NGGX4zZVpt2DEvvcUk/9eVgKbPzR3BiNvdz1mQKhJeUvfbUI49mhtvkvJ6+GyVxs3HGIR1AaufNvkUnef0PjjC02GVwq6PV2iQ/ntBX1Y9ftJPHh+b77acpTLX17NkaxG6uHtiH+QuX3NzzAtCNa+VtWDy9gLX90JT8SZpda2flLpRS37h5m9v+jflbHRwDCT85uRCCuec37O3QvNBFtNBRlgGvMEhJm7AK1h49tmKa3MfeY2/bzHzLkvfdXEi5c75MGm73btnVt0GGouSFvqkO2SvttWpu1Q2FWR6VLHiVGtjfBlJdXtOFfsX2KEtZ2D+A24zOQqr36hevbQ2pdN5smQmbWP33+6mXD19TfZWI4MvtqUu+/7Cda+Yj7jjsNqHrPPheaObdk/zN95yRMmTffF4aY/y6Q/mvM2Fe3OgN8dqHq3IXg9Xi/oFn6+Ptx9bi/e/M1wjmTnM+3Flaza52RV78ag57kwZ7XpzvbtQ/DBVcbLm39DZWXdoCvMYg6fzzZVrt//EVb/11S9dR9fdbxe55t84BXPmnCIPdkHzWoo7nRd8/U3k197fzDpZV/fY0IHc1bD+Y+b4odhNxkBGX6ziYFm2NqQVmS41FBODcZzHTwTDq10XZ3riNXDxZHwdiYmX9eJ0W2fwJe3w8c3mIrChqC1EfTuE6vf5vsHmXj3vh/NRKJ1R3bqqLlDOfN69+LH3cebUMvgmc4vyj3PN5/Dtw+ZMMbIGmLy9lz4D2Pz1/eY707qDlvp/lOVd4BNSTP3IREaTosRdIuJfeNYcNfZxIQFcv0ba3lj5YGmiauHxcG1n5h/qqRlpgBk/1Ijmvdtg0tfgTvXw7WfGU909QvmVnXyE87Hm/K0EYd3pleNp1sZNbXFzy16TDLFOrsXGhG//kvnsdix95mmXsueMc9zjplb/do8dKj0ypyl2zmGmspKjEg5u1AoZT6bukyMnkyBhb+FiI7mQrf2ZfePPXHEiLE9aTvNxKZ9uMWecQ/CZXPN3cAr44xHvOZl47G7m1bnFwh3rHFdGWjNTZw4bIq63PWs23SA21eYC/ajx+GeTSZmPvqO0yq3WnCfFifoAN1iQvnizrGc3z+ev32zk0e/3E5JWR17c7iDFWe9bbnJWLl/O5z3l0ovzMcHep0H130Kd2+C2T+ZiSlnhMaYFgf+waYt8C//s2W3LDTZII692l0x8HI48zq4+QezIIfLJkixRpC2f2o889omRO1p28WkcNqn2x1ZZ5qoPdPVLDBtkZVkWia48vwTBpk+KO542uXl8NUdZrxZX0PvC2Hp3927Uzi02qTsvTSyajM3KyvIVWsIpUxzsrvWmxVtlj5p7rT6THX/bwLm866pl5AVuhl+c90836juptCmvn2KhNOKFinoAGGBfrx87VDmTOjBB2sPc9O89a6LkhpKXF+TsRLUxvU+0T1qF4CEQXDrz9DrArNyzEfXwpE1dWtyHxIF01+quRzbYsy9puvhsmdqT1l0ZPAME/ff9LZZzOGN800s3D/YVOtanrBjDxdHEgaZSdbjW5y/bs/6101o64InjJBN/YfZvuh3NZfDJ34P715q0vWiusNHM82FoLzcCHpMH9OvpiZCY+CKN+HqD016Y2OuEAUmbn7jt+bOSRCaiBYr6AA+PorfT+nLP644gzVJmVz+8moOZzbRZGljERwJV78P5/3VNCjS5e6HW+pKaLRpQbz9cxMTDo5yvydF/0tMK4Cv74WUDWbC9d4tcP3nJsf+gxnmMaMWQe8yxhSSvDXVzDO4qoBMTzTFNL0mm9J8MOltEx4xn9NuF8Ve2z41Ah7bB276zvwMudZcxD682njursItzug71fSgt9bPbEy6jJG4tNCkqCbP63bBsGHD9IYNGxptvDVJmdz+3kZ8leLj20bRM64RiyGaioOrjFiOuafpYqL5WfD8GWYx6M5j4KY6LAi94S3T12P47KoFT3t/MBPFvacYj/3IOhOOckX2IbOYyZaPzDzCmHsqGzhpDWj44naTIXTHmsq8ajAx+tcmmpzru9ZVTlKWFJh87kUPmSZM13xUeQeltcn9//b3Jnxz7admYloQWgFKqY1aa6dpUq1G0AH2p+dy9WtrUMD820bTNSa0UcdvsSx5wqQwDrvJpDU2BmtfNeudKh+TQXK9G0vYpe40trhaGerKeabgxpHkDTD3PFPEExBq5gOyDwHaePRXvm3anDpyeI25MznvMYlBC62G00bQARJTc5jx6i+EBPgx//bRdIgMrv2g1k5BthHEc//cuLnLix6Cda+Z1L9a1jqswtHNJp8fKu9MIjpAl9Guj/nuDybGHt3ThFdi+phOgn2mmnROQThNOK0EHWB7yklmvr6G6NAA5t82mriIoNoPEupOWalZLqzfNNcNvxoTrSVdTzjtqUnQW/SkqCsGdmjDvBtHkJZTxLVz15KR66LkXmgYvn4w/nfNI+YgYi4ItdAqBR1gaJe2vGGrKr3sf6tJSq+hTaogCEIroNUKOsDoHtF8cMsocotKufzl1Ww85MEFoAVBEJqYVi3oAGd1bsvnc8bQJtifa15fy3fbj3naJEEQhCah1Qs6QNeYUD6bM4b+7SOY8/4m5q064GmTBEEQGp3TQtABosMC+fCWUZzfL57Hvt7JCz/tbfrFMgRBEJqR00bQwSyc8b9rz+KyMzvw7A+JPPPdHhF1QRBaDX6eNqC58fP14V9XDiY4wJdXlu0nv7iUxy4egI+PpMQJgtCyOe0EHUxTrycuGUhIgC+vrzhAfnEZ/7j8DBF1QRBaNKeloINZlPoPU/sRHODHf3/aS9+EcGaP6+5pswRBEOrNaRVDd0Qpxf3n9eLcvnH8c/EeKT4SBKFFc1oLOhhR//tlgwj08+G3n2yhrFwmSQVBaJmc9oIOEB8RxF+nD2DT4RO8uVJy1AVBaJmIoNu4ZEgHzusXzz+/38O+NAm9CILQ8nBL0JVSU5RSe5RS+5RSD7vY5yql1E6l1A6l1AeNa2bTY0IvJvNFQi+CILREahV0pZQv8BJwIdAfmKmU6u+wTy/gEWCs1noA0CJXwo0LD+Kv0waw+cgJXlue5GlzBEEQ6oQ7HvoIYJ/WOklrXQx8BDgue3ML8JLWOhtAa53WuGY2H9MGt2fKgAT+/UMiu4+f8rQ5giAIbuOOoHcAjtg9T7Zts6c30FsptUoptUYpNcXZQEqpW5VSG5RSG9LT0+tncROjlOLJSwcSEezHAx9vobi03NMmCYIguEVjTYr6Ab2ACcBM4HWlVKTjTlrr17TWw7TWw2JjYxvp1I1PdFggf790EDuPneK/P+31tDmCIAhu4Y6gpwCd7J53tG2zJxlYoLUu0VofABIxAt9imTwggcvP6sj/ft7Hr4ezPW2OIAhCrbgj6OuBXkqpbkqpAOBqYIHDPl9ivHOUUjGYEEyLn1X8y7T+JEQE8eD8LRQUl3naHEEQhBqpVdC11qXAXcBiYBcwX2u9Qyn1uFJqmm23xUCmUmonsBR4SGud2VRGNxcRQf7868rBJGXk8cx3uz1tjiAIQo241ZxLa70IWOSw7c92v2vgAdtPq2JMzxhmjenKvNUH6d8+gquGdar9IEEQBA9w2nZbrAt/mNqP/em5PPL5NmLDA5nYJ87TJgmCIFRDSv/dIMDPh5evG0qf+HDufH8TW5NPeNokQRCEaoigu0lYoB/zbhxO25AAbpq3nsOZ+Z42SRAEoQoi6HUgLiKIt28aQWm55oY315KZW+RpkwRBECoQQa8jPePCmHvDMI6eLOS2dzdSVCrpjIIgeAci6PVgWNconr1yMBsOZfPIZ9swST6CIAieRbJc6snFg9tzICOP535IpEdcGHdO7OlpkwRBOM0RQW8Ad0/qSVJ6Lv9cvIeu0aH83xntPG2SIAinMRJyaQBKKZ6+/AyGdmnLA/M3s/mIpDMKguA5RNAbSJC/L69dP5S4iECum7uWrzY79i0TBEFoHkTQG4HosEA+unU0fRPCufejzTz0yRbyiko9bZYgCKcZIuiNRIfIYD66dRT3TOrJp5uSufiFlWxPOelpswRBOI0QQW9E/Hx9eGByHz6YPYq84lIu/d8q5q5IolwWnBYEoRkQQW8CRveI5rt7z2F87zieWLiLm95eT4ZUlQqC0MSIoDcRbUMDeP2Gofxt+gBW789kyvMrWJ7oneuoCoLQOhBBb0KUUlw/uisL7hpLVKg/N7y5jicX7pR2AYIgNAki6M1A34QIFtx1NteN6szrKw4w/cVV7D5+ytNmCYLQyhBBbyaC/H154pJBvDVrOBm5xUx7YRWvL5cJU0EQGg8R9GZmYt84Ft83jvF9Ynly0S5mvPYLP+5MpUyEXRCEBqI81Slw2LBhesOGDR45tzegtWb+hiM8+30iaTlFdIgM5pqRnblqWCdiwwM9bZ4gCF6KUmqj1nqY09dE0D1LSVk5P+xM5b01h1i9PxN/X8W1I7vwwOTeRAT5e9o8QRC8jJoEXbotehh/Xx+mDmrH1EHt2J+ey9wVSbz9y0G+2XqMRy7sy2VndUAp5WkzBUFoAUgM3YvoERvGU5edwYI7z6Zj22Ae/GQLV736CxsPZcnkqSAItSIhFy+lvFzzycYjPPPdHrLyiokJC+CcXrGM7xPLuF6xRIUGeNpEQRA8gIRcWiA+PooZwzszZWA7luxO5ec96Szdk8bnv6bg56OYM6EHd0/qRYCf3GQJgmAQD70FUVau2ZZykndWH+TzX1Po3y6CZ68aTL92EZ42TRCEZqImD90t904pNUUptUcptU8p9XAN+12ulNJKKacnExqGr49iSKdInpsxhNeuH0paTiHTXlzJS0v3UVpWXqexftyZWq/jBEHwXmoVdKWUL/AScCHQH5iplOrvZL9w4F5gbWMbKVRn8oAEvr9/PJP7J/DPxXu47OXV7DzqXjuBVfsyuP29jfxz8R5unLeekwUlTWytIAjNgTse+ghgn9Y6SWtdDHwETHey39+AZ4DCRrRPqIGo0ABeuvYsXrzmTI6eKODiF1fy9Le7KSxx3fxrz/Ecbn93I91jQ/nLxf1Zk5TJpS+tIik9txktFwShKXBH0DsAR+yeJ9u2VaCUOgvopLVeWNNASqlblVIblFIb0tOllWxjcdEZ7fnxgfFccVZHXlm2nwueX86yxHQc50dSTxVy41vrCA7w5a0bR3Dj2G68d/NIThSUcMlLq1ixV/4mgtCSaXCKhFLKB3gOeLC2fbXWr2mth2mth8XGxjb01IIdkSEBPHPFGXx4yyh8lOI3b67j3GeX8dLSfRw9UUBeUSk3zVvPiYIS3pw1nA6RwQCM7B7NV3eOpV2bYGa9tZ4lu1M9/E4EQagvtWa5KKVGA49prS+wPX8EQGv9lO15G2A/YN2zJwBZwDSttcs0FslyaToKS8pYsOUon21MZu2BLJSChIgg0nKKmHvDMCb2jat2TG5RKVe98gvJ2fksvGccnaJCPGC5IAi10aBeLkopPyAROBdIAdYD12itd7jY/2fgtzWJOYigNxeHM/P5bFMy320/zs1nd+Oq4Z1q3PeiF1bQKSqEz+aMIcjftxktFQTBHRqUtqi1LgXuAhYDu4D5WusdSqnHlVLTGtdUobHpHB3C/ef3ZvH959Qo5ta+/54xhB1HT/GXr5xerwVB8GLcqhTVWi8CFjls+7OLfSc03CzBU5zbL567JvbkxaX7OKtLJDOGd/a0SYIguImU/gvVuP/83vx6JJs/fbWD6NBARnaPIlxa+QqC1yOCLlTD10fx36vPZNqLq5j9jpnn6BIdwoD2EQzpFMkVQzu53RzsZH4JvyRlMqFPrMTkBaGJkV4ugktOFpSw8VAWO4+eYuexU+w4eopDmfkE+fswY1gnZo/r7jQbRmvNluSTvL/mEF9vPUphSTlndo7k9RuGERMmqzEJQkOQFYuERmNvag6vLU/iy80plJVrpg5qR+/4cIpKyygqKaeotJxNh7PZcfQUIQG+TB/SgX7twvn7ol3Ehgfy1qzh9IwL9/TbEIQWiwi60OgcP1nIm6sO8MHaw+QWleLnowj08yHAz4eObUO4angnLhnSviL2vvnICWa/vYGi0jJeuW4oY3vGePgdCELLRARdaDLKyjVaa/x8ay86Ts7O56Z560lKz2P6kA5EBPsR5O9LkJ8vbUP9GdMjhh6xobLkniDUgCxwITQZvj4KcE+AO7YN4dM5Y/j9p1tZlphOUUkZhaVllJRVOhVdokOY2CeOc/vFMaJbFIF+MpEqCO4iHrrgcUrLyjl2spCfE9NZsiuV1fszKSotJyTAlzE9ohnfJ44JvWNpHxnMocw89hzPYffxHFJOFDBlQALn9osTr144bZCQi9CiKCguY/X+DH7ek87PiWkcySoAIMDXh2LbghxKQXigH6cKSxnQPoJ7zu3F5P7xIuxCq0cEXWixaK1Jysjj5z3pHD9ZQK/4cPomhNMrLhw/X8WXv6bw0tJ9HMzMp1+7CG4c25UJfWKJCw/ytOmC0CSIoAutmtKychZsOcqLS/aRlJEHwID2EUzoE8vgjpGknChgX1oue9NyOZyZz4WDEnh0aj+3JnLry6bD2aRkF3Dx4PZNdg7h9EQmRYVWjZ+vD5ed1ZFLz+zAzmOn+HlPOsv2pPPKsiTKyo3D0ibYn55xYfRvH8Fbqw6yLy2XF685izbBjdvSYH96Lv/4bjeLd5i+8uFBfkzoU71dsSA0BeKhC62WU4Ul7E3NpVNUMLFhgRXx9fnrj/Dol9voHBXCm7OG0yU6tMHnSjtVyL9/3Mv8DUcI8vPh1nN68PXWoxQUl7H4/nMICxTfSWgcGtQ+VxBaKhFB/gzt0pa48KAqk6VXDe/EuzePJDOvmOkvreKnXankF5c6HeNEfjGr9mWwNzXH5Xm+2pzCuc8u45MNR7h+VBeW/W4i957Xi2cuH8TRkwX8a/GeRn9vguAMcRuE05JR3aP58o6x3Pz2em5+ewNKQeeoEPrEh9M1JpTDmflsP3qS5OyCimMuPbMDD07uTce2pn9NblEpf/lqB59tSmZol7b868rBdIup9PaHdoniN6O78vYvB7l4cDuGdolq7rcpnGZIyEU4rckrKmXF3nR2H88hMdXktx/KzKdj22AGdmjDwPZtGNA+gl+SMnlz5QG0hlljuzK+dyyPfrGNw1n53DWpF/dM6ul0kjWvqJTJ/15OkL8PC+8ZJx0nhQYjWS6CUAe01k7z2Y+eKOC5HxL5bFMyWkP7NkE8f/WZjOhWs+e9LDGd37y5jrsn9eTByX2aymzhNEGyXAShDrgqTmofGcy/rhzMzWd346ddqVw/qittQmrPkhnfO5bLzurAyz/vR2HCPWd1aVvFWy8r1xw9UcDJghIGtI+QAimhXoiHLgjNQHZeMbe9t5ENB7Mo1+DvqxjcMZK2oQEcyMjjcGZ+RRXsmB7RPD59gLQZFpwiIRdB8BJOFZaw4WAWa5OyWHMgi4LiUrpGh9ItNpRu0aHkFpXy35/2UlBSxuxx3bl7Uk9CAuRGWqhEBF0QWhAZuUU8tWg3n21KpkNkMLPGdGV0j2j6tYuwdbesRGvNqYJSIoL9JExzmiCCLggtkPUHs3j8651sSzkJQESQHyO6RdMjNpTk7AIOZORxKDOPvOIyOkQGM6mvaTs8qnu0ZNO0YkTQBaEFc/xkIWsPZLImKZM1SVkkZ+fTqW0IXaJD6BIdSnxEEJsOZ7NybwYFJWWEBPgyqns0Q7u05azObRncqQ0hAX5orcnKK+ZgZj6Hs/KIDA5gcKdItxf8Fpxz7GQBt76zkScuGcjgTpFNfj7JchGEFkxCmyCmD+nA9CEdANdplYUlZfyyP5Mfd6WyJimTJbvTALMISZfoENJPFZFTVL0itnNUCEM6RTKkUyQjukU5De14GzmFJew8eoqR3aM9bQpvrDjAtpSTPP7NTj69fbRHQ18i6ILQwnAlGEH+vkzsG8fEvqYZ2In8Yn49fIKNh7LZm5bDuJ4xdIkOpWtMCJ2jQsjILWbzkRNsOXKC9QezWLDlKGAaio3oGsWIblGc3SuG/u0ankaZW1TK+gNZrN6fwabDJzijYxtmjelarz46aacKueHNdew+nsPdk3rywPm9PSaiJwtK+HDdYeIjAtl4KJsfdqYyeUCCR2wBN0MuSqkpwH8AX2Cu1vpph9cfAGYDpUA6cJPW+lBNY0rIRRC8i6MnClh3IIu1BzJZm5RV0Yo4LjyQ8b1jmdAnjjM6tiE8yI/QQD/8a2k/nFNYwuebUliw5ShbjpygtFwT4OdDv4Rwdhw9RZnWTOoTx41juzG2Z7RbonwgI4/r31hLVl4xY3pE8+OuNG4f34PfT+lT7XitNeWaJr3beGXZfp7+djcL7hrLfR9vRgGL7zunSVszNyiGrpTyBRKB84FkYD0wU2u9026ficBarXW+UmoOMEFrPaOmcUXQBcG7ST1VyLJE04p4xd50ThVWDdcE+PoQEezHGR0jGdnNePQDO7QhKT2Pd9cc5ItNKeQVl1X0ph/TI4ahtoKq1FOFvL/mEO+vPUxmXjExYYF0jgqmQ9sQOkQG0ykqmMEdI6uEf7Ymn+DGt9ajgXk3Dmdg+zb8ecF23ltzmNlnd+PR/+uHUorCkjK+2pzC6ysOUFRaxns3j2yUjpqOFJeWM+4fS+gVF857s0fy3fbj3P7eRp6+bBBXj+hc6/FbjpwgOiygojeQI9l5xfywK5XJ/eOJDKmc52iooI8GHtNaX2B7/giA1vopF/ufCbyotR5b07gi6ILQcigtK+fXIyfYn5ZLfnEZeUWl5BWXkZlbxMbD2SSlG28+yN+HwpJyAvx8mDa4PTeM7sIZHV1PFBaWlLFw6zF+ScokJbuAlBMFHDtZULFweFigH2d1aUv/dhG8+8tB2oYG8M5NI+geGwYYL/yvX+9k3uqD3DC6C/ERQby16iAZuUX0bxfB0ZMFBPn58uGto6o0TmsMPtuYzIOfbOHtm0YwvncsWmsuf3k1KScK+Pm3EwkOcJ1p9P2O49z23kYUMLl/ArPGdmVktyiUUhzOzOeNlUnM35BMQUkZXaNDmPubYRWFZg0V9CuAKVrr2bbn1wMjtdZ3udj/ReC41voJJ6/dCtwK0Llz56GHDtUYlREEoYWQnlPEugNZbDiURUJEEFcO61Tv7Jnyck3KiQI2Hc42Yx7MZk9qDn0Twnn7phHER1RdXlBrzZMLdzF35QEAzukdy23ndGdMj2h2HcvhujfW4uej+OCWUfSMC2vwe7XOeeF/VqA1fHffuIpwz/qDWVz5yi88dEEf7pzY0+mxW46cYMZrv9AnPpzRPWL4aP1hTuSX0K9dBJ3aBvPjrlR8fRSXDOnAOb1j+evXOygqKee/M89kYt+45hN0pdR1wF3AeK11UU3jiocuCIK75BSWEBrgh4+LeLjWmkXbjtMtJpT+7SOqvLbneA7Xzl0DKD64ZSS94xveUsFquPavKwdzxdCOVV6b/fYG1iZlsux3E6td1I5k5XPp/1YR5O/LF3eMJTY8kIJiHpxFvgAABphJREFUEyKat/ogx04Wcs3Izswa07XiwpVyooBb3t7AruOneOTCvtw2vmfTh1yUUucBL2DEPK22D0QEXRCE5mJfWg4zX19LebnmoQv6cMmZHRpUfHXd3LXsTcthxe8mEeBXdQJ0b2oOFzy/nLE9Y7jp7G6M7RFDgJ8PJ/NLuOzlVaTnFPH5HWPq1Ksnv7iU336yhUXbjnPomYsaJOh+mEnRc4EUzKToNVrrHXb7nAl8ivHk97pjoAi6IAjNSVJ6Lnd98Cs7j50iMsSfmSM6c/2oLiREBHE4K5+dx06x69gpkjLyKC4tp6TM9lOqaRvqT6e2IXSKCiHAz4dHPt/Gwxf25fbxPZye69Vl+3lx6T5yCktpE+zP5P7xHMjIY2vySd65eQSj6pE/X16u+e+Svdx/fp+GVYoqpaYCz2PSFt/UWj+plHoc2KC1XqCU+hEYBByzHXJYaz2tpjFF0AVBaG601qw9kMW8VQf5fudxlFIE+fmQV1wGmBTHTm2DCQ7wI8BX4e/rg6+PIjOvmOTsfApLTEfMsEA/Vj08qcZFxotKy1i5N4OFW4/xw85UcopK+c/VQyoKxOqLlP4LgiA4cCQrnw/XHSavqJT+7SPo364NveLDXIZitNak5xaRnF1ARJB/nSZYC0vKSD1V2CjpkyLogiAIrYSaBL3pypkEQRCEZkUEXRAEoZUggi4IgtBKEEEXBEFoJYigC4IgtBJE0AVBEFoJIuiCIAitBBF0QRCEVoLHCouUUjnAHo+cvH7EABmeNqIOiL1Ni9jb9LQ0m5vL3i5a61hnL3hyTdE9rqqdvBGl1Aaxt+kQe5uWlmYvtDybvcFeCbkIgiC0EkTQBUEQWgmeFPTXPHju+iD2Ni1ib9PS0uyFlmezx+312KSoIAiC0LhIyEUQBKGVIIIuCILQSvCIoCulpiil9iil9imlHvaEDTWhlHpTKZWmlNputy1KKfWDUmqv7bGtJ220RynVSSm1VCm1Uym1Qyl1r227V9qslApSSq1TSm2x2ftX2/ZuSqm1tu/Fx0qpgNrGak6UUr5KqV+VUt/YnnutvUqpg0qpbUqpzUqpDbZtXvl9AFBKRSqlPlVK7VZK7VJKjfZWe5VSfWyfq/VzSil1nzfY2+yCrpTyBV4CLgT6AzOVUv2b245amAdMcdj2MPCT1roX8JPtubdQCjyote4PjALutH2m3mpzETBJaz0YGAJMUUqNAp4B/q217glkAzd70EZn3Avssnvu7fZO1FoPscuN9tbvA8B/gO+01n2BwZjP2Svt1VrvsX2uQ4ChQD7wBd5gr9a6WX+A0cBiu+ePAI80tx1u2NkV2G73fA/QzvZ7O0xhlMftdGH7V8D5LcFmIATYBIzEVNn5OfueePoH6Ij5J50EfAMoL7f3IBDjsM0rvw9AG+AAtiQNb7fXwcbJwCpvsdcTIZcOwBG758m2bd5OvNb6mO3340C8J41xhVKqK3AmsBYvttkWvtgMpAE/APuBE1rrUtsu3va9eB74HVBuex6Nd9urge+VUhuVUrfatnnr96EbkA68ZQtpzVVKheK99tpzNfCh7XeP2yuTovVAm0uw1+V7KqXCgM+A+7TWp+xf8zabtdZl2tyydgRGAH09bJJLlFIXAWla642etqUOnK21PgsT2rxTKXWO/Yte9n3wA84CXtZanwnk4RCu8DJ7AbDNmUwDPnF8zVP2ekLQU4BOds872rZ5O6lKqXYAtsc0D9tTBaWUP0bM39daf27b7NU2A2itTwBLMSGLSKWU1V/Im74XY4FpSqmDwEeYsMt/8F570Vqn2B7TMPHdEXjv9yEZSNZar7U9/xQj8N5qr8WFwCatdartucft9YSgrwd62TIEAjC3LAs8YEddWQD8xvb7bzBxaq9AKaWAN4BdWuvn7F7ySpuVUrFKqUjb78GYeP8ujLBfYdvNa+zVWj+ite6ote6K+b4u0Vpfi5faq5QKVUqFW79j4rzb8dLvg9b6OHBEKdXHtulcYCdeaq8dM6kMt4A32OuhiYSpQCImbvqopyc2nNj3IXAMKMF4DzdjYqY/AXuBH4EoT9tpZ+/ZmNu7rcBm289Ub7UZOAP41WbvduDPtu3dgXXAPsxtbKCnbXVi+wTgG2+212bXFtvPDut/zFu/DzbbhgAbbN+JL4G2Xm5vKJAJtLHb5nF7pfRfEAShlSCTooIgCK0EEXRBEIRWggi6IAhCK0EEXRAEoZUggi4IgtBKEEEXBEFoJYigC4IgtBL+HxGK9MJC2HKHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(performance.history)[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8486714975845411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005820642118889293"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>metric</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BACE</td>\n",
       "      <td>0.952215</td>\n",
       "      <td>0.744492</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>ROC</td>\n",
       "      <td>803681</td>\n",
       "      <td>26</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BACE</td>\n",
       "      <td>0.959814</td>\n",
       "      <td>0.726546</td>\n",
       "      <td>0.855254</td>\n",
       "      <td>ROC</td>\n",
       "      <td>803681</td>\n",
       "      <td>26</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BACE</td>\n",
       "      <td>0.958401</td>\n",
       "      <td>0.747157</td>\n",
       "      <td>0.846558</td>\n",
       "      <td>ROC</td>\n",
       "      <td>803681</td>\n",
       "      <td>26</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  train_auc  valid_auc  test_auc metric  # trainable params  \\\n",
       "0      BACE   0.952215   0.744492  0.844203    ROC              803681   \n",
       "1      BACE   0.959814   0.726546  0.855254    ROC              803681   \n",
       "2      BACE   0.958401   0.747157  0.846558    ROC              803681   \n",
       "\n",
       "   best_epoch  batch_size      lr  weight_decay  \n",
       "0          26         128  0.0001             0  \n",
       "1          26         128  0.0001             0  \n",
       "2          26         128  0.0001             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./results/%s.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
