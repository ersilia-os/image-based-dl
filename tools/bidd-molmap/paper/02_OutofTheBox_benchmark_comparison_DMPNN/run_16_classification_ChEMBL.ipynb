{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.compat.v1.set_random_seed(123)\n",
    "\n",
    "#tmp_feature_dir = './tmpignore'\n",
    "tmp_feature_dir = '/raid/shenwanxiang/tempignore'\n",
    "\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: ChEMBL number of split times: 3\n"
     ]
    }
   ],
   "source": [
    "task_name = 'ChEMBL'\n",
    "from chembench import load_data\n",
    "df, induces = load_data(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365047 45631 45631\n"
     ]
    }
   ],
   "source": [
    "print(len(induces[0][0]), len(induces[0][1]), len(induces[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22 compounds has no smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226200,\n",
       " 379799,\n",
       " 380656,\n",
       " 381454,\n",
       " 393024,\n",
       " 393968,\n",
       " 396794,\n",
       " 397302,\n",
       " 400352,\n",
       " 402496,\n",
       " 404107,\n",
       " 406599,\n",
       " 407755,\n",
       " 408279,\n",
       " 418481,\n",
       " 419581,\n",
       " 419589,\n",
       " 419590,\n",
       " 441931,\n",
       " 442248,\n",
       " 447060,\n",
       " 453014]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idx = df[df.smiles.isna()].index.to_list()\n",
    "nan_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = -1\n",
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').fillna(MASK).values\n",
    "if Y.shape[1] == 0:\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    Y = Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456331, 1310)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "xs = np.array_split(df.smiles.to_list(), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_name_all = os.path.join(tmp_feature_dir, 'X1_%s.data' % (task_name))\n",
    "X2_name_all = os.path.join(tmp_feature_dir, 'X2_%s.data' % (task_name))\n",
    "\n",
    "if os.path.exists(X1_name_all) & os.path.exists(X2_name_all):\n",
    "    X1 = load(X1_name_all)\n",
    "    X2 = load(X2_name_all)\n",
    "else:\n",
    "    ## descriptors\n",
    "    X1s = []\n",
    "    for i, batch_smiles in tqdm(enumerate(xs), ascii=True):\n",
    "        ii = str(i).zfill(2)\n",
    "        X1_name = os.path.join(tmp_feature_dir, 'X1_%s_%s.data' % (task_name, ii))\n",
    "        print('save to %s' % X1_name)\n",
    "        if not os.path.exists(X1_name):\n",
    "            X1 = mp1.batch_transform(batch_smiles, n_jobs = 8)\n",
    "            X1 = X1.astype('float32')\n",
    "            dump(X1, X1_name)\n",
    "            \n",
    "        else:\n",
    "            X1 = load(X1_name)\n",
    "        X1s.append(X1)\n",
    "        del X1\n",
    "        \n",
    "    X1 = np.concatenate(X1s)\n",
    "    del X1s\n",
    "    \n",
    "    dump(X1, X1_name_all)\n",
    "    \n",
    "    ## fingerprint\n",
    "    X2s = []      \n",
    "    for i, batch_smiles in tqdm(enumerate(xs), ascii=True):\n",
    "        ii = str(i).zfill(2)\n",
    "        X2_name = os.path.join(tmp_feature_dir, 'X2_%s_%s.data' % (task_name, ii))\n",
    "        if not os.path.exists(X2_name):\n",
    "            X2 = mp2.batch_transform(batch_smiles, n_jobs = 8)\n",
    "            X2 = X2.astype('float32')\n",
    "            dump(X2, X2_name)\n",
    "            \n",
    "        else:\n",
    "            X2 = load(X2_name)\n",
    "            \n",
    "        X2s.append(X2)\n",
    "        del X2\n",
    "        \n",
    "    X2 = np.concatenate(X2s)\n",
    "    del X2s\n",
    "    dump(X2, X2_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456331, 37, 37, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_weights(trainY):\n",
    "    \"\"\"pos_weights: neg_n / pos_n \"\"\"\n",
    "    dfY = pd.DataFrame(trainY)\n",
    "    pos = dfY == 1\n",
    "    pos_n = pos.sum(axis=0)\n",
    "    neg = dfY == 0\n",
    "    neg_n = neg.sum(axis=0)\n",
    "    pos_weights = (neg_n / pos_n).values\n",
    "    neg_weights = (pos_n / neg_n).values\n",
    "    return pos_weights, neg_weights\n",
    "\n",
    "prcs_metrics = ['MUV', 'PCBA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 800\n",
    "patience = 10 #early stopping, dual to large computation cost, the larger dataset  set small waitig patience for early stopping\n",
    "dense_layers = [2048]  #1310 outputs\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "monitor = 'val_auc'\n",
    "dense_avf = 'relu'\n",
    "last_avf = None #sigmoid in loss\n",
    "\n",
    "if task_name in prcs_metrics:\n",
    "    metric = 'PRC'\n",
    "else:\n",
    "    metric = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365047 45631 45631\n",
      "epoch: 0001, loss: 0.6953 - val_loss: 0.6948; auc: 0.6349 - val_auc: 0.6179                                                                                                    \n",
      "epoch: 0002, loss: 0.6944 - val_loss: 0.6944; auc: 0.6898 - val_auc: 0.6903                                                                                                    \n",
      "epoch: 0003, loss: 0.6939 - val_loss: 0.6942; auc: 0.7209 - val_auc: 0.7077                                                                                                    \n",
      "epoch: 0004, loss: 0.6934 - val_loss: 0.6939; auc: 0.7386 - val_auc: 0.7166                                                                                                    \n",
      "epoch: 0005, loss: 0.6931 - val_loss: 0.6939; auc: 0.7649 - val_auc: 0.7240                                                                                                    \n",
      "epoch: 0006, loss: 0.6929 - val_loss: 0.6936; auc: 0.7747 - val_auc: 0.7250                                                                                                    \n",
      "epoch: 0007, loss: 0.6926 - val_loss: 0.6939; auc: 0.7897 - val_auc: 0.7325                                                                                                    \n",
      "epoch: 0008, loss: 0.6924 - val_loss: 0.6935; auc: 0.8012 - val_auc: 0.7403                                                                                                    \n",
      "epoch: 0009, loss: 0.6922 - val_loss: 0.6942; auc: 0.8101 - val_auc: 0.7153                                                                                                    \n",
      "epoch: 0010, loss: 0.6921 - val_loss: 0.6942; auc: 0.8232 - val_auc: 0.7398                                                                                                    \n",
      "epoch: 0011, loss: 0.6920 - val_loss: 0.6937; auc: 0.8321 - val_auc: 0.7470                                                                                                    \n",
      "epoch: 0012, loss: 0.6919 - val_loss: 0.6937; auc: 0.8386 - val_auc: 0.7479                                                                                                    \n",
      "epoch: 0013, loss: 0.6918 - val_loss: 0.6939; auc: 0.8484 - val_auc: 0.7518                                                                                                    \n",
      "epoch: 0014, loss: 0.6917 - val_loss: 0.6941; auc: 0.8549 - val_auc: 0.7508                                                                                                    \n",
      "epoch: 0015, loss: 0.6916 - val_loss: 0.6942; auc: 0.8636 - val_auc: 0.7626                                                                                                    \n",
      "epoch: 0016, loss: 0.6915 - val_loss: 0.6941; auc: 0.8704 - val_auc: 0.7579                                                                                                    \n",
      "epoch: 0017, loss: 0.6914 - val_loss: 0.6941; auc: 0.8768 - val_auc: 0.7549                                                                                                    \n",
      "epoch: 0018, loss: 0.6913 - val_loss: 0.6940; auc: 0.8811 - val_auc: 0.7560                                                                                                    \n",
      "epoch: 0019, loss: 0.6913 - val_loss: 0.6942; auc: 0.8879 - val_auc: 0.7601                                                                                                    \n",
      "epoch: 0020, loss: 0.6912 - val_loss: 0.6944; auc: 0.8946 - val_auc: 0.7520                                                                                                    \n",
      "epoch: 0021, loss: 0.6911 - val_loss: 0.6940; auc: 0.8992 - val_auc: 0.7577                                                                                                    \n",
      "epoch: 0022, loss: 0.6911 - val_loss: 0.6945; auc: 0.9052 - val_auc: 0.7557                                                                                                    \n",
      "epoch: 0023, loss: 0.6910 - val_loss: 0.6944; auc: 0.9078 - val_auc: 0.7648                                                                                                    \n",
      "epoch: 0024, loss: 0.6909 - val_loss: 0.6953; auc: 0.9133 - val_auc: 0.7607                                                                                                    \n",
      "epoch: 0025, loss: 0.6909 - val_loss: 0.6958; auc: 0.9179 - val_auc: 0.7607                                                                                                    \n",
      "epoch: 0026, loss: 0.6908 - val_loss: 0.6952; auc: 0.9223 - val_auc: 0.7598                                                                                                    \n",
      "epoch: 0027, loss: 0.6907 - val_loss: 0.6954; auc: 0.9263 - val_auc: 0.7458                                                                                                    \n",
      "epoch: 0028, loss: 0.6907 - val_loss: 0.6955; auc: 0.9300 - val_auc: 0.7622                                                                                                    \n",
      "epoch: 0029, loss: 0.6907 - val_loss: 0.6954; auc: 0.9332 - val_auc: 0.7603                                                                                                    \n",
      "epoch: 0030, loss: 0.6906 - val_loss: 0.6959; auc: 0.9378 - val_auc: 0.7521                                                                                                    \n",
      "epoch: 0031, loss: 0.6905 - val_loss: 0.6957; auc: 0.9414 - val_auc: 0.7584                                                                                                    \n",
      "epoch: 0032, loss: 0.6905 - val_loss: 0.6965; auc: 0.9440 - val_auc: 0.7573                                                                                                    \n",
      "epoch: 0033, loss: 0.6904 - val_loss: 0.6958; auc: 0.9471 - val_auc: 0.7605                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00033: early stopping\n",
      "365047 45631 45631\n",
      "epoch: 0001, loss: 0.6953 - val_loss: 0.6944; auc: 0.6486 - val_auc: 0.6630                                                                                                    \n",
      "epoch: 0002, loss: 0.6943 - val_loss: 0.6941; auc: 0.7041 - val_auc: 0.6891                                                                                                    \n",
      "epoch: 0003, loss: 0.6938 - val_loss: 0.6935; auc: 0.7284 - val_auc: 0.7165                                                                                                    \n",
      "epoch: 0004, loss: 0.6934 - val_loss: 0.6934; auc: 0.7460 - val_auc: 0.7267                                                                                                    \n",
      "epoch: 0005, loss: 0.6931 - val_loss: 0.6936; auc: 0.7582 - val_auc: 0.7365                                                                                                    \n",
      "epoch: 0006, loss: 0.6928 - val_loss: 0.6934; auc: 0.7763 - val_auc: 0.7319                                                                                                    \n",
      "epoch: 0007, loss: 0.6926 - val_loss: 0.6933; auc: 0.7913 - val_auc: 0.7408                                                                                                    \n",
      "epoch: 0008, loss: 0.6924 - val_loss: 0.6935; auc: 0.8038 - val_auc: 0.7430                                                                                                    \n",
      "epoch: 0009, loss: 0.6922 - val_loss: 0.6935; auc: 0.8152 - val_auc: 0.7326                                                                                                    \n",
      "epoch: 0010, loss: 0.6921 - val_loss: 0.6933; auc: 0.8240 - val_auc: 0.7375                                                                                                    \n",
      "epoch: 0011, loss: 0.6920 - val_loss: 0.6935; auc: 0.8303 - val_auc: 0.7411                                                                                                    \n",
      "epoch: 0012, loss: 0.6919 - val_loss: 0.6936; auc: 0.8412 - val_auc: 0.7323                                                                                                    \n",
      "epoch: 0013, loss: 0.6918 - val_loss: 0.6933; auc: 0.8457 - val_auc: 0.7490                                                                                                    \n",
      "epoch: 0014, loss: 0.6917 - val_loss: 0.6935; auc: 0.8568 - val_auc: 0.7420                                                                                                    \n",
      "epoch: 0015, loss: 0.6916 - val_loss: 0.6935; auc: 0.8632 - val_auc: 0.7405                                                                                                    \n",
      "epoch: 0016, loss: 0.6915 - val_loss: 0.6934; auc: 0.8697 - val_auc: 0.7434                                                                                                    \n",
      "epoch: 0017, loss: 0.6914 - val_loss: 0.6936; auc: 0.8733 - val_auc: 0.7501                                                                                                    \n",
      "epoch: 0018, loss: 0.6914 - val_loss: 0.6940; auc: 0.8804 - val_auc: 0.7402                                                                                                    \n",
      "epoch: 0019, loss: 0.6913 - val_loss: 0.6943; auc: 0.8857 - val_auc: 0.7453                                                                                                    \n",
      "epoch: 0020, loss: 0.6912 - val_loss: 0.6941; auc: 0.8912 - val_auc: 0.7669                                                                                                    \n",
      "epoch: 0021, loss: 0.6911 - val_loss: 0.6942; auc: 0.8960 - val_auc: 0.7445                                                                                                    \n",
      "epoch: 0022, loss: 0.6911 - val_loss: 0.6943; auc: 0.9005 - val_auc: 0.7594                                                                                                    \n",
      "epoch: 0023, loss: 0.6910 - val_loss: 0.6942; auc: 0.9070 - val_auc: 0.7574                                                                                                    \n",
      "epoch: 0024, loss: 0.6910 - val_loss: 0.6943; auc: 0.9108 - val_auc: 0.7507                                                                                                    \n",
      "epoch: 0025, loss: 0.6909 - val_loss: 0.6944; auc: 0.9154 - val_auc: 0.7582                                                                                                    \n",
      "epoch: 0026, loss: 0.6909 - val_loss: 0.6946; auc: 0.9189 - val_auc: 0.7479                                                                                                    \n",
      "epoch: 0027, loss: 0.6908 - val_loss: 0.6950; auc: 0.9240 - val_auc: 0.7503                                                                                                    \n",
      "epoch: 0028, loss: 0.6908 - val_loss: 0.6953; auc: 0.9243 - val_auc: 0.7444                                                                                                    \n",
      "epoch: 0029, loss: 0.6907 - val_loss: 0.6952; auc: 0.9305 - val_auc: 0.7495                                                                                                    \n",
      "epoch: 0030, loss: 0.6906 - val_loss: 0.6966; auc: 0.9331 - val_auc: 0.7570                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00030: early stopping\n",
      "365048 45630 45631\n",
      "epoch: 0001, loss: 0.6954 - val_loss: 0.6948; auc: 0.6512 - val_auc: 0.6060                                                                                                    \n",
      "epoch: 0002, loss: 0.6944 - val_loss: 0.6941; auc: 0.7088 - val_auc: 0.6594                                                                                                    \n",
      "epoch: 0003, loss: 0.6939 - val_loss: 0.6938; auc: 0.7361 - val_auc: 0.6605                                                                                                    \n",
      "epoch: 0004, loss: 0.6934 - val_loss: 0.6938; auc: 0.7587 - val_auc: 0.6768                                                                                                    \n",
      "epoch: 0005, loss: 0.6931 - val_loss: 0.6939; auc: 0.7664 - val_auc: 0.6818                                                                                                    \n",
      "epoch: 0006, loss: 0.6928 - val_loss: 0.6936; auc: 0.7863 - val_auc: 0.6868                                                                                                    \n",
      "epoch: 0007, loss: 0.6926 - val_loss: 0.6936; auc: 0.7982 - val_auc: 0.6901                                                                                                    \n",
      "epoch: 0008, loss: 0.6924 - val_loss: 0.6934; auc: 0.8003 - val_auc: 0.6955                                                                                                    \n",
      "epoch: 0009, loss: 0.6923 - val_loss: 0.6934; auc: 0.8172 - val_auc: 0.6832                                                                                                    \n",
      "epoch: 0010, loss: 0.6921 - val_loss: 0.6933; auc: 0.8271 - val_auc: 0.6993                                                                                                    \n",
      "epoch: 0011, loss: 0.6920 - val_loss: 0.6935; auc: 0.8366 - val_auc: 0.7069                                                                                                    \n",
      "epoch: 0012, loss: 0.6919 - val_loss: 0.6936; auc: 0.8454 - val_auc: 0.7114                                                                                                    \n",
      "epoch: 0013, loss: 0.6918 - val_loss: 0.6939; auc: 0.8526 - val_auc: 0.7156                                                                                                    \n",
      "epoch: 0014, loss: 0.6917 - val_loss: 0.6934; auc: 0.8572 - val_auc: 0.7153                                                                                                    \n",
      "epoch: 0015, loss: 0.6916 - val_loss: 0.6938; auc: 0.8623 - val_auc: 0.7169                                                                                                    \n",
      "epoch: 0016, loss: 0.6915 - val_loss: 0.6941; auc: 0.8712 - val_auc: 0.7170                                                                                                    \n",
      "epoch: 0017, loss: 0.6915 - val_loss: 0.6941; auc: 0.8768 - val_auc: 0.7267                                                                                                    \n",
      "epoch: 0018, loss: 0.6914 - val_loss: 0.6938; auc: 0.8801 - val_auc: 0.7260                                                                                                    \n",
      "epoch: 0019, loss: 0.6913 - val_loss: 0.6939; auc: 0.8873 - val_auc: 0.7292                                                                                                    \n",
      "epoch: 0020, loss: 0.6913 - val_loss: 0.6944; auc: 0.8930 - val_auc: 0.7210                                                                                                    \n",
      "epoch: 0021, loss: 0.6912 - val_loss: 0.6938; auc: 0.8972 - val_auc: 0.7262                                                                                                    \n",
      "epoch: 0022, loss: 0.6911 - val_loss: 0.6946; auc: 0.9028 - val_auc: 0.7280                                                                                                    \n",
      "epoch: 0023, loss: 0.6911 - val_loss: 0.6943; auc: 0.9058 - val_auc: 0.7288                                                                                                    \n",
      "epoch: 0024, loss: 0.6910 - val_loss: 0.6939; auc: 0.9109 - val_auc: 0.7352                                                                                                    \n",
      "epoch: 0025, loss: 0.6910 - val_loss: 0.6945; auc: 0.9137 - val_auc: 0.7233                                                                                                    \n",
      "epoch: 0026, loss: 0.6909 - val_loss: 0.6949; auc: 0.9184 - val_auc: 0.7310                                                                                                    \n",
      "epoch: 0027, loss: 0.6908 - val_loss: 0.6955; auc: 0.9219 - val_auc: 0.7360                                                                                                    \n",
      "epoch: 0028, loss: 0.6908 - val_loss: 0.6948; auc: 0.9265 - val_auc: 0.7315                                                                                                    \n",
      "epoch: 0029, loss: 0.6908 - val_loss: 0.6949; auc: 0.9294 - val_auc: 0.7423                                                                                                    \n",
      "epoch: 0030, loss: 0.6907 - val_loss: 0.6955; auc: 0.9322 - val_auc: 0.7341                                                                                                    \n",
      "epoch: 0031, loss: 0.6906 - val_loss: 0.6955; auc: 0.9364 - val_auc: 0.7364                                                                                                    \n",
      "epoch: 0032, loss: 0.6906 - val_loss: 0.6953; auc: 0.9405 - val_auc: 0.7217                                                                                                    \n",
      "epoch: 0033, loss: 0.6905 - val_loss: 0.6955; auc: 0.9428 - val_auc: 0.7277                                                                                                    \n",
      "epoch: 0034, loss: 0.6905 - val_loss: 0.6959; auc: 0.9461 - val_auc: 0.7312                                                                                                    \n",
      "epoch: 0035, loss: 0.6905 - val_loss: 0.6954; auc: 0.9474 - val_auc: 0.7316                                                                                                    \n",
      "epoch: 0036, loss: 0.6904 - val_loss: 0.6958; auc: 0.9508 - val_auc: 0.7284                                                                                                    \n",
      "epoch: 0037, loss: 0.6904 - val_loss: 0.6963; auc: 0.9532 - val_auc: 0.7335                                                                                                    \n",
      "epoch: 0038, loss: 0.6903 - val_loss: 0.6967; auc: 0.9562 - val_auc: 0.7346                                                                                                    \n",
      "epoch: 0039, loss: 0.6903 - val_loss: 0.6971; auc: 0.9585 - val_auc: 0.7344                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00039: early stopping\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    \n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "    \n",
    "    train_idx = list(set(train_idx) - set(nan_idx))\n",
    "    valid_idx = list(set(valid_idx) - set(nan_idx))\n",
    "    test_idx = list(set(test_idx) - set(nan_idx))\n",
    "\n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    testX = (X1[test_idx], X2[test_idx])\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "    pos_weights, neg_weights = get_pos_weights(trainY)\n",
    "    loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "\n",
    "    performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                   (validX, validY), \n",
    "                                                                   patience = patience, \n",
    "                                                                   criteria = monitor,\n",
    "                                                                   metric = metric,\n",
    "                                                                  )\n",
    "    model.fit(trainX, trainY, batch_size=batch_size, \n",
    "          epochs=epochs, verbose= 0, shuffle = True, \n",
    "          validation_data = (validX, validY), \n",
    "          callbacks=[performance]) \n",
    "\n",
    "\n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "    \n",
    "    train_aucs = performance.evaluate(trainX, trainY)            \n",
    "    valid_aucs = performance.evaluate(validX, validY)            \n",
    "    test_aucs = performance.evaluate(testX, testY)\n",
    "\n",
    "    final_res = {\n",
    "                     'task_name':task_name,            \n",
    "                     'train_auc':np.nanmean(train_aucs), \n",
    "                     'valid_auc':np.nanmean(valid_aucs),                      \n",
    "                     'test_auc':np.nanmean(test_aucs), \n",
    "                     'metric':metric,\n",
    "                     '# trainable params': trainable_params,\n",
    "                     'best_epoch': best_epoch,\n",
    "                     'batch_size':batch_size,\n",
    "                     'lr': lr,\n",
    "                     'weight_decay':weight_decay\n",
    "                    }\n",
    "    \n",
    "    results.append(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1eb85a3588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(performance.history)[['auc', 'val_auc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>metric</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>0.907848</td>\n",
       "      <td>0.764787</td>\n",
       "      <td>0.760440</td>\n",
       "      <td>ROC</td>\n",
       "      <td>4140734</td>\n",
       "      <td>22</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>0.891207</td>\n",
       "      <td>0.766938</td>\n",
       "      <td>0.745258</td>\n",
       "      <td>ROC</td>\n",
       "      <td>4140734</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>0.929407</td>\n",
       "      <td>0.742331</td>\n",
       "      <td>0.745781</td>\n",
       "      <td>ROC</td>\n",
       "      <td>4140734</td>\n",
       "      <td>28</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  train_auc  valid_auc  test_auc metric  # trainable params  \\\n",
       "0    ChEMBL   0.907848   0.764787  0.760440    ROC             4140734   \n",
       "1    ChEMBL   0.891207   0.766938  0.745258    ROC             4140734   \n",
       "2    ChEMBL   0.929407   0.742331  0.745781    ROC             4140734   \n",
       "\n",
       "   best_epoch  batch_size      lr  weight_decay  \n",
       "0          22         128  0.0001             0  \n",
       "1          19         128  0.0001             0  \n",
       "2          28         128  0.0001             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008618132842095953"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504929158022563"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./results/%s.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
