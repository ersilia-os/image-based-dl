{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:37:09] Enabling RDKit 2019.09.2 jupyter extensions\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from molmap import model as molmodel\n",
    "import molmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump\n",
    "tqdm.pandas(ascii=True)\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "np.random.seed(123)\n",
    "tf.compat.v1.set_random_seed(123)\n",
    "\n",
    "\n",
    "tmp_feature_dir = './tmpignore'\n",
    "if not os.path.exists(tmp_feature_dir):\n",
    "    os.makedirs(tmp_feature_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp1 = molmap.loadmap('../descriptor.mp')\n",
    "mp2 = molmap.loadmap('../fingerprint.mp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset: MUV number of split times: 3\n"
     ]
    }
   ],
   "source": [
    "task_name = 'MUV'\n",
    "from chembench import load_data\n",
    "df, induces = load_data(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = -1\n",
    "smiles_col = df.columns[0]\n",
    "values_col = df.columns[1:]\n",
    "Y = df[values_col].astype('float').fillna(MASK).values\n",
    "if Y.shape[1] == 0:\n",
    "    Y = Y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "X1_name = os.path.join(tmp_feature_dir, 'X1_%s.data' % task_name)\n",
    "X2_name = os.path.join(tmp_feature_dir, 'X2_%s.data' % task_name)\n",
    "if not os.path.exists(X1_name):\n",
    "    X1 = mp1.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X1, X1_name)\n",
    "else:\n",
    "    X1 = load(X1_name)\n",
    "\n",
    "if not os.path.exists(X2_name): \n",
    "    X2 = mp2.batch_transform(df.smiles, n_jobs = 8)\n",
    "    dump(X2, X2_name)\n",
    "else:\n",
    "    X2 = load(X2_name)\n",
    "\n",
    "molmap1_size = X1.shape[1:]\n",
    "molmap2_size = X2.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_weights(trainY):\n",
    "    \"\"\"pos_weights: neg_n / pos_n \"\"\"\n",
    "    dfY = pd.DataFrame(trainY)\n",
    "    pos = dfY == 1\n",
    "    pos_n = pos.sum(axis=0)\n",
    "    neg = dfY == 0\n",
    "    neg_n = neg.sum(axis=0)\n",
    "    pos_weights = (neg_n / pos_n).values\n",
    "    neg_weights = (pos_n / neg_n).values\n",
    "    return pos_weights, neg_weights\n",
    "\n",
    "prcs_metrics = ['MUV', 'PCBA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 800\n",
    "patience = 10 #early stopping, dual to large computation cost, the larger dataset  set small waitig patience for early stopping\n",
    "\n",
    "dense_layers = [128] #17\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "monitor = 'val_auc'\n",
    "dense_avf = 'relu'\n",
    "last_avf = None #sigmoid in loss\n",
    "\n",
    "if task_name in prcs_metrics:\n",
    "    metric = 'PRC'\n",
    "else:\n",
    "    metric = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74469 9309 9309\n",
      "WARNING:tensorflow:From /home/shenwanxiang/anaconda3/envs/deepchem23/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "epoch: 0001, loss: 0.8050 - val_loss: 0.8089; auc: 0.0216 - val_auc: 0.0050                                                                                                    \n",
      "epoch: 0002, loss: 0.8025 - val_loss: 0.8079; auc: 0.0596 - val_auc: 0.0070                                                                                                    \n",
      "epoch: 0003, loss: 0.8008 - val_loss: 0.8046; auc: 0.0413 - val_auc: 0.0062                                                                                                    \n",
      "epoch: 0004, loss: 0.7956 - val_loss: 0.7958; auc: 0.0343 - val_auc: 0.0078                                                                                                    \n",
      "epoch: 0005, loss: 0.7882 - val_loss: 0.7989; auc: 0.0210 - val_auc: 0.0124                                                                                                    \n",
      "epoch: 0006, loss: 0.7813 - val_loss: 0.7844; auc: 0.0304 - val_auc: 0.0092                                                                                                    \n",
      "epoch: 0007, loss: 0.7733 - val_loss: 0.7806; auc: 0.0350 - val_auc: 0.0118                                                                                                    \n",
      "epoch: 0008, loss: 0.7647 - val_loss: 0.7736; auc: 0.0546 - val_auc: 0.0094                                                                                                    \n",
      "epoch: 0009, loss: 0.7551 - val_loss: 0.7754; auc: 0.0470 - val_auc: 0.0158                                                                                                    \n",
      "epoch: 0010, loss: 0.7471 - val_loss: 0.7713; auc: 0.0533 - val_auc: 0.0109                                                                                                    \n",
      "epoch: 0011, loss: 0.7405 - val_loss: 0.7725; auc: 0.0581 - val_auc: 0.0127                                                                                                    \n",
      "epoch: 0012, loss: 0.7293 - val_loss: 0.7781; auc: 0.0488 - val_auc: 0.0172                                                                                                    \n",
      "epoch: 0013, loss: 0.7211 - val_loss: 0.7657; auc: 0.0718 - val_auc: 0.0162                                                                                                    \n",
      "epoch: 0014, loss: 0.7125 - val_loss: 0.7868; auc: 0.0591 - val_auc: 0.0358                                                                                                    \n",
      "epoch: 0015, loss: 0.7060 - val_loss: 0.7773; auc: 0.0753 - val_auc: 0.0377                                                                                                    \n",
      "epoch: 0016, loss: 0.6978 - val_loss: 0.7927; auc: 0.0808 - val_auc: 0.0393                                                                                                    \n",
      "epoch: 0017, loss: 0.6909 - val_loss: 0.7963; auc: 0.0944 - val_auc: 0.0372                                                                                                    \n",
      "epoch: 0018, loss: 0.6814 - val_loss: 0.8214; auc: 0.0986 - val_auc: 0.0394                                                                                                    \n",
      "epoch: 0019, loss: 0.6793 - val_loss: 0.7644; auc: 0.1630 - val_auc: 0.0224                                                                                                    \n",
      "epoch: 0020, loss: 0.6704 - val_loss: 0.8092; auc: 0.1395 - val_auc: 0.0424                                                                                                    \n",
      "epoch: 0021, loss: 0.6632 - val_loss: 0.8010; auc: 0.1635 - val_auc: 0.0318                                                                                                    \n",
      "epoch: 0022, loss: 0.6561 - val_loss: 0.8448; auc: 0.1584 - val_auc: 0.0756                                                                                                    \n",
      "epoch: 0023, loss: 0.6508 - val_loss: 0.8161; auc: 0.2297 - val_auc: 0.0510                                                                                                    \n",
      "epoch: 0024, loss: 0.6453 - val_loss: 0.8439; auc: 0.2389 - val_auc: 0.0338                                                                                                    \n",
      "epoch: 0025, loss: 0.6410 - val_loss: 0.8405; auc: 0.2888 - val_auc: 0.0422                                                                                                    \n",
      "epoch: 0026, loss: 0.6327 - val_loss: 0.8433; auc: 0.3349 - val_auc: 0.0419                                                                                                    \n",
      "epoch: 0027, loss: 0.6297 - val_loss: 0.8824; auc: 0.3614 - val_auc: 0.0464                                                                                                    \n",
      "epoch: 0028, loss: 0.6293 - val_loss: 0.8245; auc: 0.3736 - val_auc: 0.0371                                                                                                    \n",
      "epoch: 0029, loss: 0.6225 - val_loss: 0.9618; auc: 0.4127 - val_auc: 0.0589                                                                                                    \n",
      "epoch: 0030, loss: 0.6190 - val_loss: 0.9545; auc: 0.4654 - val_auc: 0.0440                                                                                                    \n",
      "epoch: 0031, loss: 0.6160 - val_loss: 1.0102; auc: 0.4906 - val_auc: 0.0500                                                                                                    \n",
      "epoch: 0032, loss: 0.6109 - val_loss: 0.9936; auc: 0.5269 - val_auc: 0.0504                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00032: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74469 9309 9309\n",
      "epoch: 0001, loss: 0.8045 - val_loss: 0.7756; auc: 0.0269 - val_auc: 0.0036                                                                                                    \n",
      "epoch: 0002, loss: 0.8031 - val_loss: 0.7731; auc: 0.0672 - val_auc: 0.0247                                                                                                    \n",
      "epoch: 0003, loss: 0.7995 - val_loss: 0.7692; auc: 0.0659 - val_auc: 0.0773                                                                                                    \n",
      "epoch: 0004, loss: 0.7896 - val_loss: 0.7635; auc: 0.0288 - val_auc: 0.0750                                                                                                    \n",
      "epoch: 0005, loss: 0.7799 - val_loss: 0.7647; auc: 0.0328 - val_auc: 0.0763                                                                                                    \n",
      "epoch: 0006, loss: 0.7681 - val_loss: 0.7548; auc: 0.0445 - val_auc: 0.0273                                                                                                    \n",
      "epoch: 0007, loss: 0.7575 - val_loss: 0.7545; auc: 0.0600 - val_auc: 0.0789                                                                                                    \n",
      "epoch: 0008, loss: 0.7483 - val_loss: 0.7558; auc: 0.0557 - val_auc: 0.0285                                                                                                    \n",
      "epoch: 0009, loss: 0.7403 - val_loss: 0.7493; auc: 0.0653 - val_auc: 0.0798                                                                                                    \n",
      "epoch: 0010, loss: 0.7316 - val_loss: 0.7582; auc: 0.0625 - val_auc: 0.0298                                                                                                    \n",
      "epoch: 0011, loss: 0.7236 - val_loss: 0.7637; auc: 0.0615 - val_auc: 0.0164                                                                                                    \n",
      "epoch: 0012, loss: 0.7150 - val_loss: 0.7669; auc: 0.0675 - val_auc: 0.0194                                                                                                    \n",
      "epoch: 0013, loss: 0.7089 - val_loss: 0.7518; auc: 0.0927 - val_auc: 0.0319                                                                                                    \n",
      "epoch: 0014, loss: 0.6996 - val_loss: 0.7553; auc: 0.0933 - val_auc: 0.0269                                                                                                    \n",
      "epoch: 0015, loss: 0.6931 - val_loss: 0.7640; auc: 0.0971 - val_auc: 0.0250                                                                                                    \n",
      "epoch: 0016, loss: 0.6871 - val_loss: 0.7519; auc: 0.1180 - val_auc: 0.0825                                                                                                    \n",
      "epoch: 0017, loss: 0.6786 - val_loss: 0.7555; auc: 0.1419 - val_auc: 0.0847                                                                                                    \n",
      "epoch: 0018, loss: 0.6726 - val_loss: 0.7941; auc: 0.1236 - val_auc: 0.0972                                                                                                    \n",
      "epoch: 0019, loss: 0.6654 - val_loss: 0.8164; auc: 0.1548 - val_auc: 0.0280                                                                                                    \n",
      "epoch: 0020, loss: 0.6621 - val_loss: 0.7994; auc: 0.2061 - val_auc: 0.0871                                                                                                    \n",
      "epoch: 0021, loss: 0.6534 - val_loss: 0.8135; auc: 0.2228 - val_auc: 0.0895                                                                                                    \n",
      "epoch: 0022, loss: 0.6484 - val_loss: 0.7969; auc: 0.2284 - val_auc: 0.1051                                                                                                    \n",
      "epoch: 0023, loss: 0.6429 - val_loss: 0.8130; auc: 0.2548 - val_auc: 0.1006                                                                                                    \n",
      "epoch: 0024, loss: 0.6372 - val_loss: 0.8005; auc: 0.2899 - val_auc: 0.1006                                                                                                    \n",
      "epoch: 0025, loss: 0.6327 - val_loss: 0.7821; auc: 0.3295 - val_auc: 0.0965                                                                                                    \n",
      "epoch: 0026, loss: 0.6275 - val_loss: 0.8552; auc: 0.3222 - val_auc: 0.1195                                                                                                    \n",
      "epoch: 0027, loss: 0.6231 - val_loss: 0.8581; auc: 0.3584 - val_auc: 0.1011                                                                                                    \n",
      "epoch: 0028, loss: 0.6233 - val_loss: 0.8739; auc: 0.4096 - val_auc: 0.1005                                                                                                    \n",
      "epoch: 0029, loss: 0.6170 - val_loss: 0.9295; auc: 0.3853 - val_auc: 0.1013                                                                                                    \n",
      "epoch: 0030, loss: 0.6139 - val_loss: 0.9059; auc: 0.4491 - val_auc: 0.1084                                                                                                    \n",
      "epoch: 0031, loss: 0.6150 - val_loss: 0.8942; auc: 0.5204 - val_auc: 0.1079                                                                                                    \n",
      "epoch: 0032, loss: 0.6108 - val_loss: 0.9158; auc: 0.5035 - val_auc: 0.0977                                                                                                    \n",
      "epoch: 0033, loss: 0.6079 - val_loss: 0.9389; auc: 0.5116 - val_auc: 0.0971                                                                                                    \n",
      "epoch: 0034, loss: 0.6068 - val_loss: 1.0424; auc: 0.6032 - val_auc: 0.1375                                                                                                    \n",
      "epoch: 0035, loss: 0.6013 - val_loss: 0.9592; auc: 0.5829 - val_auc: 0.1231                                                                                                    \n",
      "epoch: 0036, loss: 0.6050 - val_loss: 0.9754; auc: 0.6163 - val_auc: 0.1316                                                                                                    \n",
      "epoch: 0037, loss: 0.5999 - val_loss: 0.9551; auc: 0.6261 - val_auc: 0.1210                                                                                                    \n",
      "epoch: 0038, loss: 0.6010 - val_loss: 1.0122; auc: 0.6222 - val_auc: 0.1222                                                                                                    \n",
      "epoch: 0039, loss: 0.6019 - val_loss: 1.1244; auc: 0.6858 - val_auc: 0.1029                                                                                                    \n",
      "epoch: 0040, loss: 0.5962 - val_loss: 1.0749; auc: 0.7281 - val_auc: 0.1425                                                                                                    \n",
      "epoch: 0041, loss: 0.5948 - val_loss: 1.1353; auc: 0.7508 - val_auc: 0.1251                                                                                                    \n",
      "epoch: 0042, loss: 0.5962 - val_loss: 1.0716; auc: 0.7216 - val_auc: 0.1086                                                                                                    \n",
      "epoch: 0043, loss: 0.5958 - val_loss: 1.2303; auc: 0.6562 - val_auc: 0.1518                                                                                                    \n",
      "epoch: 0044, loss: 0.5958 - val_loss: 1.2247; auc: 0.7633 - val_auc: 0.1364                                                                                                    \n",
      "epoch: 0045, loss: 0.5958 - val_loss: 0.9618; auc: 0.7333 - val_auc: 0.1092                                                                                                    \n",
      "epoch: 0046, loss: 0.6031 - val_loss: 1.2602; auc: 0.6985 - val_auc: 0.1366                                                                                                    \n",
      "epoch: 0047, loss: 0.5911 - val_loss: 1.2000; auc: 0.8004 - val_auc: 0.1176                                                                                                    \n",
      "epoch: 0048, loss: 0.5903 - val_loss: 1.2915; auc: 0.8094 - val_auc: 0.1130                                                                                                    \n",
      "epoch: 0049, loss: 0.5934 - val_loss: 0.9285; auc: 0.7498 - val_auc: 0.1318                                                                                                    \n",
      "epoch: 0050, loss: 0.5946 - val_loss: 1.2918; auc: 0.8112 - val_auc: 0.1351                                                                                                    \n",
      "epoch: 0051, loss: 0.5906 - val_loss: 1.2277; auc: 0.8156 - val_auc: 0.1380                                                                                                    \n",
      "epoch: 0052, loss: 0.5906 - val_loss: 1.3763; auc: 0.7955 - val_auc: 0.1327                                                                                                    \n",
      "epoch: 0053, loss: 0.5897 - val_loss: 1.3532; auc: 0.8663 - val_auc: 0.1279                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00053: early stopping\n",
      "74469 9309 9309\n",
      "epoch: 0001, loss: 0.8055 - val_loss: 0.8431; auc: 0.0211 - val_auc: 0.0071                                                                                                    \n",
      "epoch: 0002, loss: 0.8027 - val_loss: 0.8423; auc: 0.0600 - val_auc: 0.0056                                                                                                    \n",
      "epoch: 0003, loss: 0.8022 - val_loss: 0.8422; auc: 0.0637 - val_auc: 0.0056                                                                                                    \n",
      "epoch: 0004, loss: 0.8005 - val_loss: 0.8381; auc: 0.0771 - val_auc: 0.0064                                                                                                    \n",
      "epoch: 0005, loss: 0.7973 - val_loss: 0.8392; auc: 0.0704 - val_auc: 0.0094                                                                                                    \n",
      "epoch: 0006, loss: 0.7907 - val_loss: 0.8279; auc: 0.0414 - val_auc: 0.0058                                                                                                    \n",
      "epoch: 0007, loss: 0.7831 - val_loss: 0.8227; auc: 0.0575 - val_auc: 0.0069                                                                                                    \n",
      "epoch: 0008, loss: 0.7717 - val_loss: 0.8198; auc: 0.0626 - val_auc: 0.0088                                                                                                    \n",
      "epoch: 0009, loss: 0.7589 - val_loss: 0.8206; auc: 0.0630 - val_auc: 0.0088                                                                                                    \n",
      "epoch: 0010, loss: 0.7482 - val_loss: 0.8174; auc: 0.0710 - val_auc: 0.0085                                                                                                    \n",
      "epoch: 0011, loss: 0.7388 - val_loss: 0.8133; auc: 0.0777 - val_auc: 0.0118                                                                                                    \n",
      "epoch: 0012, loss: 0.7300 - val_loss: 0.8312; auc: 0.0745 - val_auc: 0.0124                                                                                                    \n",
      "epoch: 0013, loss: 0.7205 - val_loss: 0.8794; auc: 0.0718 - val_auc: 0.0119                                                                                                    \n",
      "epoch: 0014, loss: 0.7141 - val_loss: 0.8472; auc: 0.0780 - val_auc: 0.0125                                                                                                    \n",
      "epoch: 0015, loss: 0.7056 - val_loss: 0.8187; auc: 0.1018 - val_auc: 0.0115                                                                                                    \n",
      "epoch: 0016, loss: 0.6994 - val_loss: 0.8351; auc: 0.1218 - val_auc: 0.0137                                                                                                    \n",
      "epoch: 0017, loss: 0.6945 - val_loss: 0.8565; auc: 0.1086 - val_auc: 0.0149                                                                                                    \n",
      "epoch: 0018, loss: 0.6866 - val_loss: 0.8889; auc: 0.1098 - val_auc: 0.0157                                                                                                    \n",
      "epoch: 0019, loss: 0.6821 - val_loss: 0.8423; auc: 0.1396 - val_auc: 0.0152                                                                                                    \n",
      "epoch: 0020, loss: 0.6727 - val_loss: 0.9264; auc: 0.1437 - val_auc: 0.0149                                                                                                    \n",
      "epoch: 0021, loss: 0.6707 - val_loss: 0.8703; auc: 0.1630 - val_auc: 0.0151                                                                                                    \n",
      "epoch: 0022, loss: 0.6655 - val_loss: 0.8761; auc: 0.1784 - val_auc: 0.0137                                                                                                    \n",
      "epoch: 0023, loss: 0.6597 - val_loss: 0.8667; auc: 0.1950 - val_auc: 0.0141                                                                                                    \n",
      "epoch: 0024, loss: 0.6526 - val_loss: 0.9360; auc: 0.1945 - val_auc: 0.0169                                                                                                    \n",
      "epoch: 0025, loss: 0.6479 - val_loss: 0.9153; auc: 0.2335 - val_auc: 0.0143                                                                                                    \n",
      "epoch: 0026, loss: 0.6431 - val_loss: 1.0224; auc: 0.2455 - val_auc: 0.0166                                                                                                    \n",
      "epoch: 0027, loss: 0.6400 - val_loss: 0.9032; auc: 0.2486 - val_auc: 0.0126                                                                                                    \n",
      "epoch: 0028, loss: 0.6364 - val_loss: 0.9822; auc: 0.2915 - val_auc: 0.0162                                                                                                    \n",
      "epoch: 0029, loss: 0.6319 - val_loss: 1.0002; auc: 0.3045 - val_auc: 0.0136                                                                                                    \n",
      "epoch: 0030, loss: 0.6306 - val_loss: 1.0403; auc: 0.3433 - val_auc: 0.0156                                                                                                    \n",
      "epoch: 0031, loss: 0.6259 - val_loss: 1.0278; auc: 0.3638 - val_auc: 0.0146                                                                                                    \n",
      "epoch: 0032, loss: 0.6222 - val_loss: 1.0715; auc: 0.3927 - val_auc: 0.0143                                                                                                    \n",
      "epoch: 0033, loss: 0.6204 - val_loss: 1.1010; auc: 0.3922 - val_auc: 0.0151                                                                                                    \n",
      "epoch: 0034, loss: 0.6169 - val_loss: 1.1295; auc: 0.4382 - val_auc: 0.0154                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, split_idxs in enumerate(induces):\n",
    "\n",
    "    train_idx, valid_idx, test_idx = split_idxs\n",
    "    print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "    trainX = (X1[train_idx], X2[train_idx])\n",
    "    trainY = Y[train_idx]\n",
    "\n",
    "    validX = (X1[valid_idx], X2[valid_idx])\n",
    "    validY = Y[valid_idx]\n",
    "\n",
    "    testX = (X1[test_idx], X2[test_idx])\n",
    "    testY = Y[test_idx]            \n",
    "\n",
    "    pos_weights, neg_weights = get_pos_weights(trainY)\n",
    "    loss = lambda y_true, y_pred: molmodel.loss.weighted_cross_entropy(y_true,y_pred, pos_weights, MASK = -1)\n",
    "\n",
    "    model = molmodel.net.DoublePathNet(molmap1_size, molmap2_size, \n",
    "                                       n_outputs=Y.shape[-1], \n",
    "                                       dense_layers=dense_layers, \n",
    "                                       dense_avf = dense_avf, \n",
    "                                       last_avf=last_avf)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #\n",
    "    #import tensorflow_addons as tfa\n",
    "    #opt = tfa.optimizers.AdamW(weight_decay = 0.1,learning_rate=0.001,beta1=0.9,beta2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer = opt, loss = loss)\n",
    "\n",
    "    performance = molmodel.cbks.CLA_EarlyStoppingAndPerformance((trainX, trainY), \n",
    "                                                                   (validX, validY), \n",
    "                                                                   patience = patience, \n",
    "                                                                   criteria = monitor,\n",
    "                                                                   metric = metric,\n",
    "                                                                  )\n",
    "    model.fit(trainX, trainY, batch_size=batch_size, \n",
    "          epochs=epochs, verbose= 0, shuffle = True, \n",
    "          validation_data = (validX, validY), \n",
    "          callbacks=[performance]) \n",
    "\n",
    "\n",
    "    best_epoch = performance.best_epoch\n",
    "    trainable_params = model.count_params()\n",
    "    \n",
    "    train_aucs = performance.evaluate(trainX, trainY)            \n",
    "    valid_aucs = performance.evaluate(validX, validY)            \n",
    "    test_aucs = performance.evaluate(testX, testY)\n",
    "\n",
    "    final_res = {\n",
    "                     'task_name':task_name,            \n",
    "                     'train_auc':np.nanmean(train_aucs), \n",
    "                     'valid_auc':np.nanmean(valid_aucs),                      \n",
    "                     'test_auc':np.nanmean(test_aucs), \n",
    "                     'metric':metric,\n",
    "                     '# trainable params': trainable_params,\n",
    "                     'best_epoch': best_epoch,\n",
    "                     'batch_size':batch_size,\n",
    "                     'lr': lr,\n",
    "                     'weight_decay':weight_decay\n",
    "                    }\n",
    "    \n",
    "    results.append(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f74d1dde518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(performance.history)[['auc', 'val_auc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09577824485433067"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03853965267093655"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).test_auc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>valid_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>metric</th>\n",
       "      <th># trainable params</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MUV</td>\n",
       "      <td>0.158415</td>\n",
       "      <td>0.075642</td>\n",
       "      <td>0.055068</td>\n",
       "      <td>PRC</td>\n",
       "      <td>719537</td>\n",
       "      <td>21</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MUV</td>\n",
       "      <td>0.656168</td>\n",
       "      <td>0.151842</td>\n",
       "      <td>0.131699</td>\n",
       "      <td>PRC</td>\n",
       "      <td>719537</td>\n",
       "      <td>42</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MUV</td>\n",
       "      <td>0.194501</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.100568</td>\n",
       "      <td>PRC</td>\n",
       "      <td>719537</td>\n",
       "      <td>23</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task_name  train_auc  valid_auc  test_auc metric  # trainable params  \\\n",
       "0       MUV   0.158415   0.075642  0.055068    PRC              719537   \n",
       "1       MUV   0.656168   0.151842  0.131699    PRC              719537   \n",
       "2       MUV   0.194501   0.016884  0.100568    PRC              719537   \n",
       "\n",
       "   best_epoch  batch_size      lr  weight_decay  \n",
       "0          21         128  0.0001             0  \n",
       "1          42         128  0.0001             0  \n",
       "2          23         128  0.0001             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('./results/%s.csv' % task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
